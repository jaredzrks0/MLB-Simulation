{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cc637b-3c0c-4eaa-949e-114252d863ad",
   "metadata": {},
   "source": [
    "## UPDATES IN PROGRESS -- PRIOR SAVED VERSIONS OF FINAL DATASETS CAN BE LOADED IN TRAINING MODELS WORKSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2960ea60-04b9-4d9d-becc-8e033aff61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to do:\n",
    "### - SORT VALUES IN THE BATTER AND PITCHER DFS ON GAME STATE TO ENSURE ALL PLAYS ARE IN ORDER\n",
    "### - Add in current game situation (inning, score diff, runners on)\n",
    "### - Add in num batters faced for pitcher in game (also maybe a rest metric like days since last pitched if its easy)\n",
    "### If we ever start using the daily pulled weather with hourly changes, make sure the weather attachment and cleaning still works in build_plays_by_hand_combo\n",
    "\n",
    "\n",
    "# Use the below to eventually build a stealing df to help with the simulation\n",
    "# pitches[pitches.des.str.contains(\"steal\") == True].iloc[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeafc4d",
   "metadata": {},
   "source": [
    "### Import Packages and Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13d2afd-0220-4a36-96a4-80e22c5e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Major Packages\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import sys\n",
    "import sklearn \n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import time\n",
    "import timeit\n",
    "import random\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, cross_validate, cross_val_predict, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Modules in folder\n",
    "import constants\n",
    "from functions import *\n",
    "# Warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Internal Modules Outside Current Folder\n",
    "# Change the path so that we can import the local cloud functions stored in a different directory. THE PATH IS DIFFERENT ON MAC AND PI, SO USE TRY EXCEPT FOR BOTH\n",
    "try: # for mac\n",
    "    sys.path.insert(1, '/users/jaredzirkes/Desktop/Python/GitHub')\n",
    "    from google_cloud.cloud_functions import CloudHelper\n",
    "except:\n",
    "    sys.path.insert(1, \"/home/pi/Desktop/Python\")\n",
    "    from google_cloud.cloud_functions import CloudHelper\n",
    "\n",
    "YEAR = 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3327f",
   "metadata": {},
   "source": [
    "### Import Prior Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86bf466-5680-46ed-8451-9f295e3e26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file of raw pitches from the given year\n",
    "all_pitches = CloudHelper().download_from_cloud(\"yearly_pitches_files/pitches_{}.pkl\".format(YEAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22461809",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = all_pitches.copy()\n",
    "cleaned_data = clean_raw_pitches(raw_data)\n",
    "coef_dicts = build_neutralization_coefficient_dictionaries(cleaned_data)\n",
    "\n",
    "neutralized_data = neutralize_stats(cleaned_data, coef_dicts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d08fc-e207-495f-a3fd-5f2fe431520e",
   "metadata": {},
   "source": [
    "## Roll Stats Daily To Get Final Odds Functions Training Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f26938-005b-4dc6-9bc9-3722ca5b99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_factored_batting_stats(factored_batting_stats, min_periods = 0, is_dump=False):\n",
    "    \"\"\"\n",
    "    Function rolls batting stats and percentages across the tracked play types.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    factored_batting_stats: DataFrame\n",
    "        A DataFrame that contains the all plays segmented by hand combo, and also includes a column with the calculated impact from the weather/ballpark. This is\n",
    "        the direct output on the neutralize_stats function\n",
    "    \n",
    "    rolling_period: Integer\n",
    "        The size of the time period in at-bats to roll stats by, as an accompanement to the monthly roll.\n",
    "        \n",
    "    min_periods: Integer\n",
    "        The minimum number of at-bats to consider when rolling stats. The rolling function will return None before this number is hit.\n",
    "        \n",
    "    is_dump: Boolean\n",
    "        A boolean determining whether or not the pickle the rolled factord batting stats upon calcualtion\n",
    "        \n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Tuple(DataFrame, Dictionary)\n",
    "        The original all_plays_by_hand_combbo DataFrame for later use\n",
    "        A Nested Dictionary that contains the park factors for each ballpark and each play\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a rolling percentage for each play outcome for each batter and pitcher for each year \n",
    "    rolling_factored_batting_stats = {}\n",
    "    rolling_factored_pitching_stats = {}\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Rolling Batting and Pitching Stats {}\".format(pitbat_combo))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Set up dictionaries to house everything\n",
    "        rolling_factored_batting_stats[pitbat_combo] = {}\n",
    "        rolling_factored_pitching_stats[pitbat_combo] = {}\n",
    "\n",
    "        # Filter down to the stats for just the relevant hand combo and sort by game date for rolling\n",
    "        batter_df, pitcher_df = factored_batting_stats[pitbat_combo].copy(), factored_batting_stats[pitbat_combo].copy()\n",
    "        batter_df, pitcher_df = batter_df.sort_values(by = \"game_date\", ascending = True), pitcher_df.sort_values(by = \"game_date\", ascending = True)\n",
    "        batter_df[\"pitbat\"] = pitbat_combo\n",
    "        pitcher_df[\"pitbat\"] = pitbat_combo\n",
    "    \n",
    "        for play in plays:\n",
    "            # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "            batter_df[\"season_{}\".format(play)] = batter_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "            batter_df[\"month_{}\".format(play)] = batter_df[\"season_{}\".format(play)]\n",
    "            # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "            pitcher_df[\"season_{}\".format(play)] = pitcher_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "            pitcher_df[\"month_{}\".format(play)] = pitcher_df[\"season_{}\".format(play)]\n",
    "            \n",
    "        \n",
    "        # Roll batting stats on a season and montly basis\n",
    "        season_rolled_batter_df = batter_df.copy().groupby(by=\"batter\").rolling(window=504, closed=\"left\").sum().to_dict()\n",
    "        month_rolled_batter_df = batter_df.copy().groupby(by=\"batter\").rolling(window=75, closed=\"left\").sum().to_dict()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Roll pitching stats on a season and montly basis\n",
    "        season_rolled_pitcher_df = pitcher_df.copy().groupby(by=\"pitcher\").rolling(window=504, closed=\"left\").sum().to_dict()\n",
    "        month_rolled_pitcher_df = pitcher_df.copy().groupby(by=\"pitcher\").rolling(window=75, closed=\"left\").sum().to_dict()\n",
    "        \n",
    "        for play in plays:\n",
    "            # Assign the rolled values from players' stats back to the pitcher and batter DataFrames by pulling the data from the dictionaries\n",
    "            batter_df[\"season_{}\".format(play)] = batter_df.apply(lambda x: season_rolled_batter_df[\"season_{}\".format(play)][(x.batter, x.name)], axis = 1)\n",
    "            batter_df[\"month_{}\".format(play)] = batter_df.apply(lambda x: month_rolled_batter_df[\"month_{}\".format(play)][(x.batter, x.name)], axis = 1)\n",
    "            \n",
    "            \n",
    "            pitcher_df[\"season_{}\".format(play)] = pitcher_df.apply(lambda x: season_rolled_pitcher_df[\"season_{}\".format(play)][(x.pitcher, x.name)], axis = 1)\n",
    "            pitcher_df[\"month_{}\".format(play)] = pitcher_df.apply(lambda x: month_rolled_pitcher_df[\"month_{}\".format(play)][(x.pitcher, x.name)], axis = 1)\n",
    "\n",
    "      \n",
    "        print(\"Repercentaging Rolled Batting Stats {}\".format(pitbat_combo))\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Repercentage factored batting stats percentage to sum to 1 because they don't necessarily after neutralization\n",
    "        season_columns = [\"season_{}\".format(play) for play in plays]\n",
    "        month_columns = [\"month_{}\".format(play) for play in plays]\n",
    "        batter_df[season_columns] = batter_df.apply(lambda row: pd.Series([row[f\"season_{play_type}\"]/row[season_columns].sum() for play_type in list(plays)]) if row[season_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "        batter_df[month_columns] = batter_df.apply(lambda row: pd.Series([row[f\"month_{play_type}\"]/row[month_columns].sum() for play_type in list(plays)]) if row[month_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "       \n",
    "        \n",
    "        print(\"Repercentaging Rolled Pitching Stats {}\".format(pitbat_combo))\n",
    "        # Repercentage factored pitching stats percentage to sum to 1 because they don't necessarily after neutralization\n",
    "        pitcher_df[season_columns] = pitcher_df.apply(lambda row: pd.Series([row[f\"season_{play_type}\"]/row[season_columns].sum() for play_type in list(plays)]) if row[season_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "        pitcher_df[month_columns] = pitcher_df.apply(lambda row: pd.Series([row[f\"month_{play_type}\"]/row[month_columns].sum() for play_type in list(plays)]) if row[month_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "       \n",
    "        \n",
    "        \n",
    "#         pitcher_df[[\"season_{}\".format(play) for play in plays]] = pitcher_df.apply(lambda x: pd.Series([x[[\"season_{}\".format(play) for play in plays]][\"season_{}\".format(p)]/x[[\"season_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"season_{}\".format(p) for p in plays]].sum() > 0 else pd.Series([0 for p in plays]), axis=1)\n",
    "#         pitcher_df[[\"month_{}\".format(play) for play in plays]] = pitcher_df.apply(lambda x: pd.Series([x[[\"month_{}\".format(play) for play in plays]][\"month_{}\".format(p)]/x[[\"month_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"month_{}\".format(p) for p in plays]].sum() > 0 else pd.Series([0 for p in plays]), axis=1)\n",
    "  \n",
    "        # Place the final rolling factored batting stats DataFrame into the storage dictionary\n",
    "        rolling_factored_batting_stats[pitbat_combo] = batter_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "        rolling_factored_pitching_stats[pitbat_combo] = pitcher_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "    \n",
    "    if is_dump == True:\n",
    "        rolling_factored_pitching_stats.to_pickle(\"rolling_factored_pitching_stats.pkl\")\n",
    "        rolling_factored_batting_stats.to_pickle(\"rolling_factored_batting_stats.pkl\")\n",
    "        \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return {\"pitching_stats\":rolling_factored_pitching_stats, \"batting_stats\":rolling_factored_batting_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da57992e-c049-4b99-8ce7-a79ee2d61d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all the rolled individual player DataFrames out of the dictionary and into a large DataFrame that will be used for final training\n",
    "def stitch_individual_stats(rolling_factored_stats):\n",
    "\n",
    "    stitched_data = {}\n",
    "    \n",
    "    batting_dict = {}\n",
    "    pitching_dict = {}\n",
    "    \n",
    "    \n",
    "    df_batter = pd.concat([rolling_factored_stats[\"batting_stats\"][pitbat_combo] for pitbat_combo in hand_combos])\n",
    "    df_pitcher = pd.concat([rolling_factored_stats[\"pitching_stats\"][pitbat_combo] for pitbat_combo in hand_combos])\n",
    "        \n",
    "        \n",
    "    stitched_data[\"batting_stats\"] = df_batter\n",
    "    stitched_data[\"pitching_stats\"] = df_pitcher\n",
    "    \n",
    "    return stitched_data\n",
    "        \n",
    "              \n",
    "        \n",
    "        \n",
    "    \n",
    "#     training_stats = pd.DataFrame()\n",
    "#     pitching_holder = pd.DataFrame()\n",
    "\n",
    "#     for pitbat_combo in hand_combos:\n",
    "#         for batter in rolling_factored_stats[\"batting_stats\"][pitbat_combo]:\n",
    "            \n",
    "#             # Find each specific player df of unique pitbat combo, and batter\n",
    "#             df_b = rolling_factored_stats[\"batting_stats\"][pitbat_combo][batter]\n",
    "\n",
    "#             # We will through an error trying to look for games with dates less than our opening day, and there's\n",
    "#             # no need to stats for ~1 games anyways, so cut off the first 3 PAs of stats\n",
    "#             if len(df_b) > 3:\n",
    "#                 training_stats = training_stats.append(df_b[3:]) \n",
    "\n",
    "#         # Do the same thing for pitchers. Note we can leave in the first 3 PAs, because we will be simply joining with\n",
    "#         # the batters, so these PAs will get cut off then.\n",
    "#         for pitcher in rolling_factored_stats[\"pitching_stats\"][pitbat_combo]:\n",
    "#             df_p = rolling_factored_stats[\"pitching_stats\"][pitbat_combo][pitcher]\n",
    "#             pitching_holder = pitching_holder.append(df_p) \n",
    "\n",
    "#         clear_output(wait=False)\n",
    "\n",
    "#     if with_year_breaks == True:\n",
    "#         training_stats[\"year\"] = training_stats.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "#         pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "#     else:\n",
    "#         training_stats[\"year\"] = training_stats.game_date.apply(lambda x: \"All Years\")\n",
    "#         pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: \"All Years\")\n",
    "\n",
    "#     #pitching_holder = pitching_holder.rename(columns = {\"batter\":'pitcher'})\n",
    "\n",
    "#     clear_output(wait=False)\n",
    "    \n",
    "    return {\"pitching_stats\":pitching_holder, \"batting_stats\":training_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2df3808-a08f-4b90-9b1b-f8283a195e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the pitching probability vector to the training set by \"joining\" on the pitbat combo, year, and pitcher name, where the date is just less than the given PA.\n",
    "# Then reattatch the weather and ballpark info for that game\n",
    "def finalize_dataset(stitched_dataset, rolling_factored_stats, factored_batting_stats, stats_with_weather):\n",
    "    stitched_dataset[\"pitching_stats\"].columns = [\"pitcher_\" + col for col in stitched_dataset[\"pitching_stats\"].columns]\n",
    "    pitching_columns_to_add = [\"pitcher_season_{}\".format(play) for play in plays] + [\"pitcher_month_{}\".format(play) for play in plays]\n",
    "    stitched_dataset[\"batting_stats\"][pitching_columns_to_add] = stitched_dataset[\"pitching_stats\"][pitching_columns_to_add]\n",
    "    \n",
    "#     for play in plays:\n",
    "# #         print(\"Attaching the Batter Probability Vectors to the Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "# #         #stitched_dataset[\"batting_stats\"][\"b_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "# #         # stitched_dataset[\"batting_stats\"][\"b_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "       \n",
    "# #         batting_df = stitched_dataset[\"batting_stats\"].apply(lambda x: stitched_dataset[\"batting_stats\"][(stitched_dataset[\"batting_stats\"].batter.values == x.batter) & (stitched_dataset[\"batting_stats\"].game_date.values < x.game_date)].iloc[-1][[\"season_\" + play, \"month_\" + play]] if len(stitched_dataset[\"batting_stats\"][(stitched_dataset[\"batting_stats\"].batter.values == x.batter) & (stitched_dataset[\"batting_stats\"].game_date.values < x.game_date)]) > 0 else pd.DataFrame(), axis=1) \n",
    "# #         stitched_dataset[\"batting_stats\"][\"b_season_\" + play] = batting_df[\"season_\" + play] if len(batting_df) > 0 else None\n",
    "# #         stitched_dataset[\"batting_stats\"][\"b_month_\" + play] = batting_df[\"month_\" + play] if len(batting_df) > 0 else None\n",
    "        \n",
    "\n",
    "# #         clear_output(wait=True)\n",
    "\n",
    "#         print(\"Attaching the Pitcher Probability Vectors to the Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "# #         stitched_dataset[\"batting_stats\"][\"p_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "# #         stitched_dataset[\"batting_stats\"][\"p_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        \n",
    "#         pitching_df = stitched_dataset[\"pitching_stats\"].apply(lambda x: stitched_dataset[\"pitching_stats\"][(stitched_dataset[\"pitching_stats\"].pitcher.values == x.pitcher) & (stitched_dataset[\"pitching_stats\"].game_date.values == x.game_date)].iloc[-1][\"season_\" + play, \"month_\" + play] if len(stitched_dataset[\"pitching_stats\"][(stitched_dataset[\"pitching_stats\"].pitcher.values == x.pitcher) & (stitched_dataset[\"pitching_stats\"].game_date.values < x.game_date)]) > 0 else pd.DataFrame(), axis=1)\n",
    "#         stitched_dataset[\"pitching_stats\"][\"b_season_\" + play] = pitching_df[\"season_\" + play] if len(pitching_df) > 0 else None\n",
    "#         stitched_dataset[\"pitching_stats\"][\"b_month_\" + play] = pitching_df[\"month_\" + play] if len(pitching_df) > 0 else None\n",
    "        \n",
    "        \n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "\n",
    "\n",
    "    # Add in a column for the actual play, to be used for comparison against our prediction vector\n",
    "    stitched_dataset[\"batting_stats\"][\"play\"] = stitched_dataset[\"batting_stats\"].apply(lambda x: factored_batting_stats[x.pitbat].loc[x.name].play_type, axis=1)\n",
    "    \n",
    "    \n",
    "    # Attatch the weather information # THIS MAY HAVE TO CHANGE WITH WEATHER CODING UPDATES\n",
    "    print(\"Attatching Original Weather Information to Final Dataset\")\n",
    "\n",
    "    weather_columns = [\"temprature_squared\", \"Left to Right\", \"Right to Left\", \"in\", \"out\", \"zero\"]\n",
    "    stitched_dataset[\"batting_stats\"][weather_columns] = stitched_dataset[\"batting_stats\"].apply(lambda x: stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk].iloc[0][weather_columns] if len(stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk]) > 0 else pd.Series({x:None for x in weather_columns}) , axis=1)\n",
    "    stitched_dataset[\"batting_stats\"][\"is_on_base\"] = stitched_dataset[\"batting_stats\"].play.apply(lambda x: 1 if x in [\"single\", \"double\", \"triple\", \"home_run\", \"walk\", \"intent_walk\"] else 0)\n",
    "    \n",
    "    # Attatch the League Average Information \n",
    "    print(\"Attatching League Average Information\")\n",
    "    league_averages = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "        league_averages[pitbat_combo] = {}\n",
    "        pitbat_df = stitched_dataset[\"batting_stats\"][stitched_dataset[\"batting_stats\"].pitbat == pitbat_combo].copy()\n",
    "        for date in pitbat_df.game_date.unique():\n",
    "            league_averages[pitbat_combo][date] = {\"season\":{}, \"month\":{}}\n",
    "            season_ago = str(int(date.split(\"-\")[0]) - 1) + date.split(\"-\")[1] + date.split(\"-\")[2]\n",
    "            month_ago = date.split(\"-\")[0] + str(int(date.split(\"-\")[1]) - 1) + date.split(\"-\")[2] #We can just subtract one from the month because baseball is not played in January\n",
    "            \n",
    "            season_pitbat_date_df = pitbat_df[(pitbat_df.game_date < date) & (pitbat_df.game_date > season_ago)]#[-1*min(504, len(pitbat_df)):].copy()\n",
    "            month_pitbat_date_df = pitbat_df[(pitbat_df.game_date < date) & (pitbat_df.game_date > month_ago)]#[-1*min(100, len(pitbat_df)):].copy()\n",
    "            \n",
    "            # Find league average from the month and full seasons worth of time\n",
    "            \n",
    "            for play in plays:\n",
    "                season_play_average = len(season_pitbat_date_df[season_pitbat_date_df.play == play])/len(season_pitbat_date_df) if len(season_pitbat_date_df) > 0 else None\n",
    "                month_play_average = len(month_pitbat_date_df[month_pitbat_date_df.play == play])/len(month_pitbat_date_df) if len(month_pitbat_date_df) > 0 else None\n",
    "                \n",
    "                league_averages[pitbat_combo][date][\"season\"][play] = season_play_average\n",
    "                league_averages[pitbat_combo][date][\"month\"][play] = season_play_average\n",
    "\n",
    "    for play in plays:\n",
    "        stitched_dataset[\"batting_stats\"][\"season_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"season\"][play], axis=1)\n",
    "        stitched_dataset[\"batting_stats\"][\"month_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"month\"][play], axis=1)\n",
    "    \n",
    "    \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return stitched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c73a80-2cc4-4cfd-8513-0ce0419cabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(final_dataset):\n",
    "    for col in [\"on_3b\", \"on_2b\", \"on_1b\"]:\n",
    "        final_dataset[col] = final_dataset[col].apply(lambda x: 1 if pd.isna(x) == False else 0) \n",
    "    \n",
    "    final_dataset[\"inning_topbot\"] = odds_dataset[col].apply(lambda x: 1 if x == \"Top\" else 0) \n",
    "    \n",
    "    ml_full_df = odds_dataset[[col for col in odds_dataset.columns if col not in [\"game_pk\", \"batter\", \"pitcher\", \"temprature\", \"wind_speed\", \"wind_direction\", \"year\"]]].dropna()\n",
    "    ml_full_df = ml_full_df[ml_full_df.game_date.apply(lambda x: int(x.split(\"-\")[1])) >= 5].reset_index(drop=True)\n",
    "    ml_full_df.drop(columns = [\"game_date\"], inplace=True)\n",
    "    ml_full_y_play = ml_full_df.play\n",
    "    ml_full_y_on_base = ml_full_df.is_on_base\n",
    "    ml_full_df.drop(columns = [\"play\", \"is_on_base\"], inplace = True)\n",
    "\n",
    "    numeric_features = [col for col in ml_full_df if col not in [\"ballpark\", \"pitbat\"]]\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "    \n",
    "    categorical_features = [\"ballpark\", \"pitbat\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ml_pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor)]\n",
    "    )\n",
    "\n",
    "    ml_full_df = ml_pipe.fit_transform(ml_full_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e2309a-a92f-404f-8456-3072da6229f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(pitches, pickle):\n",
    "    # Clean raw pitch data and sort everything by hand combos\n",
    "    all_plays_by_hand_combo = build_plays_by_hand_combo(pitches)\n",
    "    all_plays_by_hand_combo = attach_ballpark_info(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the shares of each play in each game\n",
    "    game_play_share_data = calculate_game_play_shares(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the league averages over time for each play\n",
    "    league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "    # Clean the data necessary for the weather regression, then run the analysis\n",
    "    data_for_weather_regression = prepare_weather_regression(game_play_share_data)\n",
    "    weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "    weather_coefficients = weather_regression_set[1]\n",
    "    \n",
    "    # Additionally, calculate the impact of specific parks \n",
    "    park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "    # \"Neutralize\" the raw events based on the impact from stadium and weather\n",
    "    neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors)\n",
    "\n",
    "    # Take the neutralized stats for each player and roll them for a month and a season's worth of time\n",
    "    individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats)\n",
    "    \n",
    "    # Recombine the separated dataframes (by hand combo) into one large dataframe\n",
    "    stitched_rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats)\n",
    "    \n",
    "    # Join the batting and pitching datasets so that for any given day we have both the batter and pitcher's stats\n",
    "    final_dataset = finalize_dataset(stitched_rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)\n",
    "\n",
    "    # Process the final dataset with a standard pipeline to be used in training algorithms\n",
    "    processed_dataset = process_pipeline(final_dataset[\"stats\"][\"batting_stats\"])\n",
    "    \n",
    "    return {\"stats\":final_dataset, \"league_averages\":league_averages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a148367-81b6-4f8f-a61c-b23895257a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(pitches, pickle):\n",
    "    # Clean raw pitch data and sort everything by hand combos\n",
    "    all_plays_by_hand_combo = build_plays_by_hand_combo(pitches)\n",
    "    all_plays_by_hand_combo = attach_ballpark_info(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the shares of each play in each game\n",
    "    game_play_share_data = calculate_game_play_shares(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the league averages over time for each play\n",
    "    league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "    # Clean the data necessary for the weather regression, then run the analysis\n",
    "    data_for_weather_regression = prepare_weather_regression(game_play_share_data)\n",
    "    weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "    weather_coefficients = weather_regression_set[1]\n",
    "    \n",
    "    # Additionally, calculate the impact of specific parks \n",
    "    park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "    # \"Neutralize\" the raw events based on the impact from stadium and weather\n",
    "    neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors)\n",
    "\n",
    "    # Take the neutralized stats for each player and roll them for a month and a season's worth of time\n",
    "    individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats)\n",
    "    \n",
    "    # Recombine the separated dataframes (by hand combo) into one large dataframe\n",
    "    stitched_rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats)\n",
    "    \n",
    "    # Join the batting and pitching datasets so that for any given day we have both the batter and pitcher's stats\n",
    "    final_dataset = finalize_dataset(stitched_rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)\n",
    "    \n",
    "    return {\"stats\":final_dataset, \"league_averages\":league_averages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db849c3f-a79f-4cd9-898f-9fe9f02f46c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0a7f9-30cf-42a2-98c5-c9491a8eb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(ml_full_df, open(\"/Users/jaredzirkes/Desktop/Python/Non-Github/Project - MLB Simulation/Checkpoint Files/Model Building/ML X Dataset\", \"wb\"))\n",
    "pkl.dump(ml_full_y_play, open(\"/Users/jaredzirkes/Desktop/Python/Non-Github/Project - MLB Simulation/Checkpoint Files/Model Building/ML Y Dataset(Plays)\", \"wb\"))\n",
    "pkl.dump(ml_full_y_on_base, open(\"/Users/jaredzirkes/Desktop/Python/Non-Github/Project - MLB Simulation/Checkpoint Files/Model Building/ML Y Dataset (On Base)\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30a78a5-f63d-4adf-bcad-31efe9ac1711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
