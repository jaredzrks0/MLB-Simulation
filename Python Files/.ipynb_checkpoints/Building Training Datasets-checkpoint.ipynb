{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cc637b-3c0c-4eaa-949e-114252d863ad",
   "metadata": {},
   "source": [
    "## UPDATES IN PROGRESS -- PRIOR SAVED VERSIONS OF FINAL DATASETS CAN BE LOADED IN TRAINING MODELS WORKSHEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2960ea60-04b9-4d9d-becc-8e033aff61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to do:\n",
    "### - SORT VALUES IN THE BATTER AND PITCHER DFS ON GAME STATE TO ENSURE ALL PLAYS ARE IN ORDER\n",
    "### - Add in current game situation (inning, score diff, runners on)\n",
    "### - Add in num batters faced for pitcher in game (also maybe a rest metric like days since last pitched if its easy)\n",
    "### Be able to assign the 2nd half of a double header the weather for not the first game. Right now all games get weather[x=x].iloc[0]\n",
    "### If we ever start using the daily pulled weather with hourly changes, make sure the weather attachment and cleaning still works in build_plays_by_hand_combo\n",
    "\n",
    "\n",
    "# Use the below to eventually build a stealing df to help with the simulation\n",
    "# pitches[pitches.des.str.contains(\"steal\") == True].iloc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13d2afd-0220-4a36-96a4-80e22c5e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import sklearn \n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import time\n",
    "import timeit\n",
    "import random\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, cross_validate, cross_val_predict, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "hand_combos = [\"RR\", \"RL\", \"LR\", \"LL\"]\n",
    "plays = ['strikeout', 'fly_out', 'double', 'out', 'fielders_choice','error', 'walk', 'home_run', 'single', 'sacrifice', 'double_play', 'intent_walk', 'triple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86bf466-5680-46ed-8451-9f295e3e26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpark_info = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/GitHub/Project - MLB Simulation/Outside Info Files/Ballpark Info.xlsx\", header=2)[[\"Stadium\", \"Team\", \"Start Date\", \"End Date\"]]\n",
    "weather = pd.read_pickle(\"/Users/jaredzirkes/Desktop/Python/Non-GitHub/Project - MLB Data Collection/ProReference Weather Pickles/weather_data_through_2024.pkl\") # Update this with the most recent version after running through 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3dee1f8-5614-47cb-8d78-c6a61e09a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team name and abbv conversions for use in attatching weather to pitches\n",
    "weather_name_conversions = {\"SF\":\"San Francisco Giants\", \"NYY\":\"New York Yankees\", \"DET\":\"Detroit Tigers\", \"TEX\":\"Texas Rangers\",\n",
    "                            \"STL\":\"St. Louis Cardinals\", \"WSH\":\"Washington Nationals\", \"MIL\":\"Milwaukee Brewers\", \"CLE\":\"Cleveland Guardians\",\n",
    "                            \"SD\":\"San Diego Padres\", \"COL\":\"Colorado Rockies\", \"BAL\":\"Baltimore Orioles\", \"HOU\":\"Houston Astros\",\n",
    "                            \"KC\":\"Kansas City Royals\", \"OAK\":\"Oakland Athletics\", \"BOS\":\"Boston Red Sox\", \"CWS\":\"Chicago White Sox\",\n",
    "                            \"AZ\":\"Arizona Diamondbacks\",\"ARI\":\"Arizona Diamondbacks\", \"ATL\":\"Atlanta Braves\", \"CIN\":\"Cincinnati Reds\", \"MIN\":\"Minnesota Twins\",\n",
    "                            \"MIA\":\"Miami Marlins\", \"LAD\":\"Los Angeles Dodgers\", \"TB\":\"Tampa Bay Rays\", \"PHI\":\"Philadelphia Phillies\",\n",
    "                            \"NYM\":\"New York Mets\", \"CHC\":\"Chicago Cubs\", \"TOR\":\"Toronto Blue Jays\", \"SEA\":\"Seattle Mariners\",\n",
    "                            \"LAA\":\"Los Angeles Angels\", \"PIT\":\"Pittsburgh Pirates\"}                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67dee4e7-8b54-4542-8e61-23adc31f74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of info for use in cleaning\n",
    "relevant_batting_columns = [\"game_date\", \"player_name\", \"batter\", \"pitcher\", \"events\", \"stand\", \"p_throws\", \"home_team\", \"away_team\",\n",
    "                            \"hit_location\", \"bb_type\", \"on_3b\", \"on_2b\", \"on_1b\", \"outs_when_up\", \"inning\", \"inning_topbot\",\"game_type\",\n",
    "                            \"game_pk\", \"estimated_ba_using_speedangle\", \"launch_speed_angle\", \"bat_score\", \"fld_score\", \"post_bat_score\",\n",
    "                            \"if_fielding_alignment\", \"of_fielding_alignment\", \"delta_home_win_exp\"]\n",
    "\n",
    "relevant_play_types = [\"field_out\", \"strikeout\", \"strikeout_double_play\", \"force_out\", \"grounded_into_double_play\", \"double_play\", \"fielders_choice\",\n",
    "                    \"fielders_choice_out\", \"other_out\", \"sac_fly\", \"sac_bunt\", \"single\", \"double\", \"triple\", \"home_run\", \n",
    "                    \"walk\", \"hit_by_pitch\", \"intent_walk\", \"field_error\"]\n",
    "\n",
    "play_type_dict = {\"field_out\":\"fly_out\", \"strikeout\":\"strikeout\", \"strikeout_double_play\":\"strikeout\", \"force_out\":\"out\", \"grounded_into_double_play\":\"double_play\", \"double_play\":\"double_play\", \"fielders_choice\":\"fielders_choice\",\n",
    "                    \"fielders_choice_out\":\"fielders_choice\", \"other_out\":\"out\", \"sac_fly\":\"sacrifice\", \"sac_bunt\":\"sacrifice\", \"single\":\"single\", \"double\":\"double\", \"triple\":\"triple\", \"home_run\":\"home_run\", \n",
    "                    \"walk\":\"walk\", \"hit_by_pitch\":\"walk\", \"intent_walk\":\"intent_walk\", \"field_error\":\"error\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "743aa269-74b9-42a2-9c79-d815dbd5b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wind_direction(full_weather):\n",
    "    \"\"\"Given the full description, pull out the wind direction\"\"\"\n",
    "    if full_weather != None:\n",
    "        if \"in\" in \"\".join(full_weather.split(\"Wind\")) or \"In\" in \"\".join(full_weather.split(\"Wind\")):\n",
    "            return \"in\" #full_weather.full_weather.split(\"mph \")[-1].split(' from')[0]\n",
    "        elif \"out\" in \"\".join(full_weather.split(\"Wind\")) or \"Out\" in \"\".join(full_weather.split(\"Wind\")):\n",
    "            return \"out\" #full_weather.full_weather.split(\"mph \")[-1].split(' to')[0]\n",
    "        if \"Left\" in \"\".join(full_weather.split(\"Wind\")) or \"Right\" in \"\".join(full_weather.split(\"Wind\")):\n",
    "            return full_weather.split(\"from \")[-1].strip(\".\")\n",
    "    else:\n",
    "        return \"xyz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad475912-f7e8-4589-b226-12d16cc1f29d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean Raw Pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82184391-4510-4b4d-964f-e06e1a3ff3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Raw Pitches\n",
    "pitch_list = []\n",
    "for year in range(2016, 2019):#, dt.today().year +1):\n",
    "    df_pitches = pd.read_pickle(\"/Users/jaredzirkes/Desktop/Python/Non-GitHub/Project - MLB Data Collection/Pitches Pickles/pitches_{}.pkl\".format(year))\n",
    "    pitch_list.append(df_pitches)\n",
    "all_pitches = pd.concat([x for x in pitch_list])\n",
    "%reset_selective -f \"pitch_list\"\n",
    "%reset_selective -f \"df_pitches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a50d89-cab4-4193-aba7-3a6014b197f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden cell to replace weird pitches where home and away team are swapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2766a3c9-a5c5-4e82-aac5-5b5f0fdc3429",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix a strange series to begin 2020 where the Blue Jays played as the home team IN Washington\n",
    "\n",
    "strange_games_I = all_pitches[(all_pitches.home_team == \"TOR\") & (all_pitches.away_team == \"WSH\")].index\n",
    "all_pitches.loc[strange_games_I, \"home_team\"] = \"WSH\"\n",
    "all_pitches.loc[strange_games_I, \"away_team\"] = \"TOR\"\n",
    "\n",
    "strange_games_II = all_pitches[(all_pitches.home_team == \"CIN\") & (all_pitches.away_team == \"SF\") & (all_pitches.game_date == \"2013-07-23\")].index\n",
    "all_pitches.loc[strange_games_II, \"home_team\"] = \"SF\"\n",
    "all_pitches.loc[strange_games_II, \"away_team\"] = \"CIN\"\n",
    "\n",
    "strange_games_III = all_pitches[(all_pitches.home_team == \"BAL\") & (all_pitches.away_team == \"TB\") & (all_pitches.game_date == \"2015-05-01\")].index\n",
    "all_pitches.loc[strange_games_III, \"home_team\"] = \"TB\"\n",
    "all_pitches.loc[strange_games_III, \"away_team\"] = \"BAL\"\n",
    "\n",
    "strange_games_IV = all_pitches[(all_pitches.home_team == \"BAL\") & (all_pitches.away_team == \"TB\") & (all_pitches.game_date == \"2015-05-02\")].index\n",
    "all_pitches.loc[strange_games_IV, \"home_team\"] = \"TB\"\n",
    "all_pitches.loc[strange_games_IV, \"away_team\"] = \"BAL\"\n",
    "\n",
    "strange_games_V = all_pitches[(all_pitches.home_team == \"BAL\") & (all_pitches.away_team == \"TB\") & (all_pitches.game_date == \"2015-05-03\")].index\n",
    "all_pitches.loc[strange_games_V, \"home_team\"] = \"TB\"\n",
    "all_pitches.loc[strange_games_V, \"away_team\"] = \"BAL\"\n",
    "\n",
    "strange_games_VI = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2017-09-16\")].index\n",
    "all_pitches.loc[strange_games_VI, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_VI, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_VII = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2017-09-17\")].index\n",
    "all_pitches.loc[strange_games_VII, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_VII, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_VIII = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2017-09-15\")].index\n",
    "all_pitches.loc[strange_games_VIII, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_VIII, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_IX = all_pitches[(all_pitches.home_team == \"NYY\") & (all_pitches.away_team == \"PHI\") & (all_pitches.game_date == \"2020-08-05\")].index\n",
    "all_pitches.loc[strange_games_IX, \"home_team\"] = \"PHI\"\n",
    "all_pitches.loc[strange_games_IX, \"away_team\"] = \"NYY\"\n",
    "\n",
    "strange_games_X = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"BAL\") & (all_pitches.game_date == \"2020-08-05\")].index\n",
    "all_pitches.loc[strange_games_X, \"home_team\"] = \"BAL\"\n",
    "all_pitches.loc[strange_games_X, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_XI = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"BAL\") & (all_pitches.game_date == \"2020-08-06\")].index\n",
    "all_pitches.loc[strange_games_XI, \"home_team\"] = \"BAL\"\n",
    "all_pitches.loc[strange_games_XI, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_XII = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"BAL\") & (all_pitches.game_date == \"2020-08-07\")].index\n",
    "all_pitches.loc[strange_games_XII, \"home_team\"] = \"BAL\"\n",
    "all_pitches.loc[strange_games_XII, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_XIII = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"CHC\") & (all_pitches.game_date == \"2020-08-17\")].index\n",
    "all_pitches.loc[strange_games_XIII, \"home_team\"] = \"CHC\"\n",
    "all_pitches.loc[strange_games_XIII, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_XIX = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"CHC\") & (all_pitches.game_date == \"2020-08-18\")].index\n",
    "all_pitches.loc[strange_games_XIX, \"home_team\"] = \"CHC\"\n",
    "all_pitches.loc[strange_games_XIX, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_XX = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"CHC\") & (all_pitches.game_date == \"2020-08-19\")].index\n",
    "all_pitches.loc[strange_games_XX, \"home_team\"] = \"CHC\"\n",
    "all_pitches.loc[strange_games_XX, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_XXI = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"WSH\") & (all_pitches.game_date == \"2020-08-22\")].index\n",
    "all_pitches.loc[strange_games_XXI, \"home_team\"] = \"WSH\"\n",
    "all_pitches.loc[strange_games_XXI, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_XXII = all_pitches[(all_pitches.home_team == \"MIA\") & (all_pitches.away_team == \"NYM\") & (all_pitches.game_date == \"2020-08-25\")].index\n",
    "all_pitches.loc[strange_games_XXII, \"home_team\"] = \"NYM\"\n",
    "all_pitches.loc[strange_games_XXII, \"away_team\"] = \"MIA\"\n",
    "\n",
    "strange_games_XXIII = all_pitches[(all_pitches.home_team == \"NYY\") & (all_pitches.away_team == \"ATL\") & (all_pitches.game_date == \"2020-08-26\")].index\n",
    "all_pitches.loc[strange_games_XXIII, \"home_team\"] = \"ATL\"\n",
    "all_pitches.loc[strange_games_XXIII, \"away_team\"] = \"NYY\"\n",
    "\n",
    "strange_games_XXIV = all_pitches[(all_pitches.home_team == \"CIN\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2020-08-27\")].index\n",
    "all_pitches.loc[strange_games_XXIV, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_XXIV, \"away_team\"] = \"CIN\"\n",
    "\n",
    "strange_games_XXV = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SD\") & (all_pitches.game_date == \"2020-08-27\")].index\n",
    "all_pitches.loc[strange_games_XXV, \"home_team\"] = \"SD\"\n",
    "all_pitches.loc[strange_games_XXV, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_XXVI = all_pitches[(all_pitches.home_team == \"LAD\") & (all_pitches.away_team == \"SF\") & (all_pitches.game_date == \"2020-08-27\")].index\n",
    "all_pitches.loc[strange_games_XXVI, \"home_team\"] = \"SF\"\n",
    "all_pitches.loc[strange_games_XXVI, \"away_team\"] = \"LAD\"\n",
    "\n",
    "strange_games_XXVII = all_pitches[(all_pitches.home_team == \"PIT\") & (all_pitches.away_team == \"STL\") & (all_pitches.game_date == \"2020-08-27\")].index\n",
    "all_pitches.loc[strange_games_XXVII, \"home_team\"] = \"STL\"\n",
    "all_pitches.loc[strange_games_XXVII, \"away_team\"] = \"PIT\"\n",
    "\n",
    "strange_games_XXVIII = all_pitches[(all_pitches.home_team == \"NYM\") & (all_pitches.away_team == \"NYY\") & (all_pitches.game_date == \"2020-08-28\")].index\n",
    "all_pitches.loc[strange_games_XXVIII, \"home_team\"] = \"NYY\"\n",
    "all_pitches.loc[strange_games_XXVIII, \"away_team\"] = \"NYM\"\n",
    "\n",
    "strange_games_XXVIV = all_pitches[(all_pitches.home_team == \"MIN\") & (all_pitches.away_team == \"DET\") & (all_pitches.game_date == \"2020-08-29\")].index\n",
    "all_pitches.loc[strange_games_XXVIV, \"home_team\"] = \"DET\"\n",
    "all_pitches.loc[strange_games_XXVIV, \"away_team\"] = \"MIN\"\n",
    "\n",
    "strange_games_XXVV = all_pitches[(all_pitches.home_team == \"OAK\") & (all_pitches.away_team == \"HOU\") & (all_pitches.game_date == \"2020-08-29\")].index\n",
    "all_pitches.loc[strange_games_XXVV, \"home_team\"] = \"HOU\"\n",
    "all_pitches.loc[strange_games_XXVV, \"away_team\"] = \"OAK\"\n",
    "\n",
    "strange_games_XXVVI = all_pitches[(all_pitches.home_team == \"CHC\") & (all_pitches.away_team == \"CIN\") & (all_pitches.game_date == \"2020-08-29\")].index\n",
    "all_pitches.loc[strange_games_XXVVI, \"home_team\"] = \"CIN\"\n",
    "all_pitches.loc[strange_games_XXVVI, \"away_team\"] = \"CHC\"\n",
    "\n",
    "strange_games_XXVVII = all_pitches[(all_pitches.home_team == \"NYM\") & (all_pitches.away_team == \"NYY\") & (all_pitches.game_date == \"2020-08-30\")].index\n",
    "all_pitches.loc[strange_games_XXVVII, \"home_team\"] = \"NYY\"\n",
    "all_pitches.loc[strange_games_XXVVII, \"away_team\"] = \"NYM\"\n",
    "\n",
    "strange_games_XXVVIII = all_pitches[(all_pitches.home_team == \"WSH\") & (all_pitches.away_team == \"ATL\") & (all_pitches.game_date == \"2020-09-4\")].index\n",
    "all_pitches.loc[strange_games_XXVVIII, \"home_team\"] = \"ATL\"\n",
    "all_pitches.loc[strange_games_XXVVII, \"away_team\"] = \"WSH\"\n",
    "\n",
    "strange_games_XXVVIV = all_pitches[(all_pitches.home_team == \"NYY\") & (all_pitches.away_team == \"BAL\") & (all_pitches.game_date == \"2020-09-04\")].index\n",
    "all_pitches.loc[strange_games_XXVVIV, \"home_team\"] = \"BAL\"\n",
    "all_pitches.loc[strange_games_XXVVIV, \"away_team\"] = \"NYY\"\n",
    "\n",
    "strange_games_XXVVV = all_pitches[(all_pitches.home_team == \"TOR\") & (all_pitches.away_team == \"BOS\") & (all_pitches.game_date == \"2020-09-04\")].index\n",
    "all_pitches.loc[strange_games_XXVVV, \"home_team\"] = \"BOS\"\n",
    "all_pitches.loc[strange_games_XXVVV, \"away_team\"] = \"TOR\"\n",
    "\n",
    "strange_games_XXVVVI = all_pitches[(all_pitches.home_team == \"DET\") & (all_pitches.away_team == \"MIN\") & (all_pitches.game_date == \"2020-09-04\")].index\n",
    "all_pitches.loc[strange_games_XXVVVI, \"home_team\"] = \"MIN\"\n",
    "all_pitches.loc[strange_games_XXVVVI, \"away_team\"] = \"DET\"\n",
    "\n",
    "strange_games_XXVVVII = all_pitches[(all_pitches.home_team == \"CIN\") & (all_pitches.away_team == \"PIT\") & (all_pitches.game_date == \"2020-09-04\")].index\n",
    "all_pitches.loc[strange_games_XXVVVII, \"home_team\"] = \"PIT\"\n",
    "all_pitches.loc[strange_games_XXVVVII, \"away_team\"] = \"CIN\"\n",
    "\n",
    "strange_games_XXVVVIII = all_pitches[(all_pitches.home_team == \"HOU\") & (all_pitches.away_team == \"LAA\") & (all_pitches.game_date == \"2020-09-05\")].index\n",
    "all_pitches.loc[strange_games_XXVVVIII, \"home_team\"] = \"LAA\"\n",
    "all_pitches.loc[strange_games_XXVVVIII, \"away_team\"] = \"HOU\"\n",
    "\n",
    "strange_games_XXVVVIV = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"CHC\") & (all_pitches.game_date == \"2020-09-05\")].index\n",
    "all_pitches.loc[strange_games_XXVVVIV, \"home_team\"] = \"CHC\"\n",
    "all_pitches.loc[strange_games_XXVVVIV, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_L = all_pitches[(all_pitches.home_team == \"HOU\") & (all_pitches.away_team == \"OAK\") & (all_pitches.game_date == \"2020-09-08\")].index\n",
    "all_pitches.loc[strange_games_L, \"home_team\"] = \"OAK\"\n",
    "all_pitches.loc[strange_games_L, \"away_team\"] = \"HOU\"\n",
    "\n",
    "strange_games_LI = all_pitches[(all_pitches.home_team == \"BOS\") & (all_pitches.away_team == \"PHI\") & (all_pitches.game_date == \"2020-09-08\")].index\n",
    "all_pitches.loc[strange_games_LI, \"home_team\"] = \"PHI\"\n",
    "all_pitches.loc[strange_games_LI, \"away_team\"] = \"BOS\"\n",
    "\n",
    "strange_games_LII = all_pitches[(all_pitches.home_team == \"MIN\") & (all_pitches.away_team == \"STL\") & (all_pitches.game_date == \"2020-09-08\")].index\n",
    "all_pitches.loc[strange_games_LII, \"home_team\"] = \"STL\"\n",
    "all_pitches.loc[strange_games_LII, \"away_team\"] = \"MIN\"\n",
    "\n",
    "strange_games_LIII = all_pitches[(all_pitches.home_team == \"DET\") & (all_pitches.away_team == \"STL\") & (all_pitches.game_date == \"2020-09-10\")].index\n",
    "all_pitches.loc[strange_games_LIII, \"home_team\"] = \"STL\"\n",
    "all_pitches.loc[strange_games_LIII, \"away_team\"] = \"DET\"\n",
    "\n",
    "strange_games_LIV = all_pitches[(all_pitches.home_team == \"PHI\") & (all_pitches.away_team == \"MIA\") & (all_pitches.game_date == \"2020-09-11\")].index\n",
    "all_pitches.loc[strange_games_LIV, \"home_team\"] = \"MIA\"\n",
    "all_pitches.loc[strange_games_LIV, \"away_team\"] = \"PHI\"\n",
    "\n",
    "strange_games_LV = all_pitches[(all_pitches.home_team == \"BAL\") & (all_pitches.away_team == \"NYY\") & (all_pitches.game_date == \"2020-09-11\")].index\n",
    "all_pitches.loc[strange_games_LV, \"home_team\"] = \"NYY\"\n",
    "all_pitches.loc[strange_games_LV, \"away_team\"] = \"BAL\"\n",
    "\n",
    "strange_games_LVI = all_pitches[(all_pitches.home_team == \"OAK\") & (all_pitches.away_team == \"TEX\") & (all_pitches.game_date == \"2020-09-12\")].index\n",
    "all_pitches.loc[strange_games_LVI, \"home_team\"] = \"TEX\"\n",
    "all_pitches.loc[strange_games_LVI, \"away_team\"] = \"OAK\"\n",
    "\n",
    "strange_games_LVII = all_pitches[(all_pitches.home_team == \"PHI\") & (all_pitches.away_team == \"MIA\") & (all_pitches.game_date == \"2020-09-13\")].index\n",
    "all_pitches.loc[strange_games_LVII, \"home_team\"] = \"MIA\"\n",
    "all_pitches.loc[strange_games_LVII, \"away_team\"] = \"PHI\"\n",
    "\n",
    "strange_games_LVIII = all_pitches[(all_pitches.home_team == \"SF\") & (all_pitches.away_team == \"SD\") & (all_pitches.game_date == \"2020-09-13\")].index\n",
    "all_pitches.loc[strange_games_LVII, \"home_team\"] = \"SD\"\n",
    "all_pitches.loc[strange_games_LVII, \"away_team\"] = \"SF\"\n",
    "\n",
    "strange_games_LIX = all_pitches[(all_pitches.home_team == \"PIT\") & (all_pitches.away_team == \"CIN\") & (all_pitches.game_date == \"2020-09-14\")].index\n",
    "all_pitches.loc[strange_games_LIX, \"home_team\"] = \"CIN\"\n",
    "all_pitches.loc[strange_games_LIX, \"away_team\"] = \"PIT\"\n",
    "\n",
    "strange_games_LX = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2020-09-14\")].index\n",
    "all_pitches.loc[strange_games_LX, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_LX, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_LXI = all_pitches[(all_pitches.home_team == \"OAK\") & (all_pitches.away_team == \"SEA\") & (all_pitches.game_date == \"2020-09-14\")].index\n",
    "all_pitches.loc[strange_games_LXI, \"home_team\"] = \"SEA\"\n",
    "all_pitches.loc[strange_games_LXI, \"away_team\"] = \"OAK\"\n",
    "\n",
    "strange_games_LXII = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"MIL\") & (all_pitches.game_date == \"2020-09-16\")].index\n",
    "all_pitches.loc[strange_games_LXII, \"home_team\"] = \"MIL\"\n",
    "all_pitches.loc[strange_games_LXII, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_LXIII = all_pitches[(all_pitches.home_team == \"TB\") & (all_pitches.away_team == \"BAL\") & (all_pitches.game_date == \"2020-09-17\")].index\n",
    "all_pitches.loc[strange_games_LXIII, \"home_team\"] = \"BAL\"\n",
    "all_pitches.loc[strange_games_LXIII, \"away_team\"] = \"TB\"\n",
    "\n",
    "strange_games_LXIV = all_pitches[(all_pitches.home_team == \"WSH\") & (all_pitches.away_team == \"MIA\") & (all_pitches.game_date == \"2020-09-18\")].index\n",
    "all_pitches.loc[strange_games_LXIV, \"home_team\"] = \"MIA\"\n",
    "all_pitches.loc[strange_games_LXIV, \"away_team\"] = \"WSH\"\n",
    "\n",
    "strange_games_LXV = all_pitches[(all_pitches.home_team == \"TOR\") & (all_pitches.away_team == \"PHI\") & (all_pitches.game_date == \"2020-09-18\")].index\n",
    "all_pitches.loc[strange_games_LXV, \"home_team\"] = \"PHI\"\n",
    "all_pitches.loc[strange_games_LXV, \"away_team\"] = \"TOR\"\n",
    "\n",
    "strange_games_LXVI = all_pitches[(all_pitches.home_team == \"STL\") & (all_pitches.away_team == \"PIT\") & (all_pitches.game_date == \"2020-09-18\")].index\n",
    "all_pitches.loc[strange_games_LXVI, \"home_team\"] = \"PIT\"\n",
    "all_pitches.loc[strange_games_LXVI, \"away_team\"] = \"STL\"\n",
    "\n",
    "strange_games_LXVII = all_pitches[(all_pitches.home_team == \"WSH\") & (all_pitches.away_team == \"MIA\") & (all_pitches.game_date == \"2020-09-20\")].index\n",
    "all_pitches.loc[strange_games_LXVII, \"home_team\"] = \"MIA\"\n",
    "all_pitches.loc[strange_games_LXVII, \"away_team\"] = \"WSH\"\n",
    "\n",
    "strange_games_LXVIII = all_pitches[(all_pitches.home_team == \"PHI\") & (all_pitches.away_team == \"WSH\") & (all_pitches.game_date == \"2020-09-22\")].index\n",
    "all_pitches.loc[strange_games_LXVIII, \"home_team\"] = \"WSH\"\n",
    "all_pitches.loc[strange_games_LXVIII, \"away_team\"] = \"PHI\"\n",
    "\n",
    "strange_games_LXIX = all_pitches[(all_pitches.home_team == \"COL\") & (all_pitches.away_team == \"ARI\") & (all_pitches.game_date == \"2020-09-25\")].index\n",
    "all_pitches.loc[strange_games_LXIX, \"home_team\"] = \"ARI\"\n",
    "all_pitches.loc[strange_games_LXIX, \"away_team\"] = \"COL\"\n",
    "\n",
    "strange_games_LXX = all_pitches[(all_pitches.home_team == \"SD\") & (all_pitches.away_team == \"SF\") & (all_pitches.game_date == \"2020-09-25\")].index\n",
    "all_pitches.loc[strange_games_LXX, \"home_team\"] = \"SF\"\n",
    "all_pitches.loc[strange_games_LXX, \"away_team\"] = \"SD\"\n",
    "\n",
    "strange_games_LXXI = all_pitches[(all_pitches.home_team == \"MIL\") & (all_pitches.away_team == \"STL\") & (all_pitches.game_date == \"2020-09-25\")].index\n",
    "all_pitches.loc[strange_games_LXXI, \"home_team\"] = \"STL\"\n",
    "all_pitches.loc[strange_games_LXXI, \"away_team\"] = \"MIL\"\n",
    "\n",
    "strange_games_LXXII = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"OAK\") & (all_pitches.game_date == \"2020-09-26\")].index\n",
    "all_pitches.loc[strange_games_LXXII, \"home_team\"] = \"OAK\"\n",
    "all_pitches.loc[strange_games_LXXII, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXIII = all_pitches[(all_pitches.home_team == \"NYM\") & (all_pitches.away_team == \"WSH\") & (all_pitches.game_date == \"2020-09-26\")].index\n",
    "all_pitches.loc[strange_games_LXXIII, \"home_team\"] = \"WSH\"\n",
    "all_pitches.loc[strange_games_LXXIII, \"away_team\"] = \"NYM\"\n",
    "\n",
    "strange_games_LXXIV = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SF\") & (all_pitches.game_date == \"2020-09-16\")].index\n",
    "all_pitches.loc[strange_games_LXXIV, \"home_team\"] = \"SF\"\n",
    "all_pitches.loc[strange_games_LXXIV, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXV = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SF\") & (all_pitches.game_date == \"2020-09-17\")].index\n",
    "all_pitches.loc[strange_games_LXXV, \"home_team\"] = \"SF\"\n",
    "all_pitches.loc[strange_games_LXXV, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXVI = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SD\") & (all_pitches.game_date == \"2020-09-18\")].index\n",
    "all_pitches.loc[strange_games_LXXVI, \"home_team\"] = \"SD\"\n",
    "all_pitches.loc[strange_games_LXXVI, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXVII = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SD\") & (all_pitches.game_date == \"2020-09-19\")].index\n",
    "all_pitches.loc[strange_games_LXXVII, \"home_team\"] = \"SD\"\n",
    "all_pitches.loc[strange_games_LXXVII, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXVIII = all_pitches[(all_pitches.home_team == \"SEA\") & (all_pitches.away_team == \"SD\") & (all_pitches.game_date == \"2020-09-20\")].index\n",
    "all_pitches.loc[strange_games_LXXVIII, \"home_team\"] = \"SD\"\n",
    "all_pitches.loc[strange_games_LXXVIII, \"away_team\"] = \"SEA\"\n",
    "\n",
    "strange_games_LXXXI = all_pitches[(all_pitches.home_team == \"WSH\") & (all_pitches.away_team == \"TOR\") & ((all_pitches.game_date == \"2021-04-27\")|(all_pitches.game_date == \"2021-04-27\"))].index\n",
    "all_pitches.loc[strange_games_LXXXI, \"home_team\"] = \"TOR\"\n",
    "all_pitches.loc[strange_games_LXXXI, \"away_team\"] = \"WSH\"\n",
    "\n",
    "strange_games_LXXIX = all_pitches[(all_pitches.home_team == \"TOR\") & (all_pitches.away_team == \"LAA\") & (all_pitches.game_date == \"2021-08-10\")].index\n",
    "all_pitches.loc[strange_games_LXXIX, \"home_team\"] = \"LAA\"\n",
    "all_pitches.loc[strange_games_LXXIX, \"away_team\"] = \"TOR\"\n",
    "\n",
    "strange_games_LXXX = all_pitches[(all_pitches.home_team == \"OAK\") & (all_pitches.away_team == \"DET\") & (all_pitches.game_date == \"2022-05-10\")].index\n",
    "all_pitches.loc[strange_games_LXXX, \"home_team\"] = \"DET\"\n",
    "all_pitches.loc[strange_games_LXXX, \"away_team\"] = \"OAK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264507f3-ce58-42fe-800f-9739dd1f560f",
   "metadata": {},
   "source": [
    "### Filter all pitches to only those resulting in a relavant play, and clean to only columns we might use later on\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638a714e-a579-4b4e-9b1d-15ac6b8be917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_plays_by_hand_combo(all_pitches):\n",
    "    # Filter down to only regular season games\n",
    "    all_pitches = all_pitches[all_pitches.game_type == \"R\"]\n",
    "\n",
    "    # Convert the datetime game_date to a string formatted as YYYY-MM-DD, and sort the df on the column to make sure everything is in order\n",
    "    all_pitches.game_date = all_pitches.game_date.apply(lambda x: str(x).split(\" \")[0])\n",
    "    all_pitches = all_pitches.sort_values(by = \"game_date\", ascending = True)\n",
    "\n",
    "    # Filter all pitches to only those with an event\n",
    "    all_plays = all_pitches[pd.isna(all_pitches.events) == False]\n",
    "\n",
    "    # Filter all pitches with an event to only those types we care about\n",
    "    relevant_plays = all_plays[all_plays.events.isin(relevant_play_types)]\n",
    "\n",
    "    # Clean all the relevant plays and sort by date\n",
    "    final_plays = relevant_plays[relevant_batting_columns].sort_values(by = \"game_date\").reset_index(drop = True)\n",
    "\n",
    "    # Add a new column that groups all the event types into eventual Y labels\n",
    "    final_plays[\"play_type\"] = final_plays.events.apply(lambda x: play_type_dict[x])\n",
    "\n",
    "    # Finally, insert a new 'type counter' coulumn that will be used repeatedly for calculating rolling stats\n",
    "    final_plays[\"type_counter\"] = 1\n",
    "\n",
    "    all_plays = final_plays.copy()\n",
    "    \n",
    "    # Set up a Dict to hold all pitches, divided by the pitbat combo\n",
    "    all_plays_by_hand_combo = {\"RR\":{}, \"RL\":{}, \"LR\":{}, \"LL\":{}}\n",
    "\n",
    "    # Split all plays on combo of batter/pitcher handedness before placing into the dictionary\n",
    "    for pitbat_combo in all_plays_by_hand_combo.keys(): \n",
    "        pitbat_df = all_plays[(all_plays.stand == pitbat_combo[0]) & (all_plays.p_throws == pitbat_combo[0])].copy().reset_index(drop=True)\n",
    "        all_plays_by_hand_combo[pitbat_combo]= pitbat_df\n",
    "        \n",
    "    # Attatch the full weather description to each individual pitch\n",
    "    for pitbat_combo in all_plays_by_hand_combo.keys(): \n",
    "        #all_plays_by_hand_combo[pitbat_combo][\"full_weather\"] = all_plays_by_hand_combo[pitbat_combo].apply(lambda x: weather[(weather.date.values == x.game_date) & (weather.home_team.values == weather_name_conversions[x.home_team])].weather.iloc[0] if len(weather[(weather.date.values == x.game_date) & (weather.home_team.values == weather_name_conversions[x.home_team])]) > 0 else weather[(weather.date.values == x.game_date) & (weather.home_team.values == weather_name_conversions[x.away_team])].weather.iloc[0], axis = 1)\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"full_weather\"] = all_plays_by_hand_combo[pitbat_combo].apply(lambda x: weather[(weather.date.values == x.game_date) & ((weather.home_team.values == weather_name_conversions[x.home_team])|((weather.home_team.values == weather_name_conversions[x.away_team])))].weather.iloc[0], axis = 1)\n",
    "    \n",
    "                                                                                                            \n",
    "    # Break up the full weather info into temp, wind speed, and wind direction seperately\n",
    "    for pitbat_combo in all_plays_by_hand_combo.keys():\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"temprature\"] = all_plays_by_hand_combo[pitbat_combo].full_weather.apply(lambda x: int(x.split(\": \")[1].split(\"Â°\")[0]))\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"wind_speed\"] = all_plays_by_hand_combo[pitbat_combo].full_weather.apply(lambda x: int(x.split(\"Wind \")[1].split(\"mph\")[0]) if \"Wind\" in x else 0)\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"wind_direction\"] = all_plays_by_hand_combo[pitbat_combo].full_weather.apply(get_wind_direction)\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"wind_direction\"] = all_plays_by_hand_combo[pitbat_combo].wind_direction.apply(lambda x: x.split(\", \")[0] if x != None else x)\n",
    "        \n",
    "        \n",
    "    return all_plays_by_hand_combo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51516dfb-6aa7-42d5-b8b4-85a062b96ea9",
   "metadata": {},
   "source": [
    "### Attatch Ballpark Info to the Pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398a9419-4f2e-4803-bd38-088a494be958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine our first three years of data (maintaining hand combo seperation) to be the full initial data\n",
    "def attach_ballpark_info(all_plays_by_hand_combo, ballpark_info=ballpark_info):\n",
    "    \"\"\"\n",
    "    Function attatches the correct ballpark name to individual pitches\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    all_plays_by_hand_combo: DataFrame\n",
    "        A cleaned DataFrame of pitches, including columns for the date and the home team\n",
    "    \n",
    "    ballpark_info: DataFrame\n",
    "        A DataFrame of Ballpark information including columns for the team that plays there and the start/end date that the team played there\n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Dataframe\n",
    "        A DataFrame of all pitches divided by pitbat combo, now including a column for the ballpark\n",
    "    \"\"\"\n",
    "    \n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Cleaning Raw Pitches - Attaching Ballpark Info\", pitbat_combo)\n",
    "        df = all_plays_by_hand_combo[pitbat_combo]\n",
    "        \n",
    "        # Create a column for the ballpark based on the date and home_team of each pitch\n",
    "        df[\"ballpark\"] = df.apply(lambda x: ballpark_info[(ballpark_info.Team.values == x.home_team) & (ballpark_info[\"End Date\"].values > int(x.game_date.split(\"-\")[0]))].Stadium.iloc[0],axis=1)\n",
    "        \n",
    "        clear_output(wait = False)\n",
    "    \n",
    "    return all_plays_by_hand_combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce929f94-c283-4f92-abd0-268bde13050c",
   "metadata": {},
   "source": [
    "## Determining Weather/Park Impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ed311-fb8f-4fa4-84a9-298125e7ee4f",
   "metadata": {},
   "source": [
    "### Calculate Game Play Shares (Yfor weather regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc85937-510c-4fe6-9984-e0cb43b42756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, calculate within the game (and pitbat_combo), the share of the plays that were each play type\n",
    "def calculate_game_play_shares(all_plays_by_hand_combo):\n",
    "    \"\"\"\n",
    "    Function calculates the game play share for individual plays and inserts a column of the shares into all relevant all plays dfs\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    all_plays_by_hand_combo: DataFrame\n",
    "        A cleaned DataFrame of pitches, including columns for the play type of each play and the game_pk for each game\n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Dataframe\n",
    "        A DataFrame of all pitches divided by pitbat combo, now including a column for the game play share of each play type within each different game\n",
    "    \"\"\"\n",
    "\n",
    "    game_play_shares = {x:{} for x in hand_combos}\n",
    "    n = 0\n",
    "\n",
    "    for pitbat_combo in all_plays_by_hand_combo:\n",
    "        full_df = all_plays_by_hand_combo[pitbat_combo].copy()\n",
    "        # For each game\n",
    "        for game in full_df.game_pk.unique():\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "            # Slice all pitches to just the individual game\n",
    "            game_df = full_df[full_df.game_pk.values == game].copy()\n",
    "            total_games = len(game_df)\n",
    "            \n",
    "            # Calculate the total number of the play in the specific game by rolling within each play type\n",
    "            game_df[\"type_counter\"] = game_df.groupby(by = \"play_type\").cumsum().type_counter \n",
    "            game_df = game_df.groupby(by = \"play_type\").max()\n",
    "\n",
    "            # Calculate the play share for each play type within the specific game by dividing the rolled counter by the total plays in the game\n",
    "            game_df[\"play_share\"]  = game_df.type_counter/total_games \n",
    "\n",
    "            # Insert the game play shares for the specific game into a larger dictionary holder for later reference\n",
    "            game_play_shares[pitbat_combo][game] = game_df\n",
    "\n",
    "            # Update the counter and reprint to inform user of the current position\n",
    "            if n%1000 == 0:\n",
    "                print(\"Calculating The Play Share by Play Type for Each Game. There are {}K Instances Remaining\".format(round((sum([len(all_plays_by_hand_combo[x].game_pk.unique()) for x in hand_combos])-n)/1000),6))\n",
    "            n+= 1\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "\n",
    "    # Add a column in the all plays dfs that is the game play share for the specific game and play type of each play\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Inserting Play Shares by Play Type from Each Game To the All Pitches Data Set. There are {} Pitbat Combos Remaining\".format(len(hand_combos) - hand_combos.index(pitbat_combo)))\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        # The if statement in the apply below is used to catch the rare case (n=2 PA in 2018-2019) where the game_pk = <NA>. When this happens the play associated is in the game itself, but does not make it into the \n",
    "        # game_play_shares dict which throws and error when pulling the play type from the dictionary\n",
    "        all_plays_by_hand_combo[pitbat_combo][\"game_play_share\"] = all_plays_by_hand_combo[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][x.game_pk].loc[x.play_type].play_share if x.play_type in game_play_shares[pitbat_combo][x.game_pk].index else 0, axis = 1)\n",
    "            \n",
    "            \n",
    "    return all_plays_by_hand_combo\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32a1eb-a0d9-4929-b212-81ffe4e7148e",
   "metadata": {},
   "source": [
    "### Cleaning for Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc5f36d-2ce2-46e9-81ff-d8d281380f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wind_direction(all_plays_by_hand_combo, wind_column = \"wind_direction\"):\n",
    "    \"\"\"\n",
    "    Function converts the wind columns in all_plays_by_hand_combo from a categorical wind direction (string) and numeric wind speed into OHE columns representing\n",
    "    both wind direction and wind speed\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    all_plays_by_hand_combo: DataFrame\n",
    "        A cleaned DataFrame of pitches, including columns for the wind direction and wind speed of each play\n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Dataframe\n",
    "        A DataFrame of all pitches divided by pitbat combo, now including a set of columns, one each for each possible wind direction, with values of the wind\n",
    "        speed in that direction\n",
    "    \"\"\"\n",
    "    \n",
    "    # When wind speed is 0, the direction is automatically listed as \"in\" --> convert it to \"zero\" to differentiate\n",
    "    ind = all_plays_by_hand_combo[all_plays_by_hand_combo.wind_speed.values == 0].index\n",
    "    all_plays_by_hand_combo.loc[ind, \"wind_direction\"] = \"zero\"\n",
    "    \n",
    "    # Use pd.get_dummies to One Hot Encode the wind direction as binary columns\n",
    "    wind_columns = pd.get_dummies(wind_column, columns=['categorical_column', ])\n",
    "    wind_columns = pd.concat([all_plays_by_hand_combo, wind_columns], axis = 1)\n",
    "    \n",
    "    # Finally multiply the binary wind direction columns by the wind speed to get the final wind speed in the correct direction\n",
    "    for column in wind_columns.columns[-5:]:\n",
    "        wind_columns[column] = wind_columns[column] * wind_columns[\"wind_speed\"]\n",
    "    \n",
    "    return wind_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c4bf72-24de-47d6-828e-d6de500ccd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weather_regression(all_plays_by_hand_combo):\n",
    "    \"\"\" INSERT FUNCTION INFORMATION\"\"\"\n",
    "    \n",
    "    weather_training_data = {x:{} for x in hand_combos}\n",
    "    l =  []\n",
    "\n",
    "    # Clean the data to fit what we will need for weather regressions\n",
    "    for pitbat_combo in hand_combos:  \n",
    "        weather_training_df = all_plays_by_hand_combo[pitbat_combo].copy()\n",
    "        \n",
    "        # Remove any games with a month lower than 5 (May)\n",
    "        weather_training_df = weather_training_df[weather_training_df.game_date.apply(lambda x: int(x.split(\"-\")[1])) >=5]\n",
    "        \n",
    "        # Filter to only the columns we will need for the weather regressions\n",
    "        weather_training_data[pitbat_combo] = weather_training_df[[\"game_pk\",\"game_date\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]\n",
    "        \n",
    "        # Group the weather training data by game and play type to get the game_play_share for each play type for each game\n",
    "        weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo].groupby(by = [\"game_pk\", \"play_type\"]).last().reset_index()\n",
    "\n",
    "    # As the only plays in our data are types that happened in games, fill in all the missing play types for each game with a game_share of 0 for that play type\n",
    "    play_types = set(numpy.concatenate([all_plays_by_hand_combo[pitbat].play_type.value_counts().index for pitbat in hand_combos]))\n",
    "    n = 0\n",
    "    for pitbat_combo in hand_combos:\n",
    "        for game in weather_training_data[pitbat_combo].game_pk.unique():\n",
    "            n += 1\n",
    "            if n%500 == 0:\n",
    "                print(\"Filling in the Missing Values for Probability Vectors. There are {}K Instances Remaining\".format(round((sum([len(weather_training_data[x].game_pk.unique()) for x in hand_combos])-n)/1000),6))\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "            # Slice all plays to a specific game\n",
    "            df = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].game_pk.values == game].copy()\n",
    "            if len(df) < len(play_types): # Check if there are any missing plays and if so, determine how many and which ones\n",
    "                missing_plays = [play for play in play_types if play not in df.play_type.values]\n",
    "                num_missing_plays = len(missing_plays)\n",
    "                \n",
    "                ###weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.Series({\"game_pk\":game, \"game_date\":df.iloc[0].game_date, \"play_type\":play, \"temprature\":df.iloc[0].temprature, \"wind_speed\":df.iloc[0].wind_speed, \"wind_direction\":df.iloc[0].wind_direction, \"game_share_delta\":all_training_data[pitbat_combo][(all_training_data[pitbat_combo].game_date < df.iloc[0].game_date) & (all_training_data[pitbat_combo].play_type == play)].iloc[-1].eod_play_share * -1}), ignore_index = True)\n",
    "                # Pull all the game info for easy reference while inserting\n",
    "                game_info = df.iloc[0]\n",
    "                \n",
    "                # Build and insert into all pitches a DataFrame of each missing play from each game with the basic game info for the weather regression, including a game play share of 0\n",
    "                weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.DataFrame({\"game_pk\":[game]*num_missing_plays, \"game_date\":[game_info.game_date]*num_missing_plays, \"play_type\":missing_plays, \"temprature\":[game_info.temprature]*num_missing_plays, \"wind_speed\":[game_info.wind_speed]*num_missing_plays, \"wind_direction\":[game_info.wind_direction]*num_missing_plays, \"game_play_share\":[0]*num_missing_plays}), ignore_index=True)\n",
    "    \n",
    "    \n",
    "    clear_output(wait = False)\n",
    "\n",
    "    # Final edits to weather training data\n",
    "    for pitbat_combo in hand_combos:\n",
    "        # Filter down to only the relevant columns for the weather regression\n",
    "        weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo][[\"game_pk\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]\n",
    "\n",
    "        # Square temprature to use in the regression because I believe it behaves this way\n",
    "        weather_training_data[pitbat_combo][\"temprature_squared\"] = weather_training_data[pitbat_combo][\"temprature\"].apply(lambda x: x**2)\n",
    "\n",
    "        # Encode the wind directions and calculate final wind speeds in the direction\n",
    "        weather_training_data[pitbat_combo] = convert_wind_direction(weather_training_data[pitbat_combo], weather_training_data[pitbat_combo].wind_direction)\n",
    "\n",
    "\n",
    "    \n",
    "    return weather_training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f931-a022-42d2-80e2-3cbbe32e48e5",
   "metadata": {},
   "source": [
    "### Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302a46d2-cae7-4475-a92a-c2174f89a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_regress(weather_training_data):\n",
    "    \"\"\"\n",
    "    Function regresses the percent of plays in a game that are each play type on the underlying weather condition to determine\n",
    "    the impact of weather conditions on the play type distribution. This will be used in neutralizing batting stats for use in \n",
    "    modeling.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    weather_training_data: DataFrame\n",
    "        A DataFrame that contains the underlying weather conditions of each play in addition to the game information. This is the direct\n",
    "        output of the prepare_weather_regressions function.\n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Tuple(DataFrame, Dictionary)\n",
    "        A DataFrame of the original weather_training_data for use later on.\n",
    "        A Nested Dictionary that contains the weather coefficients for each weather datapoint for each play type\n",
    "    \"\"\"\n",
    "        \n",
    "    weather_coefficients = {}\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        weather_coefficients[pitbat_combo] = {}\n",
    "        \n",
    "        # Segment to only the specific play type for each play type before regressing on the weather info\n",
    "        for play_type in weather_training_data[pitbat_combo].play_type.unique():\n",
    "            PAs = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].play_type == play_type]\n",
    "\n",
    "            # Remove outliers for game_share_delta, most of which are caused by low pitbat_combo sample sizes in games\n",
    "            PAs = PAs[(np.abs(stats.zscore(PAs.game_play_share)) < 3)]\n",
    "\n",
    "            # Create 2 sets of x data, with and without squaring temprature\n",
    "            x = PAs[PAs.columns[np.r_[2:4, 6:11]]] #grab only the weather related columns and then get rid of regular temprature\n",
    "\n",
    "            x_sq = x[[col for col in x.columns if col != \"temprature\" and col != \"wind_speed\"]]\n",
    "\n",
    "            y = PAs.game_play_share\n",
    "\n",
    "            # Regress the temprature squared dataset on game_share_delta\n",
    "            lin_sq = LinearRegression(fit_intercept = True)\n",
    "            lin_sq.fit(x_sq, y)\n",
    "\n",
    "            weather_coefficients[pitbat_combo][play_type] = {\"intercept\":lin_sq.intercept_, \"temprature_sq\":lin_sq.coef_[0], \"wind_ltr\":lin_sq.coef_[1],\n",
    "                                                     \"wind_rtl\":lin_sq.coef_[2], \"wind_in\":lin_sq.coef_[3], \"wind_out\":lin_sq.coef_[4]}\n",
    "            \n",
    "    return(weather_training_data, weather_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608cb28-ea92-4716-82dc-8a43099902cd",
   "metadata": {},
   "source": [
    "### Calculating Park Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4195106a-6e17-480e-bf0b-e746187bd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_park_factors(all_plays_by_hand_combo):\n",
    "    \"\"\"\n",
    "    Function calculated the park factor for each ballpark for each play type based on the percentage that the play type occurs in\n",
    "    the park vs not in the park\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    all_plays_by_hand_combo: DataFrame\n",
    "        A DataFrame that contains the all plays segmented by hand combo, and also includes the ballpark in which the play occured.\n",
    "        \n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Tuple(DataFrame, Dictionary)\n",
    "        The original all_plays_by_hand_combbo DataFrame for later use\n",
    "        A Nested Dictionary that contains the park factors for each ballpark and each play\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    park_factors_dict = {}\n",
    "    print(\"Calculating Ballpark Factors\")\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        park_factors_dict[pitbat_combo] = {}\n",
    "        \n",
    "        # For each ballpark, segment all our plays into 2 DataFrames. 1 for all plays at the park and 1 or all plays not at the park\n",
    "        for ballpark in all_plays_by_hand_combo[\"RR\"].ballpark.unique():\n",
    "            park_factors_dict[pitbat_combo][ballpark] = {}\n",
    "            at_park_df = all_plays_by_hand_combo[pitbat_combo][(all_plays_by_hand_combo[pitbat_combo].ballpark == ballpark)].copy()\n",
    "            not_at_park_df = all_plays_by_hand_combo[pitbat_combo][(all_plays_by_hand_combo[pitbat_combo].ballpark != ballpark)].copy()\n",
    "\n",
    "            # For each play type, calculate the percentage it occurs at in the park and out of the park\n",
    "            for play_type in all_plays_by_hand_combo[\"RR\"].play_type.unique():\n",
    "                at_park_rate = len(at_park_df[at_park_df.play_type == play_type])/len(at_park_df)\n",
    "                not_at_park_rate = len(not_at_park_df[not_at_park_df.play_type == play_type])/len(not_at_park_df)\n",
    "\n",
    "                try:\n",
    "                    park_factor = at_park_rate/not_at_park_rate\n",
    "                except:\n",
    "                    park_factor = \"n/a\"\n",
    "                \n",
    "                # Insert the park factors into a dictionary\n",
    "                park_factors_dict[pitbat_combo][ballpark][play_type] = park_factor\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return (all_plays_by_hand_combo, park_factors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32878f77-8cea-4145-9f94-456977256e5a",
   "metadata": {},
   "source": [
    "## Neutralizing Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2cd011-8050-49b6-8514-37ba1f0a5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize_stats(all_plays_by_hand_combo, weather_coefficients, park_factors_dict, is_dump=False):\n",
    "    \"\"\"\n",
    "    Function uses the weather coefficients and park factors to determine an 'impact' for each individual play in the date based on its\n",
    "    actual weather info and park.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    all_plays_by_hand_combo: DataFrame\n",
    "        A DataFrame that contains the all plays segmented by hand combo, and also includes the ballpark in which the play occured and the real weather info.\n",
    "    \n",
    "    weather_cofficients: Dictionary\n",
    "        A nested dictionary of the weather coefficients by play. This is the direct output of the weather_regress function\n",
    "        \n",
    "    park_factors_dist: Dictionary\n",
    "        A nested dictionary of the park factors by play. This is the direct output of the calculate_park_factors function\n",
    "        \n",
    "    is_dump: Boolean\n",
    "        A boolean determining whether or not the pickle the factord batting stats upon calcualtion\n",
    "             \n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Tuple(DataFrame, Dictionary)\n",
    "        The original all_plays_by_hand_combbo DataFrame for later use\n",
    "        A Nested Dictionary that contains the park factors for each ballpark and each play\n",
    "        \n",
    "    \"\"\"\n",
    "    print(\"Neutralizing Batting Stats using Weather/Stadium Coefficients\")\n",
    "\n",
    "    factored_training_stats = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "\n",
    "        # Grab the relevant columns and games\n",
    "        df = all_plays_by_hand_combo[pitbat_combo][[\"game_pk\", \"game_date\", \"batter\", \"pitcher\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"ballpark\"]].copy()\n",
    "\n",
    "        # Add information for the actual weather and stadium impacts for each game\n",
    "        df = convert_wind_direction(df, df.wind_direction)\n",
    "        df[\"weather_expectation\"] = df.apply(lambda x: x[\"Left to Right\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_ltr\"] + x[\"Right to Left\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_rtl\"] +\n",
    "                                        x[\"in\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_in\"] + x[\"out\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_out\"] +\n",
    "                                        (x[\"temprature\"]**2) * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "\n",
    "        df[\"neutral_weather_expectation\"] = df.apply(lambda x: 72**2 * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "        df[\"weather_impact\"] = df.weather_expectation/df.neutral_weather_expectation\n",
    "        df[\"stadium_impact\"] = df.apply(lambda x: park_factors_dict[pitbat_combo][x.ballpark][x.play_type], axis=1)\n",
    "\n",
    "        # Multiply the weather and stadium impacts to get the total impact for the specific at-bat result\n",
    "        df[\"play_value\"] = 1\n",
    "        df[\"impact\"] = df.play_value * df.weather_impact * df.stadium_impact\n",
    "        df.play_value = 1/df.impact\n",
    "        \n",
    "        # Grab the final df that we will use for rolling stats\n",
    "        factored_training_stats[pitbat_combo] = df[[\"game_pk\", \"game_date\",\"ballpark\", \"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\", \"play_type\",\"impact\", \"play_value\"]]\n",
    "        \n",
    "        if is_dump == True:\n",
    "            factored_training_stats.to_pickle(\"/Users/jaredzirkes/Documents/GitHub/MLB-Simulation/training_batting_stats_with_factors.pkl\")\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return factored_training_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed13770-9311-45df-a82a-2ed3dbc0b67b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Calculate League Averages Over the Length of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdf65dc-6fea-4a88-898a-0a1058d343a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_league_averages(game_play_share_data):\n",
    "    league_average_plays_dict = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "        league_average_plays_dict[pitbat_combo] = {}\n",
    "        for play in plays:\n",
    "            df = game_play_share_data[pitbat_combo]\n",
    "            play_share = len(df[df.play_type == play])/len(df)\n",
    "            league_average_plays_dict[pitbat_combo][play] = play_share\n",
    "\n",
    "    return league_average_plays_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d08fc-e207-495f-a3fd-5f2fe431520e",
   "metadata": {},
   "source": [
    "## Roll Stats Daily To Get Final Odds Functions Training Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6f26938-005b-4dc6-9bc9-3722ca5b99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_factored_batting_stats(factored_batting_stats, min_periods = 0, is_dump=False):\n",
    "    \"\"\"\n",
    "    Function rolls batting stats and percentages across the tracked play types.\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    factored_batting_stats: DataFrame\n",
    "        A DataFrame that contains the all plays segmented by hand combo, and also includes a column with the calculated impact from the weather/ballpark. This is\n",
    "        the direct output on the neutralize_stats function\n",
    "    \n",
    "    rolling_period: Integer\n",
    "        The size of the time period in at-bats to roll stats by, as an accompanement to the monthly roll.\n",
    "        \n",
    "    min_periods: Integer\n",
    "        The minimum number of at-bats to consider when rolling stats. The rolling function will return None before this number is hit.\n",
    "        \n",
    "    is_dump: Boolean\n",
    "        A boolean determining whether or not the pickle the rolled factord batting stats upon calcualtion\n",
    "        \n",
    "    -----------------    \n",
    "   \n",
    "    Returns: Tuple(DataFrame, Dictionary)\n",
    "        The original all_plays_by_hand_combbo DataFrame for later use\n",
    "        A Nested Dictionary that contains the park factors for each ballpark and each play\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a rolling percentage for each play outcome for each batter and pitcher for each year \n",
    "    rolling_factored_batting_stats = {}\n",
    "    rolling_factored_pitching_stats = {}\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Rolling Batting and Pitching Stats {}\".format(pitbat_combo))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Set up dictionaries to house everything\n",
    "        rolling_factored_batting_stats[pitbat_combo] = {}\n",
    "        rolling_factored_pitching_stats[pitbat_combo] = {}\n",
    "\n",
    "        # Filter down to the stats for just the relevant hand combo and sort by game date for rolling\n",
    "        batter_df, pitcher_df = factored_batting_stats[pitbat_combo].copy(), factored_batting_stats[pitbat_combo].copy()\n",
    "        batter_df, pitcher_df = batter_df.sort_values(by = \"game_date\", ascending = True), pitcher_df.sort_values(by = \"game_date\", ascending = True)\n",
    "        batter_df[\"pitbat\"] = pitbat_combo\n",
    "        pitcher_df[\"pitbat\"] = pitbat_combo\n",
    "    \n",
    "        for play in plays:\n",
    "            # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "            batter_df[\"season_{}\".format(play)] = batter_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "            batter_df[\"month_{}\".format(play)] = batter_df[\"season_{}\".format(play)]\n",
    "            # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "            pitcher_df[\"season_{}\".format(play)] = pitcher_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "            pitcher_df[\"month_{}\".format(play)] = pitcher_df[\"season_{}\".format(play)]\n",
    "            \n",
    "        \n",
    "        # Roll batting stats on a season and montly basis\n",
    "        season_rolled_batter_df = batter_df.copy().groupby(by=\"batter\").rolling(window=504, closed=\"left\").sum().to_dict()\n",
    "        month_rolled_batter_df = batter_df.copy().groupby(by=\"batter\").rolling(window=75, closed=\"left\").sum().to_dict()\n",
    "        \n",
    "        \n",
    "\n",
    "        # Roll pitching stats on a season and montly basis\n",
    "        season_rolled_pitcher_df = pitcher_df.copy().groupby(by=\"pitcher\").rolling(window=504, closed=\"left\").sum().to_dict()\n",
    "        month_rolled_pitcher_df = pitcher_df.copy().groupby(by=\"pitcher\").rolling(window=75, closed=\"left\").sum().to_dict()\n",
    "        \n",
    "        for play in plays:\n",
    "            # Assign the rolled values from players' stats back to the pitcher and batter DataFrames by pulling the data from the dictionaries\n",
    "            batter_df[\"season_{}\".format(play)] = batter_df.apply(lambda x: season_rolled_batter_df[\"season_{}\".format(play)][(x.batter, x.name)], axis = 1)\n",
    "            batter_df[\"month_{}\".format(play)] = batter_df.apply(lambda x: month_rolled_batter_df[\"month_{}\".format(play)][(x.batter, x.name)], axis = 1)\n",
    "            \n",
    "            \n",
    "            pitcher_df[\"season_{}\".format(play)] = pitcher_df.apply(lambda x: season_rolled_pitcher_df[\"season_{}\".format(play)][(x.pitcher, x.name)], axis = 1)\n",
    "            pitcher_df[\"month_{}\".format(play)] = pitcher_df.apply(lambda x: month_rolled_pitcher_df[\"month_{}\".format(play)][(x.pitcher, x.name)], axis = 1)\n",
    "\n",
    "      \n",
    "        print(\"Repercentaging Rolled Batting Stats {}\".format(pitbat_combo))\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Repercentage factored batting stats percentage to sum to 1 because they don't necessarily after neutralization\n",
    "        season_columns = [\"season_{}\".format(play) for play in plays]\n",
    "        month_columns = [\"month_{}\".format(play) for play in plays]\n",
    "        batter_df[season_columns] = batter_df.apply(lambda row: pd.Series([row[f\"season_{play_type}\"]/row[season_columns].sum() for play_type in list(plays)]) if row[season_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "        batter_df[month_columns] = batter_df.apply(lambda row: pd.Series([row[f\"month_{play_type}\"]/row[month_columns].sum() for play_type in list(plays)]) if row[month_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "       \n",
    "        \n",
    "        print(\"Repercentaging Rolled Pitching Stats {}\".format(pitbat_combo))\n",
    "        # Repercentage factored pitching stats percentage to sum to 1 because they don't necessarily after neutralization\n",
    "        pitcher_df[season_columns] = pitcher_df.apply(lambda row: pd.Series([row[f\"season_{play_type}\"]/row[season_columns].sum() for play_type in list(plays)]) if row[season_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "        pitcher_df[month_columns] = pitcher_df.apply(lambda row: pd.Series([row[f\"month_{play_type}\"]/row[month_columns].sum() for play_type in list(plays)]) if row[month_columns].sum() > 0 else pd.Series([0 for play_type in plays]), axis=1)\n",
    "       \n",
    "        \n",
    "        \n",
    "#         pitcher_df[[\"season_{}\".format(play) for play in plays]] = pitcher_df.apply(lambda x: pd.Series([x[[\"season_{}\".format(play) for play in plays]][\"season_{}\".format(p)]/x[[\"season_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"season_{}\".format(p) for p in plays]].sum() > 0 else pd.Series([0 for p in plays]), axis=1)\n",
    "#         pitcher_df[[\"month_{}\".format(play) for play in plays]] = pitcher_df.apply(lambda x: pd.Series([x[[\"month_{}\".format(play) for play in plays]][\"month_{}\".format(p)]/x[[\"month_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"month_{}\".format(p) for p in plays]].sum() > 0 else pd.Series([0 for p in plays]), axis=1)\n",
    "  \n",
    "        # Place the final rolling factored batting stats DataFrame into the storage dictionary\n",
    "        rolling_factored_batting_stats[pitbat_combo] = batter_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "        rolling_factored_pitching_stats[pitbat_combo] = pitcher_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "    \n",
    "    if is_dump == True:\n",
    "        rolling_factored_pitching_stats.to_pickle(\"rolling_factored_pitching_stats.pkl\")\n",
    "        rolling_factored_batting_stats.to_pickle(\"rolling_factored_batting_stats.pkl\")\n",
    "        \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return {\"pitching_stats\":rolling_factored_pitching_stats, \"batting_stats\":rolling_factored_batting_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da57992e-c049-4b99-8ce7-a79ee2d61d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all the rolled individual player DataFrames out of the dictionary and into a large DataFrame that will be used for final training\n",
    "def stitch_individual_stats(rolling_factored_stats):\n",
    "\n",
    "    stitched_data = {}\n",
    "    \n",
    "    batting_dict = {}\n",
    "    pitching_dict = {}\n",
    "    \n",
    "    \n",
    "    df_batter = pd.concat([rolling_factored_stats[\"batting_stats\"][pitbat_combo] for pitbat_combo in hand_combos])\n",
    "    df_pitcher = pd.concat([rolling_factored_stats[\"pitching_stats\"][pitbat_combo] for pitbat_combo in hand_combos])\n",
    "        \n",
    "        \n",
    "    stitched_data[\"batting_stats\"] = df_batter\n",
    "    stitched_data[\"pitching_stats\"] = df_pitcher\n",
    "    \n",
    "    return stitched_data\n",
    "        \n",
    "              \n",
    "        \n",
    "        \n",
    "    \n",
    "#     training_stats = pd.DataFrame()\n",
    "#     pitching_holder = pd.DataFrame()\n",
    "\n",
    "#     for pitbat_combo in hand_combos:\n",
    "#         for batter in rolling_factored_stats[\"batting_stats\"][pitbat_combo]:\n",
    "            \n",
    "#             # Find each specific player df of unique pitbat combo, and batter\n",
    "#             df_b = rolling_factored_stats[\"batting_stats\"][pitbat_combo][batter]\n",
    "\n",
    "#             # We will through an error trying to look for games with dates less than our opening day, and there's\n",
    "#             # no need to stats for ~1 games anyways, so cut off the first 3 PAs of stats\n",
    "#             if len(df_b) > 3:\n",
    "#                 training_stats = training_stats.append(df_b[3:]) \n",
    "\n",
    "#         # Do the same thing for pitchers. Note we can leave in the first 3 PAs, because we will be simply joining with\n",
    "#         # the batters, so these PAs will get cut off then.\n",
    "#         for pitcher in rolling_factored_stats[\"pitching_stats\"][pitbat_combo]:\n",
    "#             df_p = rolling_factored_stats[\"pitching_stats\"][pitbat_combo][pitcher]\n",
    "#             pitching_holder = pitching_holder.append(df_p) \n",
    "\n",
    "#         clear_output(wait=False)\n",
    "\n",
    "#     if with_year_breaks == True:\n",
    "#         training_stats[\"year\"] = training_stats.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "#         pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "#     else:\n",
    "#         training_stats[\"year\"] = training_stats.game_date.apply(lambda x: \"All Years\")\n",
    "#         pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: \"All Years\")\n",
    "\n",
    "#     #pitching_holder = pitching_holder.rename(columns = {\"batter\":'pitcher'})\n",
    "\n",
    "#     clear_output(wait=False)\n",
    "    \n",
    "    return {\"pitching_stats\":pitching_holder, \"batting_stats\":training_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2df3808-a08f-4b90-9b1b-f8283a195e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the pitching probability vector to the training set by \"joining\" on the pitbat combo, year, and pitcher name, where the date is just less than the given PA.\n",
    "# Then reattatch the weather and ballpark info for that game\n",
    "def finalize_dataset(stitched_dataset, rolling_factored_stats, factored_batting_stats, stats_with_weather):\n",
    "    stitched_dataset[\"pitching_stats\"].columns = [\"pitcher_\" + col for col in stitched_dataset[\"pitching_stats\"].columns]\n",
    "    pitching_columns_to_add = [\"pitcher_season_{}\".format(play) for play in plays] + [\"pitcher_month_{}\".format(play) for play in plays]\n",
    "    stitched_dataset[\"batting_stats\"][pitching_columns_to_add] = stitched_dataset[\"pitching_stats\"][pitching_columns_to_add]\n",
    "    \n",
    "#     for play in plays:\n",
    "# #         print(\"Attaching the Batter Probability Vectors to the Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "# #         #stitched_dataset[\"batting_stats\"][\"b_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "# #         # stitched_dataset[\"batting_stats\"][\"b_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "       \n",
    "# #         batting_df = stitched_dataset[\"batting_stats\"].apply(lambda x: stitched_dataset[\"batting_stats\"][(stitched_dataset[\"batting_stats\"].batter.values == x.batter) & (stitched_dataset[\"batting_stats\"].game_date.values < x.game_date)].iloc[-1][[\"season_\" + play, \"month_\" + play]] if len(stitched_dataset[\"batting_stats\"][(stitched_dataset[\"batting_stats\"].batter.values == x.batter) & (stitched_dataset[\"batting_stats\"].game_date.values < x.game_date)]) > 0 else pd.DataFrame(), axis=1) \n",
    "# #         stitched_dataset[\"batting_stats\"][\"b_season_\" + play] = batting_df[\"season_\" + play] if len(batting_df) > 0 else None\n",
    "# #         stitched_dataset[\"batting_stats\"][\"b_month_\" + play] = batting_df[\"month_\" + play] if len(batting_df) > 0 else None\n",
    "        \n",
    "\n",
    "# #         clear_output(wait=True)\n",
    "\n",
    "#         print(\"Attaching the Pitcher Probability Vectors to the Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "# #         stitched_dataset[\"batting_stats\"][\"p_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "# #         stitched_dataset[\"batting_stats\"][\"p_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        \n",
    "#         pitching_df = stitched_dataset[\"pitching_stats\"].apply(lambda x: stitched_dataset[\"pitching_stats\"][(stitched_dataset[\"pitching_stats\"].pitcher.values == x.pitcher) & (stitched_dataset[\"pitching_stats\"].game_date.values == x.game_date)].iloc[-1][\"season_\" + play, \"month_\" + play] if len(stitched_dataset[\"pitching_stats\"][(stitched_dataset[\"pitching_stats\"].pitcher.values == x.pitcher) & (stitched_dataset[\"pitching_stats\"].game_date.values < x.game_date)]) > 0 else pd.DataFrame(), axis=1)\n",
    "#         stitched_dataset[\"pitching_stats\"][\"b_season_\" + play] = pitching_df[\"season_\" + play] if len(pitching_df) > 0 else None\n",
    "#         stitched_dataset[\"pitching_stats\"][\"b_month_\" + play] = pitching_df[\"month_\" + play] if len(pitching_df) > 0 else None\n",
    "        \n",
    "        \n",
    "        \n",
    "#         clear_output(wait=True)\n",
    "\n",
    "\n",
    "    # Add in a column for the actual play, to be used for comparison against our prediction vector\n",
    "    stitched_dataset[\"batting_stats\"][\"play\"] = stitched_dataset[\"batting_stats\"].apply(lambda x: factored_batting_stats[x.pitbat].loc[x.name].play_type, axis=1)\n",
    "    \n",
    "    \n",
    "    # Attatch the weather information # THIS MAY HAVE TO CHANGE WITH WEATHER CODING UPDATES\n",
    "    print(\"Attatching Original Weather Information to Final Dataset\")\n",
    "\n",
    "    weather_columns = [\"temprature_squared\", \"Left to Right\", \"Right to Left\", \"in\", \"out\", \"zero\"]\n",
    "    stitched_dataset[\"batting_stats\"][weather_columns] = stitched_dataset[\"batting_stats\"].apply(lambda x: stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk].iloc[0][weather_columns] if len(stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk]) > 0 else pd.Series({x:None for x in weather_columns}) , axis=1)\n",
    "    stitched_dataset[\"batting_stats\"][\"is_on_base\"] = stitched_dataset[\"batting_stats\"].play.apply(lambda x: 1 if x in [\"single\", \"double\", \"triple\", \"home_run\", \"walk\", \"intent_walk\"] else 0)\n",
    "    \n",
    "    # Attatch the League Average Information \n",
    "    print(\"Attatching League Average Information\")\n",
    "    league_averages = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "        league_averages[pitbat_combo] = {}\n",
    "        pitbat_df = stitched_dataset[\"batting_stats\"][stitched_dataset[\"batting_stats\"].pitbat == pitbat_combo].copy()\n",
    "        for date in pitbat_df.game_date.unique():\n",
    "            league_averages[pitbat_combo][date] = {\"season\":{}, \"month\":{}}\n",
    "            season_ago = str(int(date.split(\"-\")[0]) - 1) + date.split(\"-\")[1] + date.split(\"-\")[2]\n",
    "            month_ago = date.split(\"-\")[0] + str(int(date.split(\"-\")[1]) - 1) + date.split(\"-\")[2] #We can just subtract one from the month because baseball is not played in January\n",
    "            \n",
    "            season_pitbat_date_df = pitbat_df[(pitbat_df.game_date < date) & (pitbat_df.game_date > season_ago)]#[-1*min(504, len(pitbat_df)):].copy()\n",
    "            month_pitbat_date_df = pitbat_df[(pitbat_df.game_date < date) & (pitbat_df.game_date > month_ago)]#[-1*min(100, len(pitbat_df)):].copy()\n",
    "            \n",
    "            # Find league average from the month and full seasons worth of time\n",
    "            \n",
    "            for play in plays:\n",
    "                season_play_average = len(season_pitbat_date_df[season_pitbat_date_df.play == play])/len(season_pitbat_date_df) if len(season_pitbat_date_df) > 0 else None\n",
    "                month_play_average = len(month_pitbat_date_df[month_pitbat_date_df.play == play])/len(month_pitbat_date_df) if len(month_pitbat_date_df) > 0 else None\n",
    "                \n",
    "                league_averages[pitbat_combo][date][\"season\"][play] = season_play_average\n",
    "                league_averages[pitbat_combo][date][\"month\"][play] = season_play_average\n",
    "\n",
    "    for play in plays:\n",
    "        stitched_dataset[\"batting_stats\"][\"season_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"season\"][play], axis=1)\n",
    "        stitched_dataset[\"batting_stats\"][\"month_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"month\"][play], axis=1)\n",
    "    \n",
    "    \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return stitched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c73a80-2cc4-4cfd-8513-0ce0419cabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(final_dataset):\n",
    "    for col in [\"on_3b\", \"on_2b\", \"on_1b\"]:\n",
    "        final_dataset[col] = final_dataset[col].apply(lambda x: 1 if pd.isna(x) == False else 0) \n",
    "    \n",
    "    final_dataset[\"inning_topbot\"] = odds_dataset[col].apply(lambda x: 1 if x == \"Top\" else 0) \n",
    "    \n",
    "    ml_full_df = odds_dataset[[col for col in odds_dataset.columns if col not in [\"game_pk\", \"batter\", \"pitcher\", \"temprature\", \"wind_speed\", \"wind_direction\", \"year\"]]].dropna()\n",
    "    ml_full_df = ml_full_df[ml_full_df.game_date.apply(lambda x: int(x.split(\"-\")[1])) >= 5].reset_index(drop=True)\n",
    "    ml_full_df.drop(columns = [\"game_date\"], inplace=True)\n",
    "    ml_full_y_play = ml_full_df.play\n",
    "    ml_full_y_on_base = ml_full_df.is_on_base\n",
    "    ml_full_df.drop(columns = [\"play\", \"is_on_base\"], inplace = True)\n",
    "\n",
    "    numeric_features = [col for col in ml_full_df if col not in [\"ballpark\", \"pitbat\"]]\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"scaler\", StandardScaler())]\n",
    "    )\n",
    "    \n",
    "    categorical_features = [\"ballpark\", \"pitbat\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ml_pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor)]\n",
    "    )\n",
    "\n",
    "    ml_full_df = ml_pipe.fit_transform(ml_full_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47e2309a-a92f-404f-8456-3072da6229f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(pitches, pickle):\n",
    "    # Clean raw pitch data and sort everything by hand combos\n",
    "    all_plays_by_hand_combo = build_plays_by_hand_combo(pitches)\n",
    "    all_plays_by_hand_combo = attach_ballpark_info(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the shares of each play in each game\n",
    "    game_play_share_data = calculate_game_play_shares(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the league averages over time for each play\n",
    "    league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "    # Clean the data necessary for the weather regression, then run the analysis\n",
    "    data_for_weather_regression = prepare_weather_regression(game_play_share_data)\n",
    "    weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "    weather_coefficients = weather_regression_set[1]\n",
    "    \n",
    "    # Additionally, calculate the impact of specific parks \n",
    "    park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "    # \"Neutralize\" the raw events based on the impact from stadium and weather\n",
    "    neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors)\n",
    "\n",
    "    # Take the neutralized stats for each player and roll them for a month and a season's worth of time\n",
    "    individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats)\n",
    "    \n",
    "    # Recombine the separated dataframes (by hand combo) into one large dataframe\n",
    "    stitched_rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats)\n",
    "    \n",
    "    # Join the batting and pitching datasets so that for any given day we have both the batter and pitcher's stats\n",
    "    final_dataset = finalize_dataset(stitched_rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)\n",
    "\n",
    "    # Process the final dataset with a standard pipeline to be used in training algorithms\n",
    "    processed_dataset = process_pipeline(final_dataset[\"stats\"][\"batting_stats\"])\n",
    "    \n",
    "    return {\"stats\":final_dataset, \"league_averages\":league_averages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a148367-81b6-4f8f-a61c-b23895257a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(pitches, pickle):\n",
    "    # Clean raw pitch data and sort everything by hand combos\n",
    "    all_plays_by_hand_combo = build_plays_by_hand_combo(pitches)\n",
    "    all_plays_by_hand_combo = attach_ballpark_info(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the shares of each play in each game\n",
    "    game_play_share_data = calculate_game_play_shares(all_plays_by_hand_combo)\n",
    "    \n",
    "    # Calculate the league averages over time for each play\n",
    "    league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "    # Clean the data necessary for the weather regression, then run the analysis\n",
    "    data_for_weather_regression = prepare_weather_regression(game_play_share_data)\n",
    "    weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "    weather_coefficients = weather_regression_set[1]\n",
    "    \n",
    "    # Additionally, calculate the impact of specific parks \n",
    "    park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "    # \"Neutralize\" the raw events based on the impact from stadium and weather\n",
    "    neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors)\n",
    "\n",
    "    # Take the neutralized stats for each player and roll them for a month and a season's worth of time\n",
    "    individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats)\n",
    "    \n",
    "    # Recombine the separated dataframes (by hand combo) into one large dataframe\n",
    "    stitched_rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats)\n",
    "    \n",
    "    # Join the batting and pitching datasets so that for any given day we have both the batter and pitcher's stats\n",
    "    final_dataset = finalize_dataset(stitched_rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)\n",
    "    \n",
    "    return {\"stats\":final_dataset, \"league_averages\":league_averages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7630f85-a174-4e5c-8b97-ef1e3005e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset = pd.read_pickle(\"/Users/jaredzirkes/Desktop/Python/Non-Github/Project - MLB Simulation/Checkpoint Files/Model Building/Test Dataset 2016-18.pkl\")[\"stats\"][\"batting_stats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db849c3f-a79f-4cd9-898f-9fe9f02f46c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae0a7f9-30cf-42a2-98c5-c9491a8eb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(ml_full_df, open(\"ML X Dataset\", \"wb\"))\n",
    "pkl.dump(ml_full_y_play, open(\"ML Y Dataset (Plays)\", \"wb\"))\n",
    "pkl.dump(ml_full_y_on_base, open(\"ML Y Dataset (On Base)\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
