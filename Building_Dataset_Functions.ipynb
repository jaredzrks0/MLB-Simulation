{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960ea60-04b9-4d9d-becc-8e033aff61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to do:\n",
    "### - Add in current game situation (inning, score diff, runners on)\n",
    "### - Add in num batters faced for pitcher in game (also maybe a rest metric like days since last pitched if its easy)\n",
    "### - Expand y vector to full set of plays\n",
    "\n",
    "\n",
    "# Use the below to eventually build a stealing df to help with the simulation\n",
    "# pitches[pitches.des.str.contains(\"steal\") == True].iloc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c13d2afd-0220-4a36-96a4-80e22c5e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import sklearn \n",
    "import pickle as pkl\n",
    "import warnings\n",
    "import time\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, cross_validate, cross_val_predict, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "hand_combos = [\"RR\", \"RL\", \"LR\", \"LL\"]\n",
    "training_years = [\"2012\", \"2013\", \"2014\"]\n",
    "plays = ['strikeout', 'fly_out', 'double', 'out', 'fielders_choice',\n",
    "       'error', 'walk', 'home_run', 'single', 'sacrifice', 'double_play',\n",
    "       'intent_walk', 'triple']\n",
    "on_bases = [\"single\", \"double\", \"triple\", \"home_run\", \"walk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d86bf466-5680-46ed-8451-9f295e3e26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpark_info = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/MLB BETTING/Ballpark Info.xlsx\", header=2)[[\"Stadium\", \"Team\", \"Start Date\", \"End Date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f77ea6-bbfb-4dff-af45-b72437d3ddde",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bc5f36d-2ce2-46e9-81ff-d8d281380f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wind_direction(df, wind_column):\n",
    "    \"\"\" Given a df of batting stats with a column for wind speed and  a column for wind direction, \n",
    "    convert to a wind speed in each direction across multiple columns.\"\"\"\n",
    "    \n",
    "    # When wind speed is 0, the direction is automatically listed as \"in\" --> convert it to \"zero\" to differentiate\n",
    "    ind = df[df.wind_speed == 0].index\n",
    "    df.loc[ind, \"wind_direction\"] = \"zero\"\n",
    "    \n",
    "    # Use pd.get_dummies to One Hot Encode\n",
    "    wind_columns = pd.get_dummies(wind_column, columns=['categorical_column', ])\n",
    "    \n",
    "    wind_columns = pd.concat([df, wind_columns], axis = 1)\n",
    "    \n",
    "    # Finally multiply the binary wind direction columns by the wind speed to get the final wind speed in the correct direction\n",
    "    for column in wind_columns.columns[-5:]:\n",
    "        wind_columns[column] = wind_columns[column] * wind_columns[\"wind_speed\"]\n",
    "    \n",
    "    return wind_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d623ebb-dbe0-471e-a3ef-adf9af73cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stadium_column(df, stadium_column):\n",
    "    stadiums = pd.get_dummies(stadium_column, columns=[\"categorical_column\", ])\n",
    "    df = pd.concat([df, stadiums], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ac3bcf5-619b-4b73-a4e1-42fa81be0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log5 (pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the log5 equation. NOTE: DO NOT USE RIGHT NOW\"\"\" \n",
    "    one = (pB*pP)/pL\n",
    "    two = ((1-pB)*(1-pP))/(1-pL)\n",
    "    \n",
    "    return one/(one + two)\n",
    "\n",
    "\n",
    "def morey_z(pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the Morey Z equation\"\"\"\n",
    "    one = (pB-pL)/np.sqrt(pL*(1-pL))\n",
    "    two = (pP-pL)/np.sqrt(pL*(1-pL))\n",
    "    three = np.sqrt(pL*(1-pL))\n",
    "    return ((one + two)/np.sqrt(2) * three) +pL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c27694e7-2ebd-4a40-8cdc-bb3f0abc9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_play_percentages(batting_percentages, pitching_percentages, league_percentages, pitbat_combo, function):\n",
    "    \"\"\" Given a list of probabilities for all PA outcomes for the batter, the pitcher, and the league, along with\n",
    "    the pitbat combo, and the desired probability funtion, return a list of the probabilities for all PA outcomes \n",
    "    for the specific PA\"\"\"\n",
    "    \n",
    "    ab_percentages = {}\n",
    "    \n",
    "    # Get the specific percentages for each play type\n",
    "    for play in plays:\n",
    "        batting_percent = batting_percentages[\"b_\" + play]\n",
    "        pitching_percent = pitching_percentages[\"p_\" + play]\n",
    "        league_percent = league_percentages[pitbat_combo][play]\n",
    "        \n",
    "        # Ensure we are using one of the two acceptable prediction functions\n",
    "        if function not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "            while funtion not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "                function = input(\"Acceptable Functions are Morey Z and Log5. Please input one.\")\n",
    "        \n",
    "        # Calculate the predicted percentage for the specific play for the PA\n",
    "        if function == \"morey z\" or function == \"Morey Z\":\n",
    "            expected_percent = morey_z(batting_percent, pitching_percent, league_percent)\n",
    "        else:\n",
    "            expected_percent = log5(batting_percent, pitching_percent, league_percent)\n",
    "    \n",
    "        # Insert the predicted percentage for the play type into our dictionary for delivery\n",
    "        ab_percentages[play] = expected_percent\n",
    "    \n",
    "    return ab_percentages\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce929f94-c283-4f92-abd0-268bde13050c",
   "metadata": {},
   "source": [
    "# Build Data Sets for Odds Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "770fcd87-9cf0-457f-84cc-088eb6857ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plays_by_hand_combo = pkl.load(open(\"/users/jaredzirkes/Desktop/Python/MLB BETTING/all_plays_by_hand_combo.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "398a9419-4f2e-4803-bd38-088a494be958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine our first three years of data (maintaining hand combo seperation) to be the full initial data\n",
    "def combine_raw_pitches(training_years):\n",
    "    all_training_data = {x:pd.DataFrame() for x in hand_combos}\n",
    "    for year in training_years:\n",
    "        for pitbat_combo in hand_combos:\n",
    "            print(\"Combining Pitch Data Across Years and Attatching Ballpark Info\", year, pitbat_combo)\n",
    "            \n",
    "            df = all_plays_by_hand_combo[year][pitbat_combo]   \n",
    "            \n",
    "            df = df.sort_values(by = \"game_date\", ascending = True)\n",
    "            \n",
    "            all_training_data[pitbat_combo] = all_training_data[pitbat_combo].append(df).reset_index(drop=True)\n",
    "\n",
    "            all_training_data[pitbat_combo][\"type_counter\"] = 1\n",
    "\n",
    "            all_training_data[pitbat_combo][\"ballpark\"] = all_training_data[pitbat_combo].apply(lambda x: ballpark_info[(ballpark_info.Team == x.home_team) & (ballpark_info[\"End Date\"] > int(x.game_date.split(\"-\")[0]))].Stadium.iloc[0],axis=1)\n",
    "            clear_output(wait = True)\n",
    "\n",
    "    clear_output(wait = False)\n",
    "    \n",
    "    return all_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc85937-510c-4fe6-9984-e0cb43b42756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, calculate within the game (and pitbat_combo), the share of the plays that were each play type\n",
    "def calculate_game_play_shares(all_training_data):\n",
    "\n",
    "    game_play_shares = {x:{\"games\":{}, \"players\":{}} for x in hand_combos}\n",
    "    n = 0\n",
    "\n",
    "    for pitbat_combo in all_training_data:\n",
    "        full_df = all_training_data[pitbat_combo].copy()\n",
    "        # For each game\n",
    "        for game in full_df.game_pk.unique():\n",
    "            clear_output(wait = True)\n",
    "            game_df = full_df[full_df.game_pk == game].copy()\n",
    "            game_df[\"type_counter\"] = game_df.groupby(by = \"play_type\").cumsum().type_counter #calculate the total number of the play in the specific game\n",
    "\n",
    "            total = len(game_df)\n",
    "\n",
    "            game_df = game_df.groupby(by = \"play_type\").max()\n",
    "\n",
    "            game_df[\"play_share\"]  = game_df.type_counter/total #divide by the total number of plays, getting the play share for the game\n",
    "\n",
    "            game_play_shares[pitbat_combo][\"games\"][game] = game_df\n",
    "            game_play_shares[pitbat_combo][\"games\"][game][\"count\"] = total\n",
    "\n",
    "            if n%1000 == 0:\n",
    "                print(\"Calculating Probability Vectors for Each Game. There are {}K Instances Remaining\".format(round((sum([len(all_training_data[x].game_pk.unique()) for x in hand_combos])-n)/1000),6))\n",
    "            n+= 1\n",
    "\n",
    "    clear_output(wait = False)\n",
    "    \n",
    "    \n",
    "\n",
    "        # For every play, insert the % of all plays in the game it occured in that were of the same play type into all_training from game_play_shares df\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Inserting Data From Game by Game Probability Vectors To the Larger Data Set. There are {} Pitbat Combos Remaining\".format(len(hand_combos) - hand_combos.index(pitbat_combo)))\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        all_training_data[pitbat_combo][\"game_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"games\"][x.game_pk].loc[x.play_type].play_share, axis = 1)\n",
    "        #all_training_data[pitbat_combo][\"batter_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"players\"][x.batter].loc[x.play_type].play_share, axis = 1)\n",
    "\n",
    "    return all_training_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51ea455-bcca-4baf-9e3e-5de89996f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For every play, insert the % of all plays in the game it occured in that were of the same play type into all_training from game_play_shares df\n",
    "# for pitbat_combo in hand_combos:\n",
    "#     print(\"Inserting Data From Game by Game Probability Vectors To the Larger Data Set. There are {} Pitbat Combos Remaining\".format(len(hand_combos) - hand_combos.index(pitbat_combo)))\n",
    "#     clear_output(wait = True)\n",
    "    \n",
    "#     all_training_data[pitbat_combo][\"game_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"games\"][x.game_pk].loc[x.play_type].play_share, axis = 1)\n",
    "#     #all_training_data[pitbat_combo][\"batter_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"players\"][x.batter].loc[x.play_type].play_share, axis = 1)\n",
    "    \n",
    "# # # Now that we have the MLB eod % of plays by play type for every day and the % of plays that are each play in every game,\n",
    "# # # calculate/insert the difference between the individual game and the MLB eod values for every play\n",
    "# # for pitbat_combo in hand_combos:\n",
    "# #     all_training_data[pitbat_combo][\"game_share_delta\"] = all_training_data[pitbat_combo].game_play_share / all_training_data[pitbat_combo].eod_play_share\n",
    "# #     #all_training_data[pitbat_combo][\"batter_share_delta\"] = all_training_data[pitbat_combo].batter_play_share - all_training_data[pitbat_combo].eod_play_share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a670b7-de85-480e-ba5a-1e6a865358d8",
   "metadata": {},
   "source": [
    "## Calculating Batting Stats Factors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32a1eb-a0d9-4929-b212-81ffe4e7148e",
   "metadata": {},
   "source": [
    "#### Cleaning for Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93c4bf72-24de-47d6-828e-d6de500ccd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_weather_regression(all_training_data):\n",
    "    # Remove the first 300 (~10days) games from each season to let the rolling stats normalize\n",
    "    weather_training_data = {x:{} for x in hand_combos}\n",
    "    first_games = []\n",
    "    \n",
    "    l =  []\n",
    "\n",
    "\n",
    "    for pitbat_combo in hand_combos:  \n",
    "        weather_training_df = all_training_data[pitbat_combo].copy()\n",
    "        for year in training_years:\n",
    "            first_game_pks = all_plays_by_hand_combo[year][pitbat_combo].game_pk.unique()[:300] # Find the game_ids for the first 300 games of each season\n",
    "            first_games.append(list(first_game_pks))\n",
    "\n",
    "        first_games_list = np.concatenate(first_games).ravel()\n",
    "\n",
    "        weather_training_df = weather_training_df[weather_training_df.game_pk.isin(first_games_list) == False] # Pull out only the games that aren't in the first 100 games\n",
    "        weather_training_data[pitbat_combo] = weather_training_df[[\"game_pk\",\"game_date\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]\n",
    "        \n",
    "    # Group the weather training data by game and play type to get the game_share_delta for each play type for each game\n",
    "    for pitbat_combo in hand_combos:\n",
    "        weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo].groupby(by = [\"game_pk\", \"play_type\"]).last().reset_index()\n",
    "\n",
    "    # Because the only plays currently in our data are play types that happened in games, fill in all the missing play types for \n",
    "    # Each game with a game_share of 0 for that play type\n",
    "    play_types = ['out', 'single', 'strikeout', 'double', 'walk', 'home_run','triple']\n",
    "    n = 0\n",
    "    for pitbat_combo in hand_combos:\n",
    "        for game in weather_training_data[pitbat_combo].game_pk.unique():\n",
    "            n += 1\n",
    "            if n%500 == 0:\n",
    "                print(\"Filling in the Missing Values for Probability Vectors. There are {}K Instances Remaining\".format(round((sum([len(weather_training_data[x].game_pk.unique()) for x in hand_combos])-n)/1000),6))\n",
    "            clear_output(wait = True)\n",
    "            df = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].game_pk == game].copy()\n",
    "            if len(df) < len(play_types):\n",
    "                missing_plays = [play for play in play_types if play not in df.play_type.values]\n",
    "                for play in missing_plays:\n",
    "                    #weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.Series({\"game_pk\":game, \"game_date\":df.iloc[0].game_date, \"play_type\":play, \"temprature\":df.iloc[0].temprature, \"wind_speed\":df.iloc[0].wind_speed, \"wind_direction\":df.iloc[0].wind_direction, \"game_share_delta\":all_training_data[pitbat_combo][(all_training_data[pitbat_combo].game_date < df.iloc[0].game_date) & (all_training_data[pitbat_combo].play_type == play)].iloc[-1].eod_play_share * -1}), ignore_index = True)\n",
    "                    weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.Series({\"game_pk\":game, \"game_date\":df.iloc[0].game_date, \"play_type\":play, \"temprature\":df.iloc[0].temprature, \"wind_speed\":df.iloc[0].wind_speed, \"wind_direction\":df.iloc[0].wind_direction, \"game_play_share\":0}), ignore_index=True)\n",
    "    clear_output(wait = False)\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        # Filter down to only the relevant columns for the weather regression\n",
    "        weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo][[\"game_pk\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]\n",
    "\n",
    "        # Square temprature to use in the regression because I believe it behaves this way\n",
    "        weather_training_data[pitbat_combo][\"temprature_squared\"] = weather_training_data[pitbat_combo][\"temprature\"].apply(lambda x: x**2)\n",
    "\n",
    "        # Encode the wind directions and calculate final wind speeds in the direction\n",
    "        weather_training_data[pitbat_combo] = convert_wind_direction(weather_training_data[pitbat_combo], weather_training_data[pitbat_combo].wind_direction)\n",
    "\n",
    "\n",
    "    \n",
    "    return (weather_training_data, first_games_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f931-a022-42d2-80e2-3cbbe32e48e5",
   "metadata": {},
   "source": [
    "#### Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "302a46d2-cae7-4475-a92a-c2174f89a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_regress(weather_training_data):\n",
    "    weather_coefficients = {}\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        weather_coefficients[pitbat_combo] = {}\n",
    "        for play_type in weather_training_data[pitbat_combo].play_type.unique():\n",
    "            PAs = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].play_type == play_type]\n",
    "\n",
    "            # Remove outliers for game_share_delta, most of which are caused by low pitbat_combo sample sizes in games\n",
    "            PAs = PAs[(np.abs(stats.zscore(PAs.game_play_share)) < 3)]\n",
    "\n",
    "            # Create 2 sets of x data, with and without squaring temprature\n",
    "            x = PAs[PAs.columns[np.r_[2:4, 6:11]]] #grab only the weather related columns and then get rid of regular temprature\n",
    "\n",
    "            x_sq = x[[col for col in x.columns if col != \"temprature\" and col != \"wind_speed\"]]\n",
    "\n",
    "            y = PAs.game_play_share\n",
    "\n",
    "            # Regress the temprature squared dataset on game_share_delta\n",
    "            lin_sq = LinearRegression(fit_intercept = True)\n",
    "            lin_sq.fit(x_sq, y)\n",
    "\n",
    "            weather_coefficients[pitbat_combo][play_type] = {\"intercept\":lin_sq.intercept_, \"temprature_sq\":lin_sq.coef_[0], \"wind_ltr\":lin_sq.coef_[1],\n",
    "                                                     \"wind_rtl\":lin_sq.coef_[2], \"wind_in\":lin_sq.coef_[3], \"wind_out\":lin_sq.coef_[4]}\n",
    "            \n",
    "    return(weather_training_data, weather_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608cb28-ea92-4716-82dc-8a43099902cd",
   "metadata": {},
   "source": [
    "#### Calculating Park Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4195106a-6e17-480e-bf0b-e746187bd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_park_factors(all_training_data):\n",
    "    park_factors_dict = {}\n",
    "    print(\"Calculating Ballpark Factors\")\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        park_factors_dict[pitbat_combo] = {}\n",
    "\n",
    "        for ballpark in all_training_data[\"RR\"].ballpark.unique():\n",
    "            park_factors_dict[pitbat_combo][ballpark] = {}\n",
    "            at_park_df = all_training_data[pitbat_combo][(all_training_data[pitbat_combo].ballpark == ballpark)]\n",
    "            not_at_park_df = all_training_data[pitbat_combo][(all_training_data[pitbat_combo].ballpark != ballpark)]\n",
    "\n",
    "\n",
    "            for play_type in all_training_data[\"RR\"].play_type.unique():\n",
    "                at_park_rate = len(at_park_df[at_park_df.play_type == play_type])/len(at_park_df)\n",
    "                not_at_park_rate = len(not_at_park_df[not_at_park_df.play_type == play_type])/len(not_at_park_df)\n",
    "\n",
    "                try:\n",
    "                    park_factor = at_park_rate/not_at_park_rate\n",
    "                except:\n",
    "                    part_factor = \"n/a\"\n",
    "\n",
    "                park_factors_dict[pitbat_combo][ballpark][play_type] = park_factor\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return (all_training_data, park_factors_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32878f77-8cea-4145-9f94-456977256e5a",
   "metadata": {},
   "source": [
    "## Adjusting Stats for Batting Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2d2cd011-8050-49b6-8514-37ba1f0a5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutralize_stats(all_training_data, weather_coefficients, park_factors_dict, first_games_list, is_dump):\n",
    "    # Start a new dictionary to hold the edited training stats\n",
    "    print(\"Neutralizing Batting Stats using Weather/Stadium Coefficients\")\n",
    "\n",
    "    factored_training_stats = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "\n",
    "        # Grab the relevant columns and games\n",
    "        df = all_training_data[pitbat_combo][[\"game_pk\", \"game_date\", \"batter\", \"pitcher\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"ballpark\"]].copy()\n",
    "        #df = df[df.game_pk.isin(first_games_list) == False] # We will take out the first ten games later on\n",
    "\n",
    "        # Add information for the actual weather and stadium impacts for each game\n",
    "        df = convert_wind_direction(df, df.wind_direction)\n",
    "        df[\"weather_expectation\"] = df.apply(lambda x: x[\"Left to Right\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_ltr\"] + x[\"Right to Left\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_rtl\"] +\n",
    "                                        x[\"in\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_in\"] + x[\"out\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_out\"] +\n",
    "                                        (x[\"temprature\"]**2) * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "\n",
    "        df[\"neutral_weather_expectation\"] = df.apply(lambda x: 72**2 * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "        df[\"weather_impact\"] = df.weather_expectation/df.neutral_weather_expectation\n",
    "        df[\"stadium_impact\"] = df.apply(lambda x: park_factors_dict[pitbat_combo][x.ballpark][x.play_type], axis=1)\n",
    "\n",
    "        # Multiply the weather and stadium impacts to get the total impact for the specific at-bat result\n",
    "        df[\"play_value\"] = 1\n",
    "        df[\"impact\"] = df.play_value * df.weather_impact * df.stadium_impact\n",
    "        df.play_value = 1/df.impact\n",
    "\n",
    "        factored_training_stats[pitbat_combo] = df[[\"game_pk\", \"game_date\",\"ballpark\", \"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\", \"play_type\",\"impact\", \"play_value\"]]\n",
    "        \n",
    "        if is_dump == True:\n",
    "            pkl.dump(factored_training_stats, open(\"/Users/jaredzirkes/Documents/GitHub/MLB-Simulation/training_batting_stats_with_factors.pkl\", \"wb\"))\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return factored_training_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed13770-9311-45df-a82a-2ed3dbc0b67b",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Calculate League Averages Over the Length of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "efdf65dc-6fea-4a88-898a-0a1058d343a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_league_averages(game_play_share_data):\n",
    "    league_average_plays_dict = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "        league_average_plays_dict[pitbat_combo] = {}\n",
    "        for play in plays:\n",
    "            df = game_play_share_data[pitbat_combo]\n",
    "            play_share = len(df[df.play_type == play])/len(df)\n",
    "            league_average_plays_dict[pitbat_combo][play] = play_share\n",
    "\n",
    "    return league_average_plays_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d08fc-e207-495f-a3fd-5f2fe431520e",
   "metadata": {},
   "source": [
    "## Roll Stats Daily To Get Final Odds Functions Training Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed7d14-3b5d-42d8-a15d-3330e2a4ac74",
   "metadata": {},
   "source": [
    "### Rolling with Breaks for Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ae6fcf34-213d-4cc3-ba13-837e9258c9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def roll_factored_batting_stats(factored_batting_stats, with_year_breaks, rolling_period, min_periods, is_dump):\n",
    "    # Create a rolling percentage for each play outcome for each batter and pitcher for each year \n",
    "    rolling_factored_batting_stats = {}\n",
    "    rolling_factored_pitching_stats = {}\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        if with_year_breaks == True:\n",
    "            factored_batting_stats[pitbat_combo][\"year\"] = factored_batting_stats[pitbat_combo].game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "        else:\n",
    "            factored_batting_stats[pitbat_combo][\"year\"] = factored_batting_stats[pitbat_combo].game_date.apply(lambda x: \"All Years\")\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(\"Rolling Batting Stats Daily. There are {} Hand Combos Left\".format(len(hand_combos) - (hand_combos.index(pitbat_combo)) + 4))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "\n",
    "        rolling_factored_batting_stats[pitbat_combo] = {}\n",
    "        rolling_factored_pitching_stats[pitbat_combo] = {}\n",
    "        for year in factored_batting_stats[pitbat_combo].year.unique():\n",
    "            rolling_factored_batting_stats[pitbat_combo][year] = {}\n",
    "            rolling_factored_pitching_stats[pitbat_combo][year] = {}\n",
    "\n",
    "            # Filter down to the stats for just the relevant year\n",
    "            df = factored_batting_stats[pitbat_combo][factored_batting_stats[pitbat_combo].year == str(year)]\n",
    "            df = df.sort_values(by = \"game_date\", ascending = True)\n",
    "\n",
    "            # Build rolling stats for batters\n",
    "            b = 0\n",
    "            for batter in df.batter.unique():\n",
    "                clear_output(wait = True)\n",
    "\n",
    "\n",
    "                batter_df = df[df.batter == batter]\n",
    "                batter_df[\"season_at_bat_num\"] = 1\n",
    "                batter_df[\"month_at_bat_num\"] = 1\n",
    "\n",
    "                # Make a rolling count for the at bats for each batter\n",
    "                if with_year_breaks == True:\n",
    "                    batter_df[\"season_at_bat_num\"] = batter_df.season_at_bat_num.rolling(len(batter_df), min_periods = min_periods).sum()\n",
    "                    batter_df[\"month_at_bat_num\"] = batter_df.month_at_bat_num.rolling(100, min_periods = min_periods).sum()\n",
    "                else:\n",
    "                    batter_df[\"season_at_bat_num\"] = batter_df.season_at_bat_num.rolling(rolling_period, min_periods = min_periods).sum()\n",
    "                    batter_df[\"month_at_bat_num\"] = batter_df.month_at_bat_num.rolling(100, min_periods = min_periods).sum()\n",
    "\n",
    "                for play in plays:\n",
    "                    # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "                    batter_df[\"season_{}\".format(play)] = batter_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "                    batter_df[\"month_{}\".format(play)] = batter_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "\n",
    "                    if with_year_breaks == True:\n",
    "                        batter_df[\"season_{}\".format(play)] = batter_df[\"season_{}\".format(play)].rolling(len(batter_df), min_periods = min_periods).sum()\n",
    "                        batter_df[\"month_{}\".format(play)] = batter_df[\"month_{}\".format(play)].rolling(100, min_periods = min_periods).sum()\n",
    "                        \n",
    "                    else:\n",
    "                        batter_df[\"season_{}\".format(play)] = batter_df[\"season_{}\".format(play)].rolling(rolling_period, min_periods = min_periods).sum()\n",
    "                        batter_df[\"month_{}\".format(play)] = batter_df[\"month_{}\".format(play)].rolling(100, min_periods = min_periods).sum()\n",
    "\n",
    "                    batter_df[\"season_{}\".format(play)] = batter_df[\"season_{}\".format(play)]/batter_df.season_at_bat_num\n",
    "                    batter_df[\"month_{}\".format(play)] = batter_df[\"month_{}\".format(play)]/batter_df.month_at_bat_num\n",
    "                    \n",
    "                    \n",
    "                    batter_df[\"pitbat\"] = pitbat_combo\n",
    "                rolling_factored_batting_stats[pitbat_combo][year][batter] = batter_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "\n",
    "                if b%10 ==0:\n",
    "                    if with_year_breaks == True:\n",
    "                        print(\"Rolling Batting Stats. There are {} batters remaining in {}, with {} years remaining. Then {} Hand Combos Remaining\".format(len(df.batter.unique()) - b, year, len(training_years) - training_years.index(year)-1, len(hand_combos) - hand_combos.index(pitbat_combo) - 1))\n",
    "                    else:\n",
    "                        print(\"Rolling Batting Stats. There are {} batters remaining. Then {} Hand Combos Remaining\".format(len(df.batter.unique()) - b, len(hand_combos) - hand_combos.index(pitbat_combo) - 1))\n",
    "                        \n",
    "                b+=1\n",
    "\n",
    "                # Repercentage factored batting stats to sum to 1\n",
    "                rolling_factored_batting_stats[pitbat_combo][year][batter][[\"season_{}\".format(play) for play in plays]] = rolling_factored_batting_stats[pitbat_combo][year][batter].apply(lambda x: pd.Series([x[[\"season_{}\".format(play) for play in plays]][\"season_{}\".format(p)]/x[[\"season_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"season_{}\".format(p) for p in plays]].sum() > 0 else [0 for p in plays], axis=1)\n",
    "                rolling_factored_batting_stats[pitbat_combo][year][batter][[\"month_{}\".format(play) for play in plays]] = rolling_factored_batting_stats[pitbat_combo][year][batter].apply(lambda x: pd.Series([x[[\"month_{}\".format(play) for play in plays]][\"month_{}\".format(p)]/x[[\"month_{}\".format(play) for play in plays]].sum() for p in [z for z in plays]]) if x[[\"month_{}\".format(p) for p in plays]].sum() > 0 else [0 for p in plays], axis=1)\n",
    "\n",
    "\n",
    "            # Build the rolling stats for pitchers        \n",
    "            p=0\n",
    "            for pitcher in df.pitcher.unique():\n",
    "                clear_output(wait=True)           \n",
    "                pitcher_df = df[df.pitcher == pitcher]\n",
    "                pitcher_df[\"season_at_bat_num\"] = 1\n",
    "                pitcher_df[\"month_at_bat_num\"] = 1\n",
    "                \n",
    "                if with_year_breaks == True:\n",
    "                    batter_df[\"season_at_bat_num\"] = pitcher_df.season_at_bat_num.rolling(len(pitcher_df), min_periods = min_periods).sum()\n",
    "                    batter_df[\"month_at_bat_num\"] = pitcher_df.month_at_bat_num.rolling(100, min_periods = min_periods).sum()\n",
    "                else:\n",
    "                    batter_df[\"season_at_bat_num\"] = pitcher_df.season_at_bat_num.rolling(rolling_period, min_periods = min_periods).sum()\n",
    "                    batter_df[\"month_at_bat_num\"] = pitcher_df.month_at_bat_num.rolling(100, min_periods = min_periods).sum()\n",
    "\n",
    "                for play in plays:\n",
    "                    # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "                    pitcher_df[\"season_{}\".format(play)] = pitcher_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "                    pitcher_df[\"month_{}\".format(play)] = pitcher_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "                    \n",
    "                    if with_year_breaks == True:\n",
    "                        pitcher_df[\"season_{}\".format(play)] = pitcher_df[\"season_{}\".format(play)].rolling(len(pitcher_df), min_periods = min_periods).sum()\n",
    "                        pitcher_df[\"month_{}\".format(play)] = pitcher_df[\"month_{}\".format(play)].rolling(100, min_periods = min_periods).sum()\n",
    "                    else:\n",
    "                        pitcher_df[\"season_{}\".format(play)] = pitcher_df[\"season_{}\".format(play)].rolling(rolling_period, min_periods = min_periods).sum()\n",
    "                        pitcher_df[\"month_{}\".format(play)] = pitcher_df[\"month_{}\".format(play)].rolling(rolling_period, min_periods = min_periods).sum()\n",
    "                        \n",
    "                    pitcher_df[\"season_{}\".format(play)] = pitcher_df[\"season_{}\".format(play)]/pitcher_df.season_at_bat_num\n",
    "                    pitcher_df[\"month_{}\".format(play)] = pitcher_df[\"month_{}\".format(play)]/pitcher_df.month_at_bat_num             \n",
    "                    \n",
    "                    \n",
    "                    pitcher_df[\"pitbat\"] = pitbat_combo\n",
    "\n",
    "                #rolling_factored_pitching_stats[pitbat_combo][year][pitcher] = pitcher_df[[\"game_pk\", \"game_date\", \"batter\", \"pitcher\", \"pitbat\", \"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"]]\n",
    "                rolling_factored_pitching_stats[pitbat_combo][year][pitcher] = pitcher_df[[\"game_pk\", \"game_date\", \"ballpark\",\"temprature\", \"wind_speed\", \"wind_direction\", \"batter\", \"pitcher\", \"pitbat\",'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot', \"bat_score\", \"fld_score\"] + [\"season_{}\".format(play) for play in plays] + [\"month_{}\".format(play) for play in plays]]\n",
    "                    \n",
    "                if p%5 ==0:\n",
    "                    if with_year_breaks == True:\n",
    "                        print(\"Rolling Pitching Stats. There are {} pitchers remaining in {}, with {} years remaining. Then {} Hand Combos Remaining\".format(len(df.pitcher.unique()) - p, year, len(training_years) - training_years.index(year)-1, len(hand_combos) - hand_combos.index(pitbat_combo) - 1))\n",
    "                    else:\n",
    "                        print(\"Rolling Pitching Stats. There are {} pitchers remaining. Then {} Hand Combos Remaining\".format(len(df.pitcher.unique()) - b, len(hand_combos) - hand_combos.index(pitbat_combo) - 1))\n",
    "                p+=1\n",
    "\n",
    "                # Repercentage factored pitching stats to sum to 1\n",
    "                rolling_factored_pitching_stats[pitbat_combo][year][pitcher][[\"season_{}\".format(p) for p in plays]] = rolling_factored_pitching_stats[pitbat_combo][year][pitcher].apply(lambda x: pd.Series([x[[\"season_{}\".format(p) for p in plays]][\"season_{}\".format(p)]/x[[\"season_{}\".format(p) for p in plays]].sum() for p in plays]) if x[[\"season_{}\".format(p) for p in plays]].sum() >0 else [0 for p in plays], axis=1)\n",
    "                rolling_factored_pitching_stats[pitbat_combo][year][pitcher][[\"month_{}\".format(p) for p in plays]] = rolling_factored_pitching_stats[pitbat_combo][year][pitcher].apply(lambda x: pd.Series([x[[\"month_{}\".format(p) for p in plays]][\"month_{}\".format(p)]/x[[\"month_{}\".format(p) for p in plays]].sum() for p in plays]) if x[[\"month_{}\".format(p) for p in plays]].sum() >0 else [0 for p in plays], axis=1)\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    if is_dump == True:\n",
    "        pkl.dump(rolling_factored_pitching_stats, open(\"rolling_factored_pitching_stats.pkl\",\"wb\"))\n",
    "        pkl.dump(rolling_factored_batting_stats, open(\"rolling_factored_batting_stats.pkl\",\"wb\"))\n",
    "    \n",
    "    return {\"pitching_stats\":rolling_factored_pitching_stats, \"batting_stats\":rolling_factored_batting_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7c3b76d8-227d-4d55-8fa8-4d963875884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a rolling percentage for each play outcome for each batter and pitcher for each year \n",
    "# rolling_factored_batting_stats = {}\n",
    "# rolling_factored_pitching_stats = {}\n",
    "\n",
    "# for pitbat_combo in hand_combos:\n",
    "#     factored_batting_stats[pitbat_combo][\"year\"] = factored_batting_stats[pitbat_combo].game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "# for pitbat_combo in hand_combos:\n",
    "#     print(\"Rolling Batting Stats Daily. There are {} Hand Combos Left\".format(len(hand_combos) - (hand_combos.index(pitbat_combo)) + 4))\n",
    "#     clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "#     rolling_factored_batting_stats[pitbat_combo] = {}\n",
    "#     rolling_factored_pitching_stats[pitbat_combo] = {}\n",
    "#     for year in training_years:\n",
    "#         rolling_factored_batting_stats[pitbat_combo][year] = {}\n",
    "#         rolling_factored_pitching_stats[pitbat_combo][year] = {}\n",
    "        \n",
    "#         # Filter down to the stats for just the relevant year\n",
    "#         df = factored_batting_stats[pitbat_combo][factored_batting_stats[pitbat_combo].year == str(year)]\n",
    "        \n",
    "#         # Build rolling stats for pitchers\n",
    "#         b = 0\n",
    "#         for batter in df.batter.unique():\n",
    "#             clear_output(wait = True)\n",
    "            \n",
    "            \n",
    "#             batter_df = df[df.batter == batter]\n",
    "#             batter_df[\"at_bat_num\"] = 1\n",
    "            \n",
    "#             # Make a rolling count for the at bats for each batter\n",
    "#             batter_df[\"at_bat_num\"] = batter_df.at_bat_num.rolling(len(batter_df), min_periods = 1).sum()\n",
    "            \n",
    "#             for play in plays:\n",
    "#                 # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "#                 batter_df[play] = batter_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "#                 batter_df[play] = batter_df[play].rolling(len(batter_df), min_periods = 1).sum()\n",
    "#                 batter_df[play] = batter_df[play]/batter_df.at_bat_num\n",
    "#                 batter_df[\"pitbat\"] = pitbat_combo\n",
    "#             rolling_factored_batting_stats[pitbat_combo][year][batter] = batter_df[[\"game_pk\", \"game_date\", \"batter\", \"pitcher\", \"pitbat\", \"at_bat_num\", \"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"]]\n",
    "                        \n",
    "#             if b%5 ==0:\n",
    "#                 print(\"Rolling Batting Stats. There are {} batters remaining in {}, with {} years remaining\".format(len(df.batter.unique()) - b, year, len(training_years) - training_years.index(year)-1))\n",
    "#             b+=1\n",
    "\n",
    "#             # Repercentage factored batting stats to sum to 1\n",
    "#             rolling_factored_batting_stats[pitbat_combo][year][batter][plays] = rolling_factored_batting_stats[pitbat_combo][year][batter].apply(lambda x: pd.Series([x[plays][p]/x[plays].sum() for p in plays]), axis=1)\n",
    "        \n",
    "        \n",
    "#         # Build the rolling stats for pitchers        \n",
    "#         p=0\n",
    "#         for pitcher in df.pitcher.unique():\n",
    "#             clear_output(wait=True)           \n",
    "#             pitcher_df = df[df.pitcher == pitcher]\n",
    "#             pitcher_df[\"at_bat_num\"] = 1\n",
    "#             pitcher_df[\"at_bat_num\"] = pitcher_df.at_bat_num.rolling(len(pitcher_df), min_periods = 1).sum()\n",
    "            \n",
    "#             for play in plays:\n",
    "#                 # Multiply the situation impact by a binary vector for play outcomes with a 1 for the correct play\n",
    "#                 pitcher_df[play] = pitcher_df.apply(lambda x: 1*x.play_value if x.play_type==play else 0, axis = 1)\n",
    "#                 pitcher_df[play] = pitcher_df[play].rolling(len(pitcher_df), min_periods = 1).sum()\n",
    "#                 pitcher_df[play] = pitcher_df[play]/pitcher_df.at_bat_num\n",
    "#                 pitcher_df[\"pitbat\"] = pitbat_combo\n",
    "\n",
    "#             rolling_factored_pitching_stats[pitbat_combo][year][pitcher] = pitcher_df[[\"game_pk\", \"game_date\", \"batter\", \"pitcher\", \"pitbat\", \"at_bat_num\", \"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"]]\n",
    "\n",
    "#             if p%5 ==0:\n",
    "#                 print(\"Rolling Pitching Stats. There are {} batters remaining in {}, with {} years remaining\".format(len(df.batter.unique()) - p, year, len(training_years) - training_years.index(year)-1))\n",
    "#             p+=1\n",
    "            \n",
    "#             # Repercentage factored pitching stats to sum to 1\n",
    "#             rolling_factored_pitching_stats[pitbat_combo][year][pitcher][plays] = rolling_factored_pitching_stats[pitbat_combo][year][pitcher].apply(lambda x: pd.Series([x[plays][p]/x[plays].sum() for p in plays]), axis=1)\n",
    "            \n",
    "# clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e5f9d34a-eeea-4dcb-b06e-2a8ecf7797c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_factored_pitching_stats = pkl.load(open(\"rolling_factored_pitching_stats.pkl\",\"rb\"))\n",
    "rolling_factored_batting_stats = pkl.load(open(\"rolling_factored_batting_stats.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "da57992e-c049-4b99-8ce7-a79ee2d61d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all the rolled individual player DFs out of the dictionary and into a large DF \n",
    "# that will be used for final training\n",
    "def stitch_individual_stats(rolling_factored_stats, with_year_breaks):\n",
    "    training_stats = pd.DataFrame()\n",
    "    pitching_holder = pd.DataFrame()\n",
    "\n",
    "    for pitbat_combo in hand_combos:\n",
    "        for year in rolling_factored_stats[\"batting_stats\"][pitbat_combo]:\n",
    "            print(\"Stitching Together Individual Stats Into the Odds Functions Data Set. There are {} Pitbats Left and {} Years Remaining in the Current Pitbat\".format(len(hand_combos)-hand_combos.index(pitbat_combo), \"Insert Years Remaining\"))\n",
    "            clear_output(wait = True)\n",
    "            for batter in rolling_factored_stats[\"batting_stats\"][pitbat_combo][year]:\n",
    "                # Find each specific player df of unique pitbat combo, year, and batter\n",
    "                df_b = rolling_factored_stats[\"batting_stats\"][pitbat_combo][year][batter]\n",
    "\n",
    "                # We will through an error trying to look for games with dates less than our opening day, and there's\n",
    "                # no need to stats for ~1 games anyways, so cut off the first 3 PAs of stats\n",
    "                if len(df_b) > 3:\n",
    "                    training_stats = training_stats.append(df_b[3:]) \n",
    "\n",
    "            # Do the same thing for pitchers. Note we can leave in the first 3 PAs, because we will be simply joining with\n",
    "            # the batters, so these PAs will get cut off then.\n",
    "            for pitcher in rolling_factored_stats[\"pitching_stats\"][pitbat_combo][year]:\n",
    "                df_p = rolling_factored_stats[\"pitching_stats\"][pitbat_combo][year][pitcher]\n",
    "                pitching_holder = pitching_holder.append(df_p) \n",
    "\n",
    "        clear_output(wait=False)\n",
    "\n",
    "    if with_year_breaks == True:\n",
    "        training_stats[\"year\"] = training_stats.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "        pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: x.split(\"-\")[0])\n",
    "    else:\n",
    "        training_stats[\"year\"] = training_stats.game_date.apply(lambda x: \"All Years\")\n",
    "        pitching_holder[\"year\"] = pitching_holder.game_date.apply(lambda x: \"All Years\")\n",
    "\n",
    "    #pitching_holder = pitching_holder.rename(columns = {\"batter\":'pitcher'})\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return {\"pitching_stats\":pitching_holder, \"batting_stats\":training_stats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d2df3808-a08f-4b90-9b1b-f8283a195e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the pitching probability vector to the training set by \"joining\" on the pitbat combo, year, and pitcher name, where the date is just less than the given PA.\n",
    "# Then reattatch the weather and ballpark info for that game\n",
    "def finalize_odds_dataset(stitched_dataset, rolling_factored_stats, factored_batting_stats, stats_with_weather):\n",
    "    for play in plays:\n",
    "        print(\"Attaching the Batter Probability Vectors to the Odds Functions Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "        stitched_dataset[\"batting_stats\"][\"b_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        stitched_dataset[\"batting_stats\"][\"b_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter][rolling_factored_stats[\"batting_stats\"][x.pitbat][x.year][x.batter].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        print(\"Attaching the Pitcher Probability Vectors to the Odds Functions Data Set. There are {} Plays Remaining\".format(len(plays) - plays.index(play)))\n",
    "        stitched_dataset[\"batting_stats\"][\"p_season_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher].game_date < x.game_date].iloc[-1][\"season_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        stitched_dataset[\"batting_stats\"][\"p_month_\" + play] = stitched_dataset[\"batting_stats\"].apply(lambda x: rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher].game_date < x.game_date].iloc[-1][\"month_{}\".format(play)] if len(rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher][rolling_factored_stats[\"pitching_stats\"][x.pitbat][x.year][x.pitcher].game_date < x.game_date])>0 else None, axis = 1)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    #stitched_dataset[\"batting_stats\"] = stitched_dataset[\"batting_stats\"].drop(columns = plays)\n",
    "\n",
    "    # Add in a column for the actual play, to be used for comparison against our prediction vector\n",
    "    stitched_dataset[\"batting_stats\"][\"play\"] = stitched_dataset[\"batting_stats\"].apply(lambda x: factored_batting_stats[x.pitbat].loc[x.name].play_type, axis=1)\n",
    "    \n",
    "    \n",
    "    # Attatch the weather information\n",
    "    print(\"Attatching Original Weather Information to Final Dataset\")\n",
    "\n",
    "    weather_columns = [\"temprature_squared\", \"Left to Right\", \"Right to Left\", \"in\", \"out\", \"zero\"]\n",
    "    stitched_dataset[\"batting_stats\"][weather_columns] = stitched_dataset[\"batting_stats\"].apply(lambda x: stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk].iloc[0][weather_columns] if len(stats_with_weather[x.pitbat][stats_with_weather[x.pitbat].game_pk == x.game_pk]) > 0 else pd.Series({x:None for x in weather_columns}) , axis=1)\n",
    "    stitched_dataset[\"batting_stats\"][\"is_on_base\"] = stitched_dataset[\"batting_stats\"].play.apply(lambda x: 1 if x in on_bases else 0)\n",
    "    \n",
    "    # Attatch the League Average Information ### THIS IS STILL RUNNING FOR THE WHOLE DATASET - MAKE FOR JUST A ROLLING PERIOD!!!!\n",
    "    print(\"Attatching League Average Information\")\n",
    "    league_averages = {}\n",
    "    for pitbat_combo in hand_combos:\n",
    "        league_averages[pitbat_combo] = {}\n",
    "        pitbat_df = stitched_dataset[\"batting_stats\"][stitched_dataset[\"batting_stats\"].pitbat == pitbat_combo].copy()\n",
    "        for date in pitbat_df.game_date.unique():\n",
    "            league_averages[pitbat_combo][date] = {\"season\":{}, \"month\":{}}\n",
    "            season_pitbat_date_df = pitbat_df[pitbat_df.game_date < date][-1*min(504, len(pitbat_df)):].copy()\n",
    "            month_pitbat_date_df = pitbat_df[pitbat_df.game_date < date][-1*min(100, len(pitbat_df)):].copy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Find league average from the month, half season, and full seasons worth of time\n",
    "            \n",
    "            for play in plays:\n",
    "                season_play_average = len(season_pitbat_date_df[season_pitbat_date_df.play == play])/len(season_pitbat_date_df) if len(season_pitbat_date_df) > 0 else None\n",
    "                month_play_average = len(month_pitbat_date_df[month_pitbat_date_df.play == play])/len(month_pitbat_date_df) if len(month_pitbat_date_df) > 0 else None\n",
    "                \n",
    "                league_averages[pitbat_combo][date][\"season\"][play] = season_play_average\n",
    "                league_averages[pitbat_combo][date][\"month\"][play] = season_play_average\n",
    "\n",
    "    for play in plays:\n",
    "        stitched_dataset[\"batting_stats\"][\"season_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"season\"][play], axis=1)\n",
    "        stitched_dataset[\"batting_stats\"][\"month_league_average_{}\".format(play)] = stitched_dataset[\"batting_stats\"].apply(lambda x: league_averages[x.pitbat][x.game_date][\"month\"][play], axis=1)\n",
    "    \n",
    "    \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "    return stitched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "47e2309a-a92f-404f-8456-3072da6229f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_odds_dataset(training_years, pickle, rolling_period):\n",
    "\n",
    "    all_training_data = combine_raw_pitches(training_years)\n",
    "\n",
    "    game_play_share_data = calculate_game_play_shares(all_training_data)\n",
    "    league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "    data_for_weather_regression_set = clean_for_weather_regression(game_play_share_data)\n",
    "    data_for_weather_regression = data_for_weather_regression_set[0]\n",
    "\n",
    "    first_games_list = data_for_weather_regression_set[1]\n",
    "\n",
    "    weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "    weather_coefficients = weather_regression_set[1]\n",
    "\n",
    "    park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "    neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors, first_games_list, pickle)\n",
    "\n",
    "    individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats, False, rolling_period, 0, pickle)\n",
    "\n",
    "    rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats, False)\n",
    "\n",
    "    final_odds_dataset = finalize_odds_dataset(rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)[\"batting_stats\"]\n",
    "    \n",
    "    return {\"odds_dataset\":final_odds_dataset, \"league_averages\":league_averages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "343c52f0-7c6f-43e4-ad24-307bfa3a45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_years, pickle, rolling_period = [\"2012\"], False, 504\n",
    "\n",
    "# all_training_data = combine_raw_pitches(training_years)\n",
    "\n",
    "# game_play_share_data = calculate_game_play_shares(all_training_data)\n",
    "# league_averages = calculate_league_averages(game_play_share_data)\n",
    "\n",
    "# data_for_weather_regression_set = clean_for_weather_regression(game_play_share_data)\n",
    "# data_for_weather_regression = data_for_weather_regression_set[0]\n",
    "\n",
    "# first_games_list = data_for_weather_regression_set[1]\n",
    "\n",
    "# weather_regression_set = weather_regress(data_for_weather_regression)\n",
    "# weather_coefficients = weather_regression_set[1]\n",
    "\n",
    "# park_factors = calculate_park_factors(game_play_share_data)[1]\n",
    "\n",
    "# neutralized_stats = neutralize_stats(game_play_share_data, weather_coefficients, park_factors, first_games_list, pickle)\n",
    "\n",
    "# individual_rolled_factored_stats = roll_factored_batting_stats(neutralized_stats, False, 5, 0, pickle)\n",
    "\n",
    "# rolled_factored_stats = stitch_individual_stats(individual_rolled_factored_stats, False)\n",
    "\n",
    "# final_odds_dataset = finalize_odds_dataset(rolled_factored_stats, individual_rolled_factored_stats, neutralized_stats, data_for_weather_regression)[\"batting_stats\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b0c715ee-907b-4248-99f8-644cb104bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset = build_odds_dataset([\"2012\", \"2013\", \"2014\"], True, 504)\n",
    "pkl.dump(odds_dataset, open(\"dataset\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f737f5bb-15cd-4175-a219-b94f074fe38a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [170]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43modds_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "odds_dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726bf66-32eb-4b0b-8219-a6e0d1e69a4f",
   "metadata": {},
   "source": [
    "# Continued Cleaning/Pipeline for ML Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fb873c2d-2543-4c38-a126-7111e32ccfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset = pkl.load(open(\"dataset\", \"rb\"))[\"odds_dataset\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b737c718-a0ef-4611-bfa1-59140428999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"on_3b\", \"on_2b\", \"on_1b\"]:\n",
    "    odds_dataset[col] = odds_dataset[col].apply(lambda x: 1 if pd.isna(x) == False else 0) \n",
    "    \n",
    "for col in [\"inning_topbot\"]:\n",
    "     odds_dataset[col] = odds_dataset[col].apply(lambda x: 1 if x == \"Top\" else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9dba5ebb-25b5-4dd0-9775-d1f64560f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_full_df = odds_dataset[\"odds_dataset\"][[col for col in odds_dataset[\"odds_dataset\"].columns if col not in [\"game_date\",\"game_pk\", \"batter\", \"pitcher\", \"temprature\", \"wind_speed\", \"wind_direction\", \"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\", \"year\", \"ballpark\", \"pitbat\"]] + [\"ballpark\", \"pitbat\"]].dropna()\n",
    "ml_full_df = odds_dataset[[col for col in odds_dataset.columns if col not in [\"game_pk\", \"batter\", \"pitcher\", \"temprature\", \"wind_speed\", \"wind_direction\", \"year\", \"ballpark\", \"pitbat\"] + [\"season_{}\".format(p) for p in plays] + [\"month_{}\".format(p) for p in plays]] + [\"ballpark\", \"pitbat\"]].dropna()\n",
    "ml_full_df = ml_full_df[ml_full_df.game_date.apply(lambda x: int(x.split(\"-\")[1])) >= 5].reset_index(drop=True)\n",
    "ml_full_df.drop(columns = [\"game_date\"], inplace=True)\n",
    "ml_full_y_play = ml_full_df.play\n",
    "ml_full_y_on_base = ml_full_df.is_on_base\n",
    "ml_full_df.drop(columns = [\"play\", \"is_on_base\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e73896dd-d581-43bb-b27c-7bcf3bd05137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot',\n",
       "       'bat_score', 'fld_score', 'b_season_strikeout', 'b_month_strikeout',\n",
       "       'p_season_strikeout', 'p_month_strikeout', 'b_season_fly_out',\n",
       "       'b_month_fly_out', 'p_season_fly_out', 'p_month_fly_out',\n",
       "       'b_season_double', 'b_month_double', 'p_season_double',\n",
       "       'p_month_double', 'b_season_out', 'b_month_out', 'p_season_out',\n",
       "       'p_month_out', 'b_season_fielders_choice', 'b_month_fielders_choice',\n",
       "       'p_season_fielders_choice', 'p_month_fielders_choice', 'b_season_error',\n",
       "       'b_month_error', 'p_season_error', 'p_month_error', 'b_season_walk',\n",
       "       'b_month_walk', 'p_season_walk', 'p_month_walk', 'b_season_home_run',\n",
       "       'b_month_home_run', 'p_season_home_run', 'p_month_home_run',\n",
       "       'b_season_single', 'b_month_single', 'p_season_single',\n",
       "       'p_month_single', 'b_season_sacrifice', 'b_month_sacrifice',\n",
       "       'p_season_sacrifice', 'p_month_sacrifice', 'b_season_double_play',\n",
       "       'b_month_double_play', 'p_season_double_play', 'p_month_double_play',\n",
       "       'b_season_intent_walk', 'b_month_intent_walk', 'p_season_intent_walk',\n",
       "       'p_month_intent_walk', 'b_season_triple', 'b_month_triple',\n",
       "       'p_season_triple', 'p_month_triple', 'temprature_squared',\n",
       "       'Left to Right', 'Right to Left', 'in', 'out', 'zero',\n",
       "       'season_league_average_strikeout', 'month_league_average_strikeout',\n",
       "       'season_league_average_fly_out', 'month_league_average_fly_out',\n",
       "       'season_league_average_double', 'month_league_average_double',\n",
       "       'season_league_average_out', 'month_league_average_out',\n",
       "       'season_league_average_fielders_choice',\n",
       "       'month_league_average_fielders_choice', 'season_league_average_error',\n",
       "       'month_league_average_error', 'season_league_average_walk',\n",
       "       'month_league_average_walk', 'season_league_average_home_run',\n",
       "       'month_league_average_home_run', 'season_league_average_single',\n",
       "       'month_league_average_single', 'season_league_average_sacrifice',\n",
       "       'month_league_average_sacrifice', 'season_league_average_double_play',\n",
       "       'month_league_average_double_play', 'season_league_average_intent_walk',\n",
       "       'month_league_average_intent_walk', 'season_league_average_triple',\n",
       "       'month_league_average_triple', 'ballpark', 'pitbat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9fa8c3f0-a807-45e1-971e-9848ac789eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [col for col in ml_full_df if col not in [\"ballpark\", \"pitbat\"]]\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = [\"ballpark\", \"pitbat\"]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3d149796-62ef-451a-87c5-e778c8a1d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor)]\n",
    ")\n",
    "\n",
    "ml_full_df = ml_pipe.fit_transform(ml_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8ae0a7f9-30cf-42a2-98c5-c9491a8eb766",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(ml_full_df, open(\"ML X Dataset\", \"wb\"))\n",
    "pkl.dump(ml_full_y_play, open(\"ML Y Dataset (Plays)\", \"wb\"))\n",
    "pkl.dump(ml_full_y_on_base, open(\"ML Y Dataset (On Base)\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c07418-5972-4ce2-b077-ff4d123df717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
