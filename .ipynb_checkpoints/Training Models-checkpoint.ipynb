{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6f6950fb-8f3f-471e-a686-d336ab409a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pybaseball\n",
    "import sklearn\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, cross_validate, cross_val_predict, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from pybaseball import playerid_lookup, playerid_reverse_lookup\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from ipynb.fs.full.Building_Dataset_Functions import * \n",
    "\n",
    "hand_combos = [\"RR\", \"RL\", \"LR\", \"LL\"]\n",
    "training_years = [\"2012\", \"2013\", \"2014\"]\n",
    "\n",
    "plays = [\"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"]\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24633c10-8090-43b9-b60f-3f0653425617",
   "metadata": {},
   "source": [
    "### Odds Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "72a3e000-b62f-40c9-a2ce-9f2be6368c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log5 (pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the log5 equation. NOTE: DO NOT USE RIGHT NOW\"\"\" \n",
    "    one = (pB*pP)/pL\n",
    "    two = ((1-pB)*(1-pP))/(1-pL)\n",
    "    \n",
    "    return one/(one + two)\n",
    "\n",
    "\n",
    "def morey_z(pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the Morey Z equation\"\"\"\n",
    "    one = (pB-pL)/np.sqrt(pL*(1-pL))\n",
    "    two = (pP-pL)/np.sqrt(pL*(1-pL))\n",
    "    three = np.sqrt(pL*(1-pL))\n",
    "    return ((one + two)/np.sqrt(2) * three) +pL\n",
    "\n",
    "def ab_play_percentages(batting_percentages, pitching_percentages, league_percentages, pitbat_combo, function):\n",
    "    \"\"\" Given a list of probabilities for all PA outcomes for the batter, the pitcher, and the league, along with\n",
    "    the pitbat combo, and the desired probability funtion, return a list of the probabilities for all PA outcomes \n",
    "    for the specific PA\"\"\"\n",
    "    \n",
    "    ab_percentages = {}\n",
    "    \n",
    "    # Get the specific percentages for each play type\n",
    "    for play in plays:\n",
    "        batting_percent = batting_percentages[\"b_\" + play]\n",
    "        pitching_percent = pitching_percentages[\"p_\" + play]\n",
    "        league_percent = league_percentages[pitbat_combo][play]\n",
    "        \n",
    "        # Ensure we are using one of the two acceptable prediction functions\n",
    "        if function not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "            while funtion not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "                function = input(\"Acceptable Functions are Morey Z and Log5. Please input one.\")\n",
    "        \n",
    "        # Calculate the predicted percentage for the specific play for the PA\n",
    "        if function == \"morey z\" or function == \"Morey Z\":\n",
    "            expected_percent = max(morey_z(batting_percent, pitching_percent, league_percent), 0.000001)\n",
    "        else:\n",
    "            expected_percent = log5(batting_percent, pitching_percent, league_percent)\n",
    "    \n",
    "        # Insert the predicted percentage for the play type into our dictionary for delivery\n",
    "        ab_percentages[play] = expected_percent\n",
    "        \n",
    "        # Get rid of negative and zero numbers and repercenage slightly if numbers are reset\n",
    "        ab_percentages = {key: value/sum(list(ab_percentages.values())) for key, value in ab_percentages.items()}\n",
    "    \n",
    "    return ab_percentages\n",
    "\n",
    "# League Average Guesser\n",
    "def average_guesser(batting_percentages, pitching_percentages, league_percentages, pitbat_combo):\n",
    "    ab_percentages = {}\n",
    "    \n",
    "    for play in plays:\n",
    "        league_percent = league_percentages[pitbat_combo][play]\n",
    "        ab_percentages[play] = league_percent\n",
    "        \n",
    "    ab_percentages = {key: value/sum(list(ab_percentages.values())) for key, value in ab_percentages.items()}\n",
    "    \n",
    "    return ab_percentages  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5c6311d7-843b-480c-acfd-aad8dc4d57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(probabilities, actuals):\n",
    "    \"\"\" Given a list of probabilities and acuals for a series of instances, calculate and return the average log loss\"\"\"\n",
    "    log_loss = 0\n",
    "    yhat_probabilities = []\n",
    "    for instance in range(len(probabilities)):\n",
    "        yhat_probabilities.append(max([n for n in np.array(probabilities.iloc[instance])*np.array(actuals.iloc[instance])]))\n",
    "    log_loss -= sum([np.log10(x)for x in yhat_probabilities])\n",
    "\n",
    "\n",
    "    return log_loss/len(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a51353-f359-4999-93fc-29f0ed08da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset = pkl.load(open(\"odds_functions_data_set\", \"rb\"))\n",
    "odds_dataset = pkl.load(open(\"odds_functions_dataset_without_yearbreaks.pkl\", \"rb\"))[\"batting_stats\"]\n",
    "\n",
    "league_averages = pkl.load(open(\"league_averages.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e791d36-33bd-433f-9513-efb3467424a4",
   "metadata": {},
   "source": [
    "## Make Odds Predictions on Neutral Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beadfdbf-f7f2-4b14-8a84-d143898d0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset[\"morey_prediction\"] = odds_dataset.apply(lambda x: ab_play_percentages(x[[\"b_\" + play for play in plays]], x[[\"p_\" + play for play in plays]], league_averages, x.pitbat, \"morey z\"), axis = 1)\n",
    "odds_dataset[\"morey_prediction_list\"] = odds_dataset.morey_prediction.apply(lambda x: list(x.values()))\n",
    "\n",
    "odds_dataset[\"la_prediction\"] = odds_dataset.apply(lambda x: average_guesser(x[[\"b_\" + play for play in plays]], x[[\"p_\" + play for play in plays]], league_averages, x.pitbat), axis = 1)\n",
    "odds_dataset[\"la_prediction_list\"] = odds_dataset.la_prediction.apply(lambda x: list(x.values()))\n",
    "\n",
    "odds_dataset[\"actuals\"] = odds_dataset.apply(lambda x: list(x.la_prediction.keys()).index(x.play),axis=1)\n",
    "\n",
    "odds_dataset['yhat'] = odds_dataset.actuals.apply(lambda x: [0]*len(plays))\n",
    "odds_dataset['yhat'] = odds_dataset.apply(lambda x: x.yhat[0:x.actuals] +[1] +  x.yhat[x.actuals+1:], axis=1)\n",
    "\n",
    "odds_dataset = odds_dataset.drop(columns = [\"morey_prediction\", \"la_prediction\"])\n",
    "\n",
    "# Remove some instances with NA from pitchers who only make 1 app\n",
    "odds_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7ad2dd-8b6e-489d-8caa-b3b6aa6beb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crappy Log Loss: 0.6243287896373452\n",
      "Morey Log Loss: 0.6917390575292162\n"
     ]
    }
   ],
   "source": [
    "crappy_log_loss = log_loss(odds_dataset.la_prediction_list, odds_dataset.yhat)\n",
    "morey_log_loss = log_loss(odds_dataset.morey_prediction_list, odds_dataset.yhat)\n",
    "\n",
    "print(\"Crappy Log Loss: {}\".format(crappy_log_loss))\n",
    "print(\"Morey Log Loss: {}\".format(morey_log_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3f94ff-83be-4e7c-9f31-817c02ab3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out's average value is 0.4821648345592577\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m morey_predictions \u001b[38;5;241m=\u001b[39m log_loss(df\u001b[38;5;241m.\u001b[39mmorey_prediction_list, df\u001b[38;5;241m.\u001b[39myhat)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms average value is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(play_percent))\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms crappy average prediction value is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcrappy_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(crappy_predictions)))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms morey average prediction value is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(morey_predictions)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(morey_predictions)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "for play in plays:\n",
    "    df = odds_dataset[odds_dataset.play == play].copy()\n",
    "    play_percent = len(df)/len(odds_dataset)\n",
    "    \n",
    "    crappy_predictions = log_loss(df.la_prediction_list, df.yhat)\n",
    "    morey_predictions = log_loss(df.morey_prediction_list, df.yhat)\n",
    "    \n",
    "    print(str(play) + \"'s average value is {}\".format(play_percent))\n",
    "    print(str(play) + \"'s crappy average prediction value is: {}\".format(sum(crappy_predictions)/len(crappy_predictions)))\n",
    "    print(str(play) + \"'s morey average prediction value is: {}\".format(sum(morey_predictions)/len(morey_predictions)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb2a5b-a470-481e-a0a5-4781e569cd50",
   "metadata": {},
   "source": [
    "# ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "287799aa-323b-4819-928a-9cd9056958df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pkl.load(open(\"ML X Dataset\", \"rb\"))\n",
    "Y_play = pkl.load(open(\"ML Y Dataset (Plays)\", \"rb\"))\n",
    "Y_onbase = pkl.load(open(\"ML Y Dataset (On Base)\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ea2f2cf5-75a5-4401-acec-e962df463c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(ml_full_df, y_full, test_size=0.2, random_state=42)\n",
    "sss = StratifiedShuffleSplit(test_size=.2, random_state=42)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train_plays, y_test_plays = Y_play[train_index], Y_play[test_index]\n",
    "    y_train_onbase, y_test_onbase = Y_onbase[train_index], Y_onbase[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddc797-50d7-47d2-826a-63460dee0682",
   "metadata": {},
   "source": [
    "## Crappy Average Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e81d1b2c-b70d-4931-8f3a-5ad183dfaa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Crappy Average Estimator for Predicting Plays Has a Neg Log Loss of: -1.436\n",
      "The Crappy Average Estimator for Predicting On Base Has a Neg Log Loss of: -0.628\n"
     ]
    }
   ],
   "source": [
    "dumb_log_loss_plays = 0\n",
    "league_averages_plays = {}\n",
    "for play in y_train_plays.value_counts().index:\n",
    "    league_averages_plays[play] = len(y_train_plays[y_train_plays == play])/len(y_train_plays)\n",
    "    dumb_log_loss_plays += len(y_train_plays[y_train_plays == play])/len(y_train_plays)* np.log(len(y_train[y_train_plays == play])/len(y_train_plays))\n",
    "    \n",
    "    \n",
    "dumb_log_loss_onbase = 0\n",
    "league_averages_onbase = {}\n",
    "for play in y_train_onbase.value_counts().index:\n",
    "    league_averages_onbase[play] = len(y_train_onbase[y_train_onbase == play])/len(y_train_onbase)\n",
    "    dumb_log_loss_onbase += len(y_train_onbase[y_train_onbase == play])/len(y_train_onbase)* np.log(len(y_train[y_train_onbase == play])/len(y_train_onbase))\n",
    "    \n",
    "print(\"The Crappy Average Estimator for Predicting Plays Has a Neg Log Loss of: {}\".format(round(dumb_log_loss_plays,3)))\n",
    "print(\"The Crappy Average Estimator for Predicting On Base Has a Neg Log Loss of: {}\".format(round(dumb_log_loss_onbase,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af0e28-f924-4f08-8c26-cf1be1fc0b65",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0271ef6-2b8d-4181-929d-7c69d1527728",
   "metadata": {},
   "source": [
    "### Basic Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b30b83a9-4bb0-452b-9f04-4f22387b4809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Logistic Regressor (Plays) Has a Neg Log Loss of: -1.414\n",
      "The Basic Logistic Regressor (On Base) Has a Neg Log Loss of: -0.625\n"
     ]
    }
   ],
   "source": [
    "softmax_plays = LogisticRegression(class_weight = None, max_iter=150)\n",
    "softmax_plays_scores = cross_val_score(softmax_plays, x_train, y_train_plays, cv=5, scoring = \"neg_log_loss\", n_jobs=4)\n",
    "print(\"The Basic Logistic Regressor (Plays) Has a Neg Log Loss of: {}\".format(round(softmax_plays_scores.mean(),3)))\n",
    "\n",
    "\n",
    "softmax_onbase = LogisticRegression(max_iter=150)\n",
    "softmax_onbase_scores = cross_val_score(softmax_onbase, x_train, y_train_onbase, cv=5, scoring = \"neg_log_loss\", n_jobs=4)\n",
    "print(\"The Basic Logistic Regressor (On Base) Has a Neg Log Loss of: {}\".format(round(softmax_onbase_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa2f89-352c-489c-9fac-f373ac1b433c",
   "metadata": {},
   "source": [
    "### Grid Search Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc027b90-8e79-4136-86cf-772dd4b3c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary of class weights to grid search on due to impalanced Dataset\n",
    "class_weights = list(y_train.value_counts().index)\n",
    "class_weights_list = []\n",
    "\n",
    "for n in range(1):\n",
    "    weights = np.random.rand(len(class_weights))\n",
    "    weights = weights/sum(weights)\n",
    "    weights = {class_weights[x]:weights[x] for x in range(len(class_weights))}\n",
    "    \n",
    "    class_weights_list.append(weights)\n",
    "    \n",
    "class_weights_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df684ae-e15c-45f2-8464-b6a9fcdc963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':np.linspace(0.001,1,2), \"solver\":[\"newton-cg\"], \"class_weight\":class_weights_list,\n",
    "              'multi_class':[\"ovr\"]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs = 4)\n",
    "grid_search.fit(x_train, y_train)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877be3bd-e2b0-461d-90c3-f747b9fd0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Logistic Regressor Has a Neg Log Loss Of: -1.414\n",
      "The Best Logistic Regressor Has Parameters Of: {'C': 1.0, 'class_weight': None, 'multi_class': 'ovr', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "final_logistic_regressor = grid_search.best_estimator_\n",
    "print(\"The Best Logistic Regressor Has a Neg Log Loss Of: {}\".format(round(grid_search.best_score_.mean(), 3)))\n",
    "print(\"The Best Logistic Regressor Has Parameters Of: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f1e6a-44d7-4286-aa62-b7141c72e7ca",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4ef11-bbba-4339-80ec-cf08ce4ab9fb",
   "metadata": {},
   "source": [
    "### Basic K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "52e01703-743a-43f5-8bcb-12b5239fa17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic kNeighbors Classifier (Plays) Has a Neg Log Loss of: -9.685\n",
      "The Basic kNeighbors Classifier (On Base) Has a Neg Log Loss of: -2.257\n"
     ]
    }
   ],
   "source": [
    "knc_plays = KNeighborsClassifier()\n",
    "knc_scores_plays = cross_val_score(knc_plays, x_train, y_train_plays, cv=5, scoring = \"neg_log_loss\", n_jobs=1)\n",
    "print(\"The Basic kNeighbors Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(knc_scores_plays.mean(),3)))\n",
    "\n",
    "knc_onbase = KNeighborsClassifier()\n",
    "knc_scores_onbase = cross_val_score(knc_onbase, x_train, y_train_onbase, cv=5, scoring = \"neg_log_loss\", n_jobs=1)\n",
    "print(\"The Basic kNeighbors Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(knc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29f728-853c-4cfc-9bb0-92a678baed36",
   "metadata": {},
   "source": [
    "### Grid Search K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e71d8dc3-cb7c-44d5-a496-416d69e78b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the K Neighbors Grid Search Below\n",
    "n_neighbors_params = [1000]\n",
    "weights_params = [\"uniform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bb9fdfbf-d4e4-43cb-801d-3cffdc87e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_parameters = {'n_neighbors':n_neighbors_params, \"weights\":weights_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "knc_grid_search_plays = GridSearchCV(KNeighborsClassifier(), knc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "knc_grid_search_plays.fit(x_train, y_train_plays)\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "knc_grid_search_onbase = GridSearchCV(KNeighborsClassifier(), knc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "knc_grid_search_onbase.fit(x_train, y_train_onbase)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e79e3c21-31d5-46f5-a589-332f26ae5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best K Neighbors Classifier Has a Neg Log Loss Of: -1.419\n",
      "The Best K Neighbors Classifier Has Parameters Of: {'n_neighbors': 1000, 'weights': 'uniform'}\n",
      "The Best K Neighbors Classifier Has a Neg Log Loss Of: -0.626\n",
      "The Best K Neighbors Classifier Has Parameters Of: {'n_neighbors': 1000, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "final_KNC_regressor_plays = knc_grid_search_plays.best_estimator_\n",
    "print(\"The Best K Neighbors Classifier Has a Neg Log Loss Of: {}\".format(round(knc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best K Neighbors Classifier Has Parameters Of: {}\".format(knc_grid_search_plays.best_params_))\n",
    "\n",
    "final_KNC_regressor_onbase = knc_grid_search_onbase.best_estimator_\n",
    "print(\"The Best K Neighbors Classifier Has a Neg Log Loss Of: {}\".format(round(knc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best K Neighbors Classifier Has Parameters Of: {}\".format(knc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cecd6-7afb-43f2-a5d9-d45f6de9ed6e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c541f-e590-4ba4-bb08-623c1dc5cf98",
   "metadata": {},
   "source": [
    "### Basic Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7471a7a6-88b9-41db-a3d9-237811f2d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Random Forest Classifier (Plays) Has a Neg Log Loss of: -2.633\n",
      "The Basic Random Forest Classifier (On Base) Has a Neg Log Loss of: -0.805\n"
     ]
    }
   ],
   "source": [
    "rf_plays = RandomForestClassifier(random_state=42)\n",
    "rf_scores_plays = cross_val_score(rf_plays, x_train, y_train_plays, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Random Forest Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(rf_scores_plays.mean(),3)))\n",
    "\n",
    "rf_onbase = RandomForestClassifier(random_state=42)\n",
    "rf_scores_onbase = cross_val_score(rf_onbase, x_train, y_train_onbase, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Random Forest Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(rf_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa3708-b682-4733-9971-04f0ac3f4718",
   "metadata": {},
   "source": [
    "### Grid Search for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ad5af3cd-b71d-4bc5-8884-b09b53eb3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the Random Forest Grid Search Below\n",
    "estimators_params= [900, 1100, 1300]\n",
    "criterion_params = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth_params = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "01b318b7-d861-4c0a-9640-61c70f18cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {'n_estimators':estimators_params, \"criterion\":criterion_params, \"max_depth\":max_depth_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "rf_grid_search_plays = GridSearchCV(RandomForestClassifier(random_state = 42), rf_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "rf_grid_search_plays.fit(x_train[:10000], y_train_plays[:10000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "rf_grid_search_onbase = GridSearchCV(RandomForestClassifier(random_state = 42), rf_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "rf_grid_search_onbase.fit(x_train[:10000], y_train_onbase[:10000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6cc0f94d-a1a2-4331-b767-bfa92836642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: -1.426\n",
      "The Best Random Forest Classifier (On Base) Has Parameters Of: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1100}\n",
      "The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: -0.631\n",
      "The Best Random Forest Classifier (On Base) Has Parameters Of: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "final_RF_regressor_plays = rf_grid_search_plays.best_estimator_\n",
    "print(\"The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(rf_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Random Forest Classifier (On Base) Has Parameters Of: {}\".format(rf_grid_search_plays.best_params_))\n",
    "\n",
    "final_RF_regressor_onbase = rf_grid_search_onbase.best_estimator_\n",
    "print(\"The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(rf_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Random Forest Classifier (On Base) Has Parameters Of: {}\".format(rf_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99ccfb-1e38-4104-8668-4be590bc0d7d",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51353baf-a3b8-44d0-8a30-a09cbaec7e1e",
   "metadata": {},
   "source": [
    "### Basic Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c1ca2b39-d918-48f3-b87c-3fa211174262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Support Vector Classifier (Plays) Has a Neg Log Loss of: -1.465\n",
      "The Basic Support Vector Classifier (On Base) Has a Neg Log Loss of: -0.645\n"
     ]
    }
   ],
   "source": [
    "svc_plays = SVC(probability=True)\n",
    "svc_scores_plays = cross_val_score(svc_plays, x_train[:2000], y_train_plays[:2000], cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Support Vector Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(svc_scores_plays.mean(),3)))\n",
    "\n",
    "svc_onbase = SVC(probability=True)\n",
    "svc_scores_onbase = cross_val_score(svc_onbase, x_train[:2000], y_train_onbase[:2000], cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Support Vector Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(svc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df1cac-f6ae-47e0-ab5c-bb9eea3495fe",
   "metadata": {},
   "source": [
    "### Grid Search for Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "60051da3-f698-4d05-b41e-a2cf9f10905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the Support Vector Classifier Grid Search Below\n",
    "C_params= [.33,.66, 1]\n",
    "kernel_params = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "degree_params = [3,5,7]\n",
    "gamma_params = [\"auto\", \"scale\"]\n",
    "class_weight_params = [None, \"balanced\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46bb8-d747-48fb-b9f7-48fc2ab4d1ca",
   "metadata": {},
   "source": [
    "Because SVCs scale poorly with n instances, we can try training the model on a subset of the training data. The below cells first find a suitible SVC to test on the subsample, and then cross_val_score and increasing sizes of the sample to check where the cross-entropy levels out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "648b375f-e078-4340-a4f5-1ead8163a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search For Plays\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5] END C=0.33, class_weight=None, degree=3, gamma=auto, kernel=linear;, score=-1.448 total time=   4.1s\n",
      "[CV 2/5] END C=0.33, class_weight=None, degree=3, gamma=auto, kernel=linear;, score=-1.449 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a Grid Search for our SVC on a 5000 instance subset of the training data\n",
    "svc_parameters = {'C':C_params, \"kernel\":kernel_params, \"degree\":degree_params, \"gamma\":gamma_params, \"class_weight\":class_weight_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "svc_grid_search_plays = GridSearchCV(SVC(probability=True), svc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 5)\n",
    "svc_grid_search_plays.fit(x_train[:5000], y_train_plays[:5000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "svc_grid_search_onbase = GridSearchCV(SVC(probability=True), svc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 5)\n",
    "svc_grid_search_onbase.fit(x_train[:5000], y_train_onbase[:5000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db926a10-24a0-4328-9188-0d5b4c9c067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SVC_regressor_plays = svc_grid_search_plays.best_estimator_\n",
    "print(\"The Best Support Vector Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(svc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Support Vector Classifier (Plays) Has Parameters Of: {}\".format(svc_grid_search.best_params_))\n",
    "\n",
    "final_SVC_regressor_onbase = svc_grid_search_onbase.best_estimator_\n",
    "print(\"The Best Support Vector Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(svc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Support Vector Classifier (On Base) Has Parameters Of: {}\".format(svc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eff8d424-a63f-4d3c-96ac-4ecae7d86e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_dict_II = {}\n",
    "for n in [15000]:\n",
    "    print(n)\n",
    "    model = SVC(C=.33, class_weight=\"balanced\", degree=7, gamma=\"auto\", kernel=\"rbf\", probability=True)\n",
    "    score = cross_val_score(model, x_train[:n], y_train[:n], cv=5, scoring=\"neg_log_loss\", verbose=3, error_score=\"raise\", n_jobs=4)\n",
    "    score_dict_II[n] = -score.mean()\n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5fc6bf0-9766-4ea2-9397-654c9f11d9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f67fca0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_dict_II.keys(), score_dict_II.values())\n",
    "plt.title(\"SVC Log Loss With Sample Size n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4719be-64c1-46bd-b3e5-c02b121afa72",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b78946-3c5d-440b-a049-79ab306a68ef",
   "metadata": {},
   "source": [
    "Similar to the SVC, we will attempt to find a suitable model on a smaller sample of the data, although we can train the final model on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab53369-cc76-46b0-a45a-d4f6b9c70770",
   "metadata": {},
   "source": [
    "### Basic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "42c9c509-0894-4d6b-b1ee-2d4dd241e620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   12.4s remaining:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: -1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: -0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "gbc_plays = GradientBoostingClassifier()\n",
    "gbc_scores_plays = cross_val_score(gbc_plays, x_train[:5000], y_train_plays[:5000], cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Basic Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(gbc_scores_plays.mean(),3)))\n",
    "\n",
    "gbc_onbase = GradientBoostingClassifier()\n",
    "gbc_scores_onbase = cross_val_score(gbc_onbase, x_train[:5000], y_train_onbase[:5000], cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Basic Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(gbc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297fa33c-5f0f-4a79-a7c1-dd9f3cf4da6d",
   "metadata": {},
   "source": [
    "### Grid Search for Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f2b430-afe1-46bf-9acd-8c65f0db8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_params = [100, 200, 300]\n",
    "depth_params = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae67fd5a-558f-4f2d-ac46-c2b9fa31053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_parameters = {'n_estimators':estimator_params, \"max_depth\":depth_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "gbc_grid_search_plays = GridSearchCV(GradientBoostingClassifier(), gbc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs=4)\n",
    "gbc_grid_search_plays.fit(x_train[:5000], y_train_plays[:5000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "gbc_grid_search_onbase = GridSearchCV(GradientBoostingClassifier(), gbc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs=4)\n",
    "gbc_grid_search_onbase.fit(x_train[:5000], y_train_onbase[:5000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17669502-7a3f-4315-ad28-6bb2ae1cc976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Gradient Boosted Classifier Has a Neg Log Loss Of: -1.481\n",
      "The Best Gradient Boosted Classifier Has Parameters Of: {'max_depth': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "final_GBC_regressor_plays = gbc_grid_search.best_estimator_\n",
    "print(\"The Best Gradient Boosted Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(gbc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Gradient Boosted Classifier (Plays Has Parameters Of: {}\".format(gbc_grid_search_plays.best_params_))\n",
    "\n",
    "final_GBC_regressor_onbase = gbc_grid_search.best_estimator_\n",
    "print(\"The Best Gradient Boosted Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(gbc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Gradient Boosted Classifier (On Base) Has Parameters Of: {}\".format(gbc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9b446-4c67-4f82-9801-65497bb90bf7",
   "metadata": {},
   "source": [
    "#### Histogram Based Option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebcf95-5eba-4a36-b0aa-802a711fcc8a",
   "metadata": {},
   "source": [
    "Because of the testing limitations, we will also try a Histogram-based Gradient Boosting Classification Tree, which scales significantly better than the standard gradient boosting tree. It does not appear to support grid search however, so we will do that manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cd1219bc-fa6b-4a89-b59d-766b44b9801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Hist Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: -1.415\n",
      "The Basic Hist Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: -0.625\n"
     ]
    }
   ],
   "source": [
    "hgbc_plays = HistGradientBoostingClassifier()\n",
    "hgbc_scores_plays = cross_val_score(hgbc_plays, x_train, y_train_plays, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic Hist Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(hgbc_scores_plays.mean(),3)))\n",
    "\n",
    "hgbc_onbase = HistGradientBoostingClassifier()\n",
    "hgbc_scores_onbase = cross_val_score(hgbc_onbase, x_train, y_train_onbase, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic Hist Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(hgbc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c793e48-cd2e-45f0-8152-23c4b292a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_params = [30, 50, 70]\n",
    "depth_params = [5, 10, None]\n",
    "max_leaf_params = [2, 3, None]\n",
    "\n",
    "all_param_lists = [iter_params, depth_params, max_leaf_params]\n",
    "\n",
    "hgbc_param_list = list(itertools.product(*all_param_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8228515f-027e-41f0-bc67-bfb53c5d42c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for the Plays Model\n",
    "print(\"Grid Search For Plays\")\n",
    "\n",
    "best_score_plays = -10000\n",
    "best_params_plays = {}\n",
    "for tup in hgbc_param_list:\n",
    "    print(tup)\n",
    "    score = cross_val_score(HistGradientBoostingClassifier(max_iter=tup[0], max_depth = tup[1], max_leaf_nodes = tup[2]), x_train, y_train_plays, cv=5,\n",
    "                                                          n_jobs = 4, scoring=\"neg_log_loss\").mean()\n",
    "    \n",
    "    if score > best_score_plays:\n",
    "        best_score_plays = score\n",
    "        best_params_plays = {\"max_iter\":tup[0], \"max_depth\":tup[1], \"max_leaf_nodes\":tup[2],}\n",
    "                            \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "# And Grid Search Again for the On Base Model\n",
    "print(\"Grid Search For On Base\")\n",
    "\n",
    "best_score_onbase = -10000\n",
    "best_params_onbase = {}\n",
    "for tup in hgbc_param_list:\n",
    "    print(tup)\n",
    "    score = cross_val_score(HistGradientBoostingClassifier(max_iter=tup[0], max_depth = tup[1], max_leaf_nodes = tup[2]), x_train, y_train_onbase, cv=5,\n",
    "                                                          n_jobs = 4, scoring=\"neg_log_loss\").mean()\n",
    "    \n",
    "    if score > best_score_onbase:\n",
    "        best_score_onbase = score\n",
    "        best_params_onbase = {\"max_iter\":tup[0], \"max_depth\":tup[1], \"max_leaf_nodes\":tup[2],}\n",
    "                            \n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7ea1894-ce92-4106-856b-49cea051a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Histogram-Based Gradient Boosted Classifier Has a Neg Log Loss Of: -1.413\n",
      "The Best Histogram-Based Gradient Boosted Classifier Has Parameters Of: {'max_iter': 70, 'max_depth': 5, 'max_leaf_nodes': 3}\n"
     ]
    }
   ],
   "source": [
    "final_HGBC_regressor_plays = HistGradientBoostingClassifier(max_iter=best_params_plays[\"max_iter\"], max_depth = best_params_plays[\"max_depth\"], max_leaf_nodes = best_params_plays[\"max_leaf_nodes\"])\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(best_score_plays, 3)))\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (Plays) Has Parameters Of: {}\".format(best_params_plays))\n",
    "\n",
    "final_HGBC_regressor_onbase = HistGradientBoostingClassifier(max_iter=best_params_onbase[\"max_iter\"], max_depth = best_params_onbase[\"max_depth\"], max_leaf_nodes = best_params_onbase[\"max_leaf_nodes\"])\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(best_score_onbase, 3)))\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (On Base) Has Parameters Of: {}\".format(best_params_onbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92f140-043d-4e64-afd5-4ae7c660377d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443619b-60a6-455c-9593-0eb7030cd580",
   "metadata": {},
   "source": [
    "### Basic ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd0e4650-b2db-4167-a101-ec4e8dd7907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic ADA Boost Classifier Has a Neg Log Loss of: -1.919\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc_scores = cross_val_score(abc, x_train, y_train, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic ADA Boost Classifier Has a Neg Log Loss of: {}\".format(round(abc_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "706e2475-6de0-4b87-9429-a948ff459b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   24.8s remaining:   37.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic ADA Boost Classifier Has a Neg Log Loss of: -1.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   47.9s finished\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(base_estimator = SVC(), algorithm = \"SAMME\")\n",
    "abc_scores = cross_val_score(abc, x_train[:2000], y_train[:2000], cv=5, scoring=\"neg_log_loss\", n_jobs = 4, verbose=3)\n",
    "print(\"The Basic ADA Boost Classifier Has a Neg Log Loss of: {}\".format(round(abc_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab25115-2855-47b3-b8f3-e6e7a143e700",
   "metadata": {},
   "source": [
    "### Grid Search for ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "283f507d-3cc6-4783-b928-70e45da1e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_params = [300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25c98934-e363-4a1c-927e-23b8fecb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_parameters = {'n_estimators':estimators_params}\n",
    "\n",
    "abc_grid_search = GridSearchCV(AdaBoostClassifier(random_state = 42), abc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "abc_grid_search.fit(x_train[:30000], y_train[:30000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "781e8c5f-8343-4637-9d5f-fe91a8e46be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Ada Boost Classifier Has a Neg Log Loss Of: -1.936\n",
      "The Best Ada Boost Classifier Has Parameters Of: {'n_estimators': 300}\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  24.8s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  25.4s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  25.4s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  24.4s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  23.4s\n"
     ]
    }
   ],
   "source": [
    "final_abc_regressor = abc_grid_search.best_estimator_\n",
    "print(\"The Best Ada Boost Classifier Has a Neg Log Loss Of: {}\".format(round(abc_grid_search.best_score_, 3)))\n",
    "print(\"The Best Ada Boost Classifier Has Parameters Of: {}\".format(abc_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b76f21-3e64-4cb0-82ad-a31486ecacc2",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "176e1347-1db6-483e-8535-218e09bb481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = [int(x[0]) for x in y_train_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0dc9e-c03d-4647-9a64-4d807fc0fa6f",
   "metadata": {},
   "source": [
    "### Basic XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34fddf7e-e003-4f14-a483-09211a20a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   18.0s remaining:   26.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic XGBoost Boost Classifier Has a Neg Log Loss of: -1.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb_scores = cross_val_score(xgb, x_train, y_train_encoded, cv=5, scoring=\"neg_log_loss\", n_jobs=4, verbose = 3)\n",
    "print(\"The Basic XGBoost Boost Classifier Has a Neg Log Loss of: {}\".format(round(xgb_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99cc79-fd1a-4551-a5af-355e1407ad50",
   "metadata": {},
   "source": [
    "### Grid Search for XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f84c72cf-d3a5-4525-86d1-7efed61efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_weight_params = [1, 5]\n",
    "gamma_params = [.5, 1, 1.5]\n",
    "subsample_params = [.6, .8]\n",
    "colsample_bytree_params = [.6, .8]\n",
    "max_depth_params = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86b73718-169a-4999-b0f7-bbae85ca9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'min_child_weight': child_weight_params,'gamma': gamma_params,'subsample': subsample_params,\n",
    "              'colsample_bytree': colsample_bytree_params,'max_depth': max_depth_params}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(XGBClassifier(), xgb_params, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "xgb_grid_search.fit(x_train[:30000], y_train_encoded[:30000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c273092a-4053-4828-868e-703fcc40f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Ada Boost Classifier Has a Neg Log Loss Of: -1.423\n",
      "The Best Ada Boost Classifier Has Parameters Of: {'colsample_bytree': 0.6, 'gamma': 1.5, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "final_xgb_regressor = xgb_grid_search.best_estimator_\n",
    "print(\"The Best XGBoost Classifier Has a Neg Log Loss Of: {}\".format(round(xgb_grid_search.best_score_, 3)))\n",
    "print(\"The Best XABoost Classifier Has Parameters Of: {}\".format(xgb_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fe78c094-6af1-4299-b347-f562a915071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   12.3s remaining:   18.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best XGBoost Classifier Has a Neg Log Loss Of: -1.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   18.3s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb_grid_search.best_estimator_, x_train, y_train_encoded, cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Best XGBoost Classifier Has a Neg Log Loss Of: {}\".format(round(scores.mean(), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7e18a-8802-4f5b-925f-6ddfe3da4c55",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "89ed6357-fc46-4a60-88b4-72a726719a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33408/33408 [==============================] - 12s 365us/step - loss: 1.4230 - sparse_categorical_crossentropy: 1.4230\n",
      "Epoch 2/150\n",
      "33408/33408 [==============================] - 12s 372us/step - loss: 1.4155 - sparse_categorical_crossentropy: 1.4155\n",
      "Epoch 3/150\n",
      "33408/33408 [==============================] - 12s 363us/step - loss: 1.4148 - sparse_categorical_crossentropy: 1.4148\n",
      "Epoch 4/150\n",
      "33408/33408 [==============================] - 12s 358us/step - loss: 1.4144 - sparse_categorical_crossentropy: 1.4144\n",
      "Epoch 5/150\n",
      "33408/33408 [==============================] - 12s 356us/step - loss: 1.4144 - sparse_categorical_crossentropy: 1.4144\n",
      "Epoch 6/150\n",
      "33408/33408 [==============================] - 12s 356us/step - loss: 1.4141 - sparse_categorical_crossentropy: 1.4141\n",
      "Epoch 7/150\n",
      "33408/33408 [==============================] - 13s 377us/step - loss: 1.4143 - sparse_categorical_crossentropy: 1.4143\n",
      "Epoch 8/150\n",
      "33408/33408 [==============================] - 12s 371us/step - loss: 1.4141 - sparse_categorical_crossentropy: 1.4141\n",
      "Epoch 9/150\n",
      "33408/33408 [==============================] - 12s 370us/step - loss: 1.4139 - sparse_categorical_crossentropy: 1.4139\n",
      "Epoch 10/150\n",
      "33408/33408 [==============================] - 12s 370us/step - loss: 1.4139 - sparse_categorical_crossentropy: 1.4139\n",
      "Epoch 11/150\n",
      "33408/33408 [==============================] - 12s 369us/step - loss: 1.4139 - sparse_categorical_crossentropy: 1.4139\n",
      "Epoch 12/150\n",
      "33408/33408 [==============================] - 13s 375us/step - loss: 1.4138 - sparse_categorical_crossentropy: 1.4138\n",
      "Epoch 13/150\n",
      "33408/33408 [==============================] - 12s 367us/step - loss: 1.4137 - sparse_categorical_crossentropy: 1.4137\n",
      "Epoch 14/150\n",
      "33408/33408 [==============================] - 12s 357us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 15/150\n",
      "33408/33408 [==============================] - 12s 361us/step - loss: 1.4137 - sparse_categorical_crossentropy: 1.4137\n",
      "Epoch 16/150\n",
      "33408/33408 [==============================] - 12s 355us/step - loss: 1.4137 - sparse_categorical_crossentropy: 1.4137\n",
      "Epoch 17/150\n",
      "33408/33408 [==============================] - 12s 354us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 18/150\n",
      "33408/33408 [==============================] - 12s 356us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 19/150\n",
      "33408/33408 [==============================] - 12s 354us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 20/150\n",
      "33408/33408 [==============================] - 12s 354us/step - loss: 1.4135 - sparse_categorical_crossentropy: 1.4135\n",
      "Epoch 21/150\n",
      "33408/33408 [==============================] - 12s 372us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 22/150\n",
      "33408/33408 [==============================] - 14s 423us/step - loss: 1.4135 - sparse_categorical_crossentropy: 1.4135\n",
      "Epoch 23/150\n",
      "33408/33408 [==============================] - 13s 377us/step - loss: 1.4135 - sparse_categorical_crossentropy: 1.4135\n",
      "Epoch 24/150\n",
      "33408/33408 [==============================] - 13s 376us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n",
      "Epoch 25/150\n",
      "33408/33408 [==============================] - 12s 358us/step - loss: 1.4137 - sparse_categorical_crossentropy: 1.4137\n",
      "Epoch 26/150\n",
      "33408/33408 [==============================] - 12s 357us/step - loss: 1.4135 - sparse_categorical_crossentropy: 1.4135\n",
      "Epoch 27/150\n",
      "33408/33408 [==============================] - 12s 358us/step - loss: 1.4136 - sparse_categorical_crossentropy: 1.4136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29f9d4d60>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='sparse_categorical_crossentropy', patience=5, start_from_epoch=4, restore_best_weights = True)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 10 nodes and specify the input shape (54 inputs)\n",
    "model.add(Dense(10, input_shape=(54,), activation='relu'))\n",
    "\n",
    "# Add the second hidden layer with 10 nodes\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 nodes (for 7 categorical outputs) and 'softmax' activation\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Call model on a test input\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_crossentropy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(x_train, np.array(y_train_encoded), epochs=150, batch_size=10, callbacks = [callback])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
