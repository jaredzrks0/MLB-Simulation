{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c13d2afd-0220-4a36-96a4-80e22c5e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import sklearn \n",
    "import pickle as pkl\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "hand_combos = [\"RR\", \"RL\", \"LR\", \"LL\"]\n",
    "training_years = [\"2012\", \"2013\", \"2014\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d86bf466-5680-46ed-8451-9f295e3e26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ballpark_info = pd.read_excel(\"/Users/jaredzirkes/Desktop/Python/MLB BETTING/Ballpark Info.xlsx\", header=2)[[\"Stadium\", \"Team\", \"Start Date\", \"End Date\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f77ea6-bbfb-4dff-af45-b72437d3ddde",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bc5f36d-2ce2-46e9-81ff-d8d281380f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wind_direction(df, wind_column):\n",
    "    \n",
    "    # When wind speed is 0, the direction is automatically listed as \"in\" --> convert it to \"zero\" to differentiate\n",
    "    ind = df[df.wind_speed == 0].index\n",
    "    df.loc[ind, \"wind_direction\"] = \"zero\"\n",
    "    \n",
    "    # Use pd.get_dummies to One Hot Encode\n",
    "    wind_columns = pd.get_dummies(wind_column, columns=['categorical_column', ])\n",
    "    \n",
    "    wind_columns = pd.concat([df, wind_columns], axis = 1)\n",
    "    \n",
    "    # Finally multiply the binary wind direction columns by the wind speed to get the final wind speed in the correct direction\n",
    "    for column in wind_columns.columns[-5:]:\n",
    "        wind_columns[column] = wind_columns[column] * wind_columns[\"wind_speed\"]\n",
    "    \n",
    "    \n",
    "    return wind_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d623ebb-dbe0-471e-a3ef-adf9af73cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stadium_column(df, stadium_column):\n",
    "    \n",
    "    stadiums = pd.get_dummies(stadium_column, columns=[\"categorical_column\", ])\n",
    "    df = pd.concat([df, stadiums], axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce929f94-c283-4f92-abd0-268bde13050c",
   "metadata": {},
   "source": [
    "# Batters Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "770fcd87-9cf0-457f-84cc-088eb6857ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plays_by_hand_combo = pkl.load(open(\"all_plays_by_hand_combo.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbaa28e2-6638-42af-aa43-66a076a3c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in               25271\n",
       "out              20263\n",
       "Left to Right    11670\n",
       "Right to Left    10233\n",
       "Name: wind_direction, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_plays_by_hand_combo[\"2014\"][\"RR\"].wind_direction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "398a9419-4f2e-4803-bd38-088a494be958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine our first three years of data (maintaining hand combo seperation) to be the full initial training set\n",
    "\n",
    "all_training_data = {x:pd.DataFrame() for x in hand_combos}\n",
    "for year in training_years:\n",
    "    print(year)\n",
    "    for pitbat_combo in hand_combos:\n",
    "        print(pitbat_combo)\n",
    "        df = all_plays_by_hand_combo[year][pitbat_combo]\n",
    "        all_training_data[pitbat_combo] = all_training_data[pitbat_combo].append(df).reset_index(drop=True)\n",
    "        \n",
    "        all_training_data[pitbat_combo][\"type_counter\"] = 1\n",
    "        \n",
    "        all_training_data[pitbat_combo][\"ballpark\"] = all_training_data[pitbat_combo].apply(lambda x: ballpark_info[(ballpark_info.Team == x.home_team) & (ballpark_info[\"End Date\"] > int(x.game_date.split(\"-\")[0]))].Stadium.iloc[0],axis=1)\n",
    "    clear_output(wait = False)\n",
    "    \n",
    "clear_output(wait = False)\n",
    "# int(all_training_data[\"RR\"].iloc[0].game_date.split(\"-\")[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b539844c-856c-4cc0-8004-071ce3147446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group all plays by the date and play type to get play_type_share showing the cumulative share of the play type at eod every day\n",
    "eod_play_shares = all_training_data.copy()\n",
    "for pitbat_combo in eod_play_shares:\n",
    "    eod_play_shares[pitbat_combo] = eod_play_shares[pitbat_combo].groupby(by = [\"play_type\"]).last()\n",
    "    \n",
    "\n",
    "# Place the eod_play_share value for each play type into all training data pulling from the eod_play_share df\n",
    "for pitbat_combo in all_training_data:\n",
    "    all_training_data[pitbat_combo][\"eod_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: eod_play_shares[pitbat_combo].loc[x.play_type].cum_play_type_share, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc85937-510c-4fe6-9984-e0cb43b42756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each game, calculate within the game (and pitbat_combo), the share of the plays that were each play type\n",
    "game_play_shares = {x:{\"games\":{}, \"players\":{}} for x in hand_combos}\n",
    "n = 0\n",
    "n1 = 0\n",
    "\n",
    "for pitbat_combo in all_training_data:\n",
    "    full_df = all_training_data[pitbat_combo].copy()\n",
    "    # For each game\n",
    "    for game in full_df.game_pk.unique():\n",
    "        clear_output(wait = True)\n",
    "        game_df = full_df[full_df.game_pk == game].copy()\n",
    "        game_df[\"type_counter\"] = game_df.groupby(by = \"play_type\").cumsum().type_counter #calculate the total number of the play\n",
    "        \n",
    "        total = len(game_df)\n",
    "        \n",
    "        \n",
    "        game_df = game_df.groupby(by = \"play_type\").max()\n",
    "        \n",
    "        \n",
    "        game_df[\"play_share\"]  = game_df.type_counter/total #divide by the total number of plays, getting the play share\n",
    "        \n",
    "        game_play_shares[pitbat_combo][\"games\"][game] = game_df\n",
    "        game_play_shares[pitbat_combo][\"games\"][game][\"count\"] = total\n",
    "        \n",
    "        n+= 1\n",
    "        if n%1000 == 0:\n",
    "            print(\"game \",n)\n",
    "        # Note -- there are ~28,000 games in this 2012-2014 training set\n",
    "        \n",
    "    # For each player\n",
    "    print(\"Player\")\n",
    "    for player in full_df.batter.unique():\n",
    "        clear_output(wait = True)\n",
    "        player_df = full_df[full_df.game_pk == player].copy()\n",
    "        player_df[\"type_counter\"] = player_df.groupby(by = \"play_type\").cumsum().type_counter #calculate the total number of the play\n",
    "        \n",
    "        total = len(player_df)\n",
    "        \n",
    "        \n",
    "        player_df = player_df.groupby(by = \"play_type\").max()\n",
    "        \n",
    "        player_df[\"play_share\"]  = player_df.type_counter/total #divide by the total number of plays, getting the play share\n",
    "        \n",
    "        game_play_shares[pitbat_combo][\"players\"][player] = player_df\n",
    "        \n",
    "        # For printing updates - note: there are ~28,000 \n",
    "        n1+= 1\n",
    "        if n1%1000 == 0:\n",
    "            print(\"Player \", n1)\n",
    "            \n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e51ea455-bcca-4baf-9e3e-5de89996f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every play, insert the % of all plays in the game it occured in that were of the same play type into all_training from game_play_shares df\n",
    "for pitbat_combo in hand_combos:\n",
    "    all_training_data[pitbat_combo][\"game_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"games\"][x.game_pk].loc[x.play_type].play_share, axis = 1)\n",
    "    #all_training_data[pitbat_combo][\"batter_play_share\"] = all_training_data[pitbat_combo].apply(lambda x: game_play_shares[pitbat_combo][\"players\"][x.batter].loc[x.play_type].play_share, axis = 1)\n",
    "    \n",
    "# Now that we have the MLB eod % of plays by play type for every day and the % of plays that are each play in every game,\n",
    "# calculate/insert the difference between the individual game and the MLB eod values for every play\n",
    "for pitbat_combo in hand_combos:\n",
    "    all_training_data[pitbat_combo][\"game_share_delta\"] = all_training_data[pitbat_combo].game_play_share / all_training_data[pitbat_combo].eod_play_share\n",
    "    #all_training_data[pitbat_combo][\"batter_share_delta\"] = all_training_data[pitbat_combo].batter_play_share - all_training_data[pitbat_combo].eod_play_share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a670b7-de85-480e-ba5a-1e6a865358d8",
   "metadata": {},
   "source": [
    "## Calculating Batting Stats Factors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32a1eb-a0d9-4929-b212-81ffe4e7148e",
   "metadata": {},
   "source": [
    "#### Cleaning for Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b502814d-9a2a-425a-805e-32c93a2dc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first 100? games from each season to let the rolling stats normalize\n",
    "weather_training_data = {x:{} for x in hand_combos}\n",
    "first_games = []\n",
    "\n",
    "\n",
    "for pitbat_combo in hand_combos:  \n",
    "    weather_training_df = all_training_data[pitbat_combo].copy()\n",
    "    for year in training_years:\n",
    "        first_game_pks = all_plays_by_hand_combo[year][pitbat_combo].game_pk.unique()[:100] # Find the game_ids for the first 100 games of each season\n",
    "        first_games.append(list(first_game_pks))\n",
    "        \n",
    "    first_games_list = np.concatenate(first_games).ravel()\n",
    "    \n",
    "    weather_training_df = weather_training_df[weather_training_df.game_pk.isin(first_games_list) == False] # Pull out only the games that aren't in the first 100 games\n",
    "    weather_training_data[pitbat_combo] = weather_training_df[[\"game_pk\",\"game_date\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b30f9d0c-c63f-4b8c-bcee-efd4017497d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the weather training data by game and play type to get the game_share_delta for each play type for each game\n",
    "# Eg. game 317795 doubles has a game_share_delta of .355\n",
    "for pitbat_combo in hand_combos: \n",
    "    weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo].groupby(by = [\"game_pk\", \"play_type\"]).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d41c0093-ffc3-403f-a866-d0beda127126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the only plays currently in our data are play types that happened in games, fill in all the missing play types for \n",
    "# Each game with a game_share of 0 for that play type\n",
    "play_types = ['out', 'single', 'strikeout', 'double', 'walk', 'home_run','triple']\n",
    "n = 0\n",
    "for pitbat_combo in hand_combos:\n",
    "    for game in weather_training_data[pitbat_combo].game_pk.unique():\n",
    "        n += 1\n",
    "        if n%500 == 0:\n",
    "            print (pitbat_combo, n)\n",
    "        clear_output(wait = True)\n",
    "        df = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].game_pk == game].copy()\n",
    "        if len(df) < len(play_types):\n",
    "            missing_plays = [play for play in play_types if play not in df.play_type.values]\n",
    "            for play in missing_plays:\n",
    "                #weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.Series({\"game_pk\":game, \"game_date\":df.iloc[0].game_date, \"play_type\":play, \"temprature\":df.iloc[0].temprature, \"wind_speed\":df.iloc[0].wind_speed, \"wind_direction\":df.iloc[0].wind_direction, \"game_share_delta\":all_training_data[pitbat_combo][(all_training_data[pitbat_combo].game_date < df.iloc[0].game_date) & (all_training_data[pitbat_combo].play_type == play)].iloc[-1].eod_play_share * -1}), ignore_index = True)\n",
    "                weather_training_data[pitbat_combo] =  weather_training_data[pitbat_combo].append(pd.Series({\"game_pk\":game, \"game_date\":df.iloc[0].game_date, \"play_type\":play, \"temprature\":df.iloc[0].temprature, \"wind_speed\":df.iloc[0].wind_speed, \"wind_direction\":df.iloc[0].wind_direction, \"game_play_share\":0}), ignore_index=True)\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "302a46d2-cae7-4475-a92a-c2174f89a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pitbat_combo in hand_combos:\n",
    "    \n",
    "    # Filter down to only the relevant columns for the weather regression\n",
    "    weather_training_data[pitbat_combo] = weather_training_data[pitbat_combo][[\"game_pk\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"game_play_share\"]]\n",
    "    \n",
    "    # Square temprature to use in the regression because I believe it behaves this way\n",
    "    weather_training_data[pitbat_combo][\"temprature_squared\"] = weather_training_data[pitbat_combo][\"temprature\"].apply(lambda x: x**2)\n",
    "    \n",
    "    # Encode the wind directions and calculate final wind speeds in the direction\n",
    "    weather_training_data[pitbat_combo] = convert_wind_direction(weather_training_data[pitbat_combo], weather_training_data[pitbat_combo].wind_direction)\n",
    "    \n",
    "    # Build interaction and magnitude into the wind direction by multiplying the binary wind direction by the wind speed\n",
    "    # for column in weather_training_data[pitbat_combo].columns[-5:]:\n",
    "    #     weather_training_data[pitbat_combo][column] = weather_training_data[pitbat_combo][column] * weather_training_data[pitbat_combo].wind_speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f931-a022-42d2-80e2-3cbbe32e48e5",
   "metadata": {},
   "source": [
    "#### Weather Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfb2ef9f-0f19-4a17-8851-a089e86a8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before regressing, remove outliers for game_share???, most of which are caused by low pitbat_combo sample sizes in games\n",
    "weather_coefficients = {}\n",
    "\n",
    "for pitbat_combo in hand_combos:\n",
    "    weather_coefficients[pitbat_combo] = {}\n",
    "    for play_type in weather_training_data[pitbat_combo].play_type.unique():\n",
    "        plays = weather_training_data[pitbat_combo][weather_training_data[pitbat_combo].play_type == play_type]\n",
    "        \n",
    "        # Remove outliers for game_share_delta, most of which are caused by low pitbat_combo sample sizes in games\n",
    "        plays = plays[(np.abs(stats.zscore(plays.game_play_share)) < 3)]\n",
    "        \n",
    "        # Create 2 sets of x data, with and without squaring temprature\n",
    "        x = plays[plays.columns[np.r_[2:4, 6:11]]] #grab only the weather related columns and then get rid of regular temprature\n",
    "        \n",
    "        x_sq = x[[col for col in x.columns if col != \"temprature\" and col != \"wind_speed\"]]\n",
    "        \n",
    "        y = plays.game_play_share\n",
    "        \n",
    "        # Regress the temprature squared dataset on game_share_delta\n",
    "        lin_sq = LinearRegression(fit_intercept = True)\n",
    "        lin_sq.fit(x_sq, y)\n",
    "        \n",
    "        weather_coefficients[pitbat_combo][play_type] = {\"intercept\":lin_sq.intercept_, \"temprature_sq\":lin_sq.coef_[0], \"wind_ltr\":lin_sq.coef_[1],\n",
    "                                                 \"wind_rtl\":lin_sq.coef_[2], \"wind_in\":lin_sq.coef_[3], \"wind_out\":lin_sq.coef_[4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7608cb28-ea92-4716-82dc-8a43099902cd",
   "metadata": {},
   "source": [
    "#### Calculating Park Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4195106a-6e17-480e-bf0b-e746187bd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "park_factors_dict = {}\n",
    "for pitbat_combo in hand_combos:\n",
    "    park_factors_dict[pitbat_combo] = {}\n",
    "    \n",
    "    for ballpark in all_training_data[\"RR\"].ballpark.unique():\n",
    "        park_factors_dict[pitbat_combo][ballpark] = {}\n",
    "        at_park_df = all_training_data[pitbat_combo][(all_training_data[pitbat_combo].ballpark == ballpark)]\n",
    "        not_at_park_df = all_training_data[pitbat_combo][(all_training_data[pitbat_combo].ballpark != ballpark)]\n",
    "    \n",
    "\n",
    "        for play_type in [\"out\", \"strikeout\", \"double\", \"walk\", \"single\", \"home_run\", \"triple\"]:\n",
    "            at_park_rate = len(at_park_df[at_park_df.play_type == play_type])/len(at_park_df)\n",
    "            not_at_park_rate = len(not_at_park_df[not_at_park_df.play_type == play_type])/len(not_at_park_df)\n",
    "\n",
    "            try:\n",
    "                park_factor = at_park_rate/not_at_park_rate\n",
    "            except:\n",
    "                part_factor = \"n/a\"\n",
    "\n",
    "            park_factors_dict[pitbat_combo][ballpark][play_type] = park_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32878f77-8cea-4145-9f94-456977256e5a",
   "metadata": {},
   "source": [
    "## Adjusting Stats for Batting Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d2cd011-8050-49b6-8514-37ba1f0a5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new dictionary to hold the edited training stats\n",
    "factored_training_stats = {}\n",
    "for pitbat_combo in hand_combos:\n",
    "    \n",
    "    # Grab the relevant columns and filter down to the relevant games (not first 100)\n",
    "    df = all_training_data[pitbat_combo][[\"game_pk\", \"game_date\", \"batter\", \"pitcher\", \"play_type\", \"temprature\", \"wind_speed\", \"wind_direction\", \"ballpark\"]]\n",
    "    df = df[df.game_pk.isin(weather_training_data[pitbat_combo].game_pk) == True]\n",
    "    \n",
    "    # Add information for the actual weather and stadium impacts for each game\n",
    "    df = convert_wind_direction(df, df.wind_direction)\n",
    "    df[\"weather_expectation\"] = df.apply(lambda x: x[\"Left to Right\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_ltr\"] + x[\"Right to Left\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_rtl\"] +\n",
    "                                    x[\"in\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_in\"] + x[\"out\"]*weather_coefficients[pitbat_combo][x.play_type][\"wind_out\"] +\n",
    "                                    (x[\"temprature\"]**2) * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "    \n",
    "    df[\"neutral_weather_expectation\"] = df.apply(lambda x: 72**2 * weather_coefficients[pitbat_combo][x.play_type][\"temprature_sq\"] + weather_coefficients[pitbat_combo][x.play_type][\"intercept\"], axis=1)\n",
    "    df[\"weather_impact\"] = df.weather_expectation/df.neutral_weather_expectation\n",
    "    df[\"stadium_impact\"] = df.apply(lambda x: park_factors_dict[pitbat_combo][x.ballpark][x.play_type], axis=1)\n",
    "    \n",
    "    # Multiply the weather and stadium impacts to get the total impact for the specific at-bat result\n",
    "    df[\"play_value\"] = 1\n",
    "    df.play_value = df.play_value * df.weather_impact * df.stadium_impact\n",
    "    \n",
    "    factored_training_stats[pitbat_combo] = df[[\"game_pk\", \"game_date\", \"batter\", \"pitcher\", \"play_type\", \"play_value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a715f83b-00c8-44d6-ae54-e477f3f82898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl.dump(factored_training_stats, open(\"training_batting_stats_with_factors.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
