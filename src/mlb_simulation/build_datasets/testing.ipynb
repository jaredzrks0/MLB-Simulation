{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b2b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import pyarrow\n",
    "\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import timedelta\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from multimodal_communication import cloud_functions as cf\n",
    "from mlb_simulation.build_datasets import constants\n",
    "from mlb_simulation.build_datasets.utils_polars import (_correct_home_away_swap,\n",
    "                   _get_wind_direction,\n",
    "                   _convert_wind_direction,\n",
    "                   _pull_full_weather,\n",
    "                   _segregate_plays_by_pitbat_combo\n",
    ")\n",
    "from mlb_simulation.build_datasets.dataset_builder_polars import DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a412badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../../../../../Documents/MLB-Data/raw_pitches/pitches_2017.pkl', 'rb') as fpath:\n",
    "    df = pkl.load(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf737428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetBuilder():\n",
    "\n",
    "    def __init__(self, rolling_windows=[75, 504], verbose=False,  gcloud_upload=False,\n",
    "                 gcloud_upload_path='', local_save=False, local_save_dir_path=''):\n",
    "        \n",
    "        self.rolling_windows = rolling_windows\n",
    "        self.verbose = verbose\n",
    "        self.gcloud_upload = gcloud_upload\n",
    "        self.gcloud_upload_path = gcloud_upload_path\n",
    "        self.local_save = local_save\n",
    "        self.local_save_dir_path = local_save_dir_path\n",
    "\n",
    "    def build_training_dataset(self, raw_pitches, save_coefficients=False, coef_save_path=''):\n",
    "        \"\"\"\n",
    "        Cleans raw pitch data, generates neutralization coefficients, anad build a final\n",
    "        machine readable dataset.\n",
    "\n",
    "        Args:\n",
    "            raw_pitches (dict): Raw pitch data for each 'pitbat' combo.\n",
    "            suffix (str): Suffix for file names.\n",
    "            save_coefficients (bool): Whether to save neutralization coefficients.\n",
    "\n",
    "        Returns:\n",
    "            dict: Training dataset dictionary containing features and target values.\n",
    "\n",
    "        FUNCTION CONNECTIONS:\n",
    "        ----------------------\n",
    "        Calls On: _clean_raw_pitches()\n",
    "                  _build_neutralization_coefficient_dictionaries()\n",
    "                  _make_final_dataset()\n",
    "        \"\"\"\n",
    "\n",
    "        # Clean raw pitches and return a cleaned pitches DataFrame\n",
    "        cleaned_data = self._clean_raw_pitches(raw_pitches)\n",
    "\n",
    "        # Create a neutralization coefficients dictionary\n",
    "        coef_dicts = self.build_neutralization_coefficient_dictionaries(cleaned_data)\n",
    "\n",
    "        if save_coefficients:\n",
    "            # Format the windows in a variable to help with the naming conventions while saving\n",
    "            windows = '_'.join([window for window in self.rolling_windows])\n",
    "\n",
    "            if self.gcloud_upload:\n",
    "                cf.CloudHelper(obj=coef_dicts).upload_to_cloud(\n",
    "                    'simulation_training_data', f\"neutralization_coefficients_dict_{windows}\")\n",
    "            if self.local_save:\n",
    "                if not coef_save_path: # Ensure a path is given for a local save\n",
    "                    raise ValueError('In order to save the coefficients locally, a path to a directory must be provided')\n",
    "                \n",
    "                base_path = Path(coef_save_path)\n",
    "                filename = f'/neutralization_coefficients_dict_{windows}.pkl'\n",
    "                full_path = base_path + filename\n",
    "                base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                with open(full_path, 'wb') as f:\n",
    "                    pkl.dump(coef_dicts, f)\n",
    "\n",
    "        # Build the final dataset\n",
    "        final_dataset = self._make_final_dataset(cleaned_data, coef_dicts)\n",
    "        if self.gcloud_upload:\n",
    "            cf.CloudHelper(obj=final_dataset).upload_to_cloud(\n",
    "                'simulation_training_data', f\"Final Datasets/final_dataset_{windows}\")\n",
    "        if self.local_save:\n",
    "            base_path = Path(self.local_save_dir_path)\n",
    "            filename = f'/daily_stats_df_updated_{dt.today().strftime(\"%Y-%m-%d\")}.pkl'\n",
    "            full_path = base_path + filename\n",
    "            base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            with open(full_path, 'wb') as f:\n",
    "                pkl.dump(final_dataset, f)\n",
    "        \n",
    "        return final_dataset\n",
    "    \n",
    "    ######################################################################################\n",
    "    # Clean Pitch Data\n",
    "    ######################################################################################\n",
    "    def clean_raw_pitches(self, raw_pitches_df: pd.DataFrame) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Cleans a DataFrame of raw pitch data, filtering and transforming it into a usable format \n",
    "        for subsequent analyses, including attaching weather and ballpark information.\n",
    "\n",
    "        Parameters:\n",
    "            raw_pitches_df (DataFrame): A DataFrame of uncleaned pitch data from the Statcast API.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with 4 keys (\"RR\", \"RL\", \"LR\", \"LL\"), each containing a DataFrame \n",
    "            of pitches divided by batter-pitcher handedness combination.\n",
    "\n",
    "        FUNCTION CONNECTIONS:\n",
    "        ----------------------\n",
    "        Calls On: \n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Cleaning Data\")\n",
    "\n",
    "        # Grab necesssary information from the df for later use that would\n",
    "        # later require calling collect early\n",
    "        self.unique_years = raw_pitches_df.game_date.dt.year.unique().tolist()\n",
    "\n",
    "        # Convert the raw_pitches file to a LazyFrame\n",
    "        raw_pitches_df = pl.from_pandas(raw_pitches_df).lazy()\n",
    "\n",
    "        # Filter down to only regular season games\n",
    "        raw_pitches_df = raw_pitches_df.filter(pl.col('game_type') == 'R')\n",
    "    \n",
    "        # Correct home and away mistakes in the pitch data\n",
    "        #raw_pitches_df = _correct_home_away_swap(raw_pitches_df)\n",
    "\n",
    "        # Convert the datetime game_date to a string formatted as YYYY-MM-DD, and sort the df on the column to make sure everything is in order\n",
    "        raw_pitches_df = raw_pitches_df.with_columns(\n",
    "            pl.col('game_date').str.split(\" \").arr.get(0)\n",
    "        ).sort(by=[\"game_date\", \"inning\", \"inning_topbot\", \"at_bat_number\"],\n",
    "               descending=[False, False, False, False])\n",
    "\n",
    "        # Filter all pitches to only those with an event\\\n",
    "        raw_plays = raw_pitches_df.drop_nulls(subset=['events'])\n",
    "\n",
    "        # Filter all pitches with an event to only those types we care about\n",
    "        # As well as only the columns we care about\n",
    "        final_plays = raw_plays.filter(\n",
    "            pl.col('events').is_in([constants.RELEVANT_PLAY_TYPES])\n",
    "        ).select(\n",
    "            constants.RELEVANT_BATTING_COLUMNS\n",
    "        )\n",
    "\n",
    "        # Add a new column that groups all the event types into eventual Y labels\n",
    "        final_plays = final_plays.with_columns(\n",
    "            pl.col('events').replace(constants.PLAY_TYPE_DICT).alias('play_type')\n",
    "        )\n",
    "\n",
    "        # Insert a new 'type counter' coulumn that will be used repeatedly for calculating rolling stats\n",
    "        final_plays = final_plays.with_columns(\n",
    "            pl.lit(1).alias('type_counter')\n",
    "        )\n",
    "        \n",
    "\n",
    "        ############ ATTATCH WEATHER INFORMATION TO EACH PITCH ############\n",
    "        \n",
    "        weather_dictionary_holder = {}\n",
    "\n",
    "        for year in self.unique_years:\n",
    "            # Pull in the proreference weather data \n",
    "            yearly_weather_df = pd.DataFrame()\n",
    "            base_path = self.local_save_dir_path\n",
    "            filename = f'/proreference_weather_data/weather_data_{year}.pkl'\n",
    "            weather_filepath = base_path + filename\n",
    "            if os.path.exists(weather_filepath):\n",
    "                with open(weather_filepath, 'rb') as fpath:\n",
    "                    yearly_weather_df = pl.read_csv(weather_filepath)\n",
    "            \n",
    "            # If not locally, download from the cloud\n",
    "            if len(yearly_weather_df) == 0:\n",
    "                yearly_weather_df = cf.CloudHelper().download_from_cloud(\"proreference_weather_data/weather_data_{}\".format(year))\n",
    "                yearly_weather_df = pl.from_pandas(yearly_weather_df)  \n",
    "\n",
    "            if len(yearly_weather_df) == 0:\n",
    "                raise Exception(f'No Prorefence weather data was found for {year}. Ensure that the data exists and paths are correct!')\n",
    "            \n",
    "            # Insert each years data into storage as a LazyFrame\n",
    "            weather_dictionary_holder[year] = yearly_weather_df.lazy()\n",
    "        \n",
    "        # Concat all the yearly weather dataframes into one larger one\n",
    "        total_weather_df = pl.concat([df for df in weather_dictionary_holder.values()], how='vertical')\n",
    "\n",
    "        # Create a new column with the converted home team names in total_weather_df\n",
    "        team_name_map = {v: k for k, v in constants.WEATHER_NAME_CONVERSIONS.items()}\n",
    "        total_weather_df = total_weather_df.with_columns([\n",
    "            pl.col('home_team').replace(team_name_map).alias('converted_home_team'),\n",
    "            pl.col('away_team').replace(team_name_map).alias('converted_away_team')\n",
    "        ])\n",
    "\n",
    "        # Drop the old columns\n",
    "        total_weather_df = total_weather_df.drop(['home_team', 'away_team'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "898d328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../../../../Documents/MLB-Data/proreference_weather_data/weather_data_2017.pkl\n"
     ]
    }
   ],
   "source": [
    "builder = DatasetBuilder(local_save_dir_path='../../../../../../../Documents/MLB-Data')\n",
    "\n",
    "builder.clean_raw_pitches(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b39afe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
