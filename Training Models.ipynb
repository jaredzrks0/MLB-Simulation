{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6f6950fb-8f3f-471e-a686-d336ab409a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pybaseball\n",
    "import sklearn\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, cross_validate, cross_val_predict, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from pybaseball import playerid_lookup, playerid_reverse_lookup\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#from ipynb.fs.full.Building_Dataset_Functions import * \n",
    "\n",
    "hand_combos = [\"RR\", \"RL\", \"LR\", \"LL\"]\n",
    "training_years = [\"2012\", \"2013\", \"2014\"]\n",
    "\n",
    "plays = [\"out\", \"strikeout\", \"walk\", \"single\", \"double\", \"triple\", \"home_run\"]\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24633c10-8090-43b9-b60f-3f0653425617",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Odds Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "72a3e000-b62f-40c9-a2ce-9f2be6368c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log5 (pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the log5 equation. NOTE: DO NOT USE RIGHT NOW\"\"\" \n",
    "    one = (pB*pP)/pL\n",
    "    two = ((1-pB)*(1-pP))/(1-pL)\n",
    "    \n",
    "    return one/(one + two)\n",
    "\n",
    "\n",
    "def morey_z(pB, pP, pL):\n",
    "    \"\"\" Given the probability of a PA outcome for the pitcher, the batter, and the overall league, calculate the\n",
    "    probability in that given at bat using the Morey Z equation\"\"\"\n",
    "    one = (pB-pL)/np.sqrt(pL*(1-pL))\n",
    "    two = (pP-pL)/np.sqrt(pL*(1-pL))\n",
    "    three = np.sqrt(pL*(1-pL))\n",
    "    return ((one + two)/np.sqrt(2) * three) +pL\n",
    "\n",
    "def ab_play_percentages(batting_percentages, pitching_percentages, league_percentages, pitbat_combo, function):\n",
    "    \"\"\" Given a list of probabilities for all PA outcomes for the batter, the pitcher, and the league, along with\n",
    "    the pitbat combo, and the desired probability funtion, return a list of the probabilities for all PA outcomes \n",
    "    for the specific PA\"\"\"\n",
    "    \n",
    "    ab_percentages = {}\n",
    "    \n",
    "    # Get the specific percentages for each play type\n",
    "    for play in plays:\n",
    "        batting_percent = batting_percentages[\"b_\" + play]\n",
    "        pitching_percent = pitching_percentages[\"p_\" + play]\n",
    "        league_percent = league_percentages[pitbat_combo][play]\n",
    "        \n",
    "        # Ensure we are using one of the two acceptable prediction functions\n",
    "        if function not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "            while funtion not in [\"morey z\", \"Morey Z\", \"log5\", \"Log5\"]:\n",
    "                function = input(\"Acceptable Functions are Morey Z and Log5. Please input one.\")\n",
    "        \n",
    "        # Calculate the predicted percentage for the specific play for the PA\n",
    "        if function == \"morey z\" or function == \"Morey Z\":\n",
    "            expected_percent = max(morey_z(batting_percent, pitching_percent, league_percent), 0.000001)\n",
    "        else:\n",
    "            expected_percent = log5(batting_percent, pitching_percent, league_percent)\n",
    "    \n",
    "        # Insert the predicted percentage for the play type into our dictionary for delivery\n",
    "        ab_percentages[play] = expected_percent\n",
    "        \n",
    "        # Get rid of negative and zero numbers and repercenage slightly if numbers are reset\n",
    "        ab_percentages = {key: value/sum(list(ab_percentages.values())) for key, value in ab_percentages.items()}\n",
    "    \n",
    "    return ab_percentages\n",
    "\n",
    "# League Average Guesser\n",
    "def average_guesser(batting_percentages, pitching_percentages, league_percentages, pitbat_combo):\n",
    "    ab_percentages = {}\n",
    "    \n",
    "    for play in plays:\n",
    "        league_percent = league_percentages[pitbat_combo][play]\n",
    "        ab_percentages[play] = league_percent\n",
    "        \n",
    "    ab_percentages = {key: value/sum(list(ab_percentages.values())) for key, value in ab_percentages.items()}\n",
    "    \n",
    "    return ab_percentages  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5c6311d7-843b-480c-acfd-aad8dc4d57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(probabilities, actuals):\n",
    "    \"\"\" Given a list of probabilities and acuals for a series of instances, calculate and return the average log loss\"\"\"\n",
    "    log_loss = 0\n",
    "    yhat_probabilities = []\n",
    "    for instance in range(len(probabilities)):\n",
    "        yhat_probabilities.append(max([n for n in np.array(probabilities.iloc[instance])*np.array(actuals.iloc[instance])]))\n",
    "    log_loss -= sum([np.log10(x)for x in yhat_probabilities])\n",
    "\n",
    "\n",
    "    return log_loss/len(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "47a51353-f359-4999-93fc-29f0ed08da17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'odds_functions_data_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [354]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m odds_dataset \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43modds_functions_data_set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m odds_dataset \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124modds_functions_dataset_without_yearbreaks.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatting_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m league_averages \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleague_averages.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'odds_functions_data_set'"
     ]
    }
   ],
   "source": [
    "odds_dataset = pkl.load(open(\"odds_functions_data_set\", \"rb\"))\n",
    "odds_dataset = pkl.load(open(\"odds_functions_dataset_without_yearbreaks.pkl\", \"rb\"))[\"batting_stats\"]\n",
    "\n",
    "league_averages = pkl.load(open(\"league_averages.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e791d36-33bd-433f-9513-efb3467424a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Make Odds Predictions on Neutral Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beadfdbf-f7f2-4b14-8a84-d143898d0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_dataset[\"morey_prediction\"] = odds_dataset.apply(lambda x: ab_play_percentages(x[[\"b_\" + play for play in plays]], x[[\"p_\" + play for play in plays]], league_averages, x.pitbat, \"morey z\"), axis = 1)\n",
    "odds_dataset[\"morey_prediction_list\"] = odds_dataset.morey_prediction.apply(lambda x: list(x.values()))\n",
    "\n",
    "odds_dataset[\"la_prediction\"] = odds_dataset.apply(lambda x: average_guesser(x[[\"b_\" + play for play in plays]], x[[\"p_\" + play for play in plays]], league_averages, x.pitbat), axis = 1)\n",
    "odds_dataset[\"la_prediction_list\"] = odds_dataset.la_prediction.apply(lambda x: list(x.values()))\n",
    "\n",
    "odds_dataset[\"actuals\"] = odds_dataset.apply(lambda x: list(x.la_prediction.keys()).index(x.play),axis=1)\n",
    "\n",
    "odds_dataset['yhat'] = odds_dataset.actuals.apply(lambda x: [0]*len(plays))\n",
    "odds_dataset['yhat'] = odds_dataset.apply(lambda x: x.yhat[0:x.actuals] +[1] +  x.yhat[x.actuals+1:], axis=1)\n",
    "\n",
    "odds_dataset = odds_dataset.drop(columns = [\"morey_prediction\", \"la_prediction\"])\n",
    "\n",
    "# Remove some instances with NA from pitchers who only make 1 app\n",
    "odds_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e7ad2dd-8b6e-489d-8caa-b3b6aa6beb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crappy Log Loss: 0.6243287896373452\n",
      "Morey Log Loss: 0.6917390575292162\n"
     ]
    }
   ],
   "source": [
    "crappy_log_loss = log_loss(odds_dataset.la_prediction_list, odds_dataset.yhat)\n",
    "morey_log_loss = log_loss(odds_dataset.morey_prediction_list, odds_dataset.yhat)\n",
    "\n",
    "print(\"Crappy Log Loss: {}\".format(crappy_log_loss))\n",
    "print(\"Morey Log Loss: {}\".format(morey_log_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c3f94ff-83be-4e7c-9f31-817c02ab3cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out's average value is 0.4821648345592577\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m morey_predictions \u001b[38;5;241m=\u001b[39m log_loss(df\u001b[38;5;241m.\u001b[39mmorey_prediction_list, df\u001b[38;5;241m.\u001b[39myhat)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms average value is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(play_percent))\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms crappy average prediction value is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcrappy_predictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(crappy_predictions)))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(play) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms morey average prediction value is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28msum\u001b[39m(morey_predictions)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(morey_predictions)))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "for play in plays:\n",
    "    df = odds_dataset[odds_dataset.play == play].copy()\n",
    "    play_percent = len(df)/len(odds_dataset)\n",
    "    \n",
    "    crappy_predictions = log_loss(df.la_prediction_list, df.yhat)\n",
    "    morey_predictions = log_loss(df.morey_prediction_list, df.yhat)\n",
    "    \n",
    "    print(str(play) + \"'s average value is {}\".format(play_percent))\n",
    "    print(str(play) + \"'s crappy average prediction value is: {}\".format(sum(crappy_predictions)/len(crappy_predictions)))\n",
    "    print(str(play) + \"'s morey average prediction value is: {}\".format(sum(morey_predictions)/len(morey_predictions)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb2a5b-a470-481e-a0a5-4781e569cd50",
   "metadata": {},
   "source": [
    "# ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "287799aa-323b-4819-928a-9cd9056958df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pkl.load(open(\"ML X Dataset\", \"rb\"))\n",
    "Y_play = pkl.load(open(\"ML Y Dataset (Plays)\", \"rb\"))\n",
    "Y_onbase = pkl.load(open(\"ML Y Dataset (On Base)\", \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ea2f2cf5-75a5-4401-acec-e962df463c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(ml_full_df, y_full, test_size=0.2, random_state=42)\n",
    "sss = StratifiedShuffleSplit(test_size=.2, random_state=42)\n",
    "for train_index, test_index in sss.split(X, Y_play):\n",
    "    x_train, x_test = X[train_index], X[test_index]\n",
    "    y_train_plays, y_test_plays = Y_play[train_index], Y_play[test_index]\n",
    "    y_train_onbase, y_test_onbase = Y_onbase[train_index], Y_onbase[test_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddc797-50d7-47d2-826a-63460dee0682",
   "metadata": {},
   "source": [
    "## Crappy Average Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "e81d1b2c-b70d-4931-8f3a-5ad183dfaa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Crappy Average Estimator for Predicting Plays Has a Neg Log Loss of: -1.745\n",
      "The Crappy Average Estimator for Predicting On Base Has a Neg Log Loss of: -0.619\n"
     ]
    }
   ],
   "source": [
    "dumb_log_loss_plays = 0\n",
    "league_averages_plays = {}\n",
    "for play in y_train_plays.value_counts().index:\n",
    "    league_averages_plays[play] = len(y_train_plays[y_train_plays == play])/len(y_train_plays)\n",
    "    dumb_log_loss_plays += len(y_train_plays[y_train_plays == play])/len(y_train_plays)* np.log(len(y_train_plays[y_train_plays == play])/len(y_train_plays))\n",
    "    \n",
    "    \n",
    "dumb_log_loss_onbase = 0\n",
    "league_averages_onbase = {}\n",
    "for play in y_train_onbase.value_counts().index:\n",
    "    league_averages_onbase[play] = len(y_train_onbase[y_train_onbase == play])/len(y_train_onbase)\n",
    "    dumb_log_loss_onbase += len(y_train_onbase[y_train_onbase == play])/len(y_train_onbase)* np.log(len(y_train_onbase[y_train_onbase == play])/len(y_train_onbase))\n",
    "    \n",
    "print(\"The Crappy Average Estimator for Predicting Plays Has a Neg Log Loss of: {}\".format(round(dumb_log_loss_plays,3)))\n",
    "print(\"The Crappy Average Estimator for Predicting On Base Has a Neg Log Loss of: {}\".format(round(dumb_log_loss_onbase,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "35a81cba-9bfc-4b2c-970f-1f1872527ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6503, 124)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af0e28-f924-4f08-8c26-cf1be1fc0b65",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0271ef6-2b8d-4181-929d-7c69d1527728",
   "metadata": {},
   "source": [
    "### Basic Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "b30b83a9-4bb0-452b-9f04-4f22387b4809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Logistic Regressor (Plays) Has a Neg Log Loss of: -1.621\n",
      "The Basic Logistic Regressor (On Base) Has a Neg Log Loss of: -0.616\n"
     ]
    }
   ],
   "source": [
    "softmax_plays = LogisticRegression(class_weight = None, max_iter=150)\n",
    "softmax_plays_scores = cross_val_score(softmax_plays, x_train, y_train_plays, cv=5, scoring = \"neg_log_loss\", n_jobs=4)\n",
    "print(\"The Basic Logistic Regressor (Plays) Has a Neg Log Loss of: {}\".format(round(softmax_plays_scores.mean(),3)))\n",
    "\n",
    "\n",
    "softmax_onbase = LogisticRegression(max_iter=150)\n",
    "softmax_onbase_scores = cross_val_score(softmax_onbase, x_train, y_train_onbase, cv=5, scoring = \"neg_log_loss\", n_jobs=4)\n",
    "print(\"The Basic Logistic Regressor (On Base) Has a Neg Log Loss of: {}\".format(round(softmax_onbase_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa2f89-352c-489c-9fac-f373ac1b433c",
   "metadata": {},
   "source": [
    "### Grid Search Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc027b90-8e79-4136-86cf-772dd4b3c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dictionary of class weights to grid search on due to impalanced Dataset\n",
    "class_weights = list(y_train.value_counts().index)\n",
    "class_weights_list = []\n",
    "\n",
    "for n in range(1):\n",
    "    weights = np.random.rand(len(class_weights))\n",
    "    weights = weights/sum(weights)\n",
    "    weights = {class_weights[x]:weights[x] for x in range(len(class_weights))}\n",
    "    \n",
    "    class_weights_list.append(weights)\n",
    "    \n",
    "class_weights_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df684ae-e15c-45f2-8464-b6a9fcdc963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':np.linspace(0.001,1,2), \"solver\":[\"newton-cg\"], \"class_weight\":class_weights_list,\n",
    "              'multi_class':[\"ovr\"]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs = 4)\n",
    "grid_search.fit(x_train, y_train)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877be3bd-e2b0-461d-90c3-f747b9fd0d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Logistic Regressor Has a Neg Log Loss Of: -1.414\n",
      "The Best Logistic Regressor Has Parameters Of: {'C': 1.0, 'class_weight': None, 'multi_class': 'ovr', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "final_logistic_regressor = grid_search.best_estimator_\n",
    "print(\"The Best Logistic Regressor Has a Neg Log Loss Of: {}\".format(round(grid_search.best_score_.mean(), 3)))\n",
    "print(\"The Best Logistic Regressor Has Parameters Of: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f1e6a-44d7-4286-aa62-b7141c72e7ca",
   "metadata": {},
   "source": [
    "## K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d4ef11-bbba-4339-80ec-cf08ce4ab9fb",
   "metadata": {},
   "source": [
    "### Basic K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "52e01703-743a-43f5-8bcb-12b5239fa17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic kNeighbors Classifier (Plays) Has a Neg Log Loss of: -9.628\n",
      "The Basic kNeighbors Classifier (On Base) Has a Neg Log Loss of: -2.254\n"
     ]
    }
   ],
   "source": [
    "knc_plays = KNeighborsClassifier()\n",
    "knc_scores_plays = cross_val_score(knc_plays, x_train, y_train_plays, cv=5, scoring = \"neg_log_loss\", n_jobs=1)\n",
    "print(\"The Basic kNeighbors Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(knc_scores_plays.mean(),3)))\n",
    "\n",
    "knc_onbase = KNeighborsClassifier()\n",
    "knc_scores_onbase = cross_val_score(knc_onbase, x_train, y_train_onbase, cv=5, scoring = \"neg_log_loss\", n_jobs=1)\n",
    "print(\"The Basic kNeighbors Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(knc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29f728-853c-4cfc-9bb0-92a678baed36",
   "metadata": {},
   "source": [
    "### Grid Search K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "e71d8dc3-cb7c-44d5-a496-416d69e78b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the K Neighbors Grid Search Below\n",
    "n_neighbors_params = [1000]\n",
    "weights_params = [\"uniform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "bb9fdfbf-d4e4-43cb-801d-3cffdc87e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search For Plays\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [293]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid Search For Plays\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m knc_grid_search_plays \u001b[38;5;241m=\u001b[39m GridSearchCV(KNeighborsClassifier(), knc_parameters, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_log_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mknc_grid_search_plays\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_plays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrid Search For On Base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_score \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:219\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, X, y_true, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m        Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:301\u001b[0m, in \u001b[0;36m_ProbaScorer._score\u001b[0;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m\"\"\"Evaluate predicted probabilities for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y)\n\u001b[0;32m--> 301\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_proba\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# `y_type` could be equal to \"binary\" even in a multi-class\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# problem: (when only 2 class are given to `y_true` during scoring)\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# Thus, we need to check for the shape of `y_pred`.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_proba_binary(y_pred, clf\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:71\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"Call estimator with method and args and kwargs.\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[method]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:275\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"Return probability estimates for the test data X.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    by lexicographic order.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py:763\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    756\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m PairwiseDistancesArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    759\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m )\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 763\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mPairwiseDistancesArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    775\u001b[0m ):\n\u001b[1;32m    776\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    777\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    778\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction.pyx:698\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction.PairwiseDistancesArgKmin.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    174\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knc_parameters = {'n_neighbors':n_neighbors_params, \"weights\":weights_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "knc_grid_search_plays = GridSearchCV(KNeighborsClassifier(), knc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "knc_grid_search_plays.fit(x_train, y_train_plays)\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "knc_grid_search_onbase = GridSearchCV(KNeighborsClassifier(), knc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "knc_grid_search_onbase.fit(x_train, y_train_onbase)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e79e3c21-31d5-46f5-a589-332f26ae5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best K Neighbors Classifier Has a Neg Log Loss Of: -1.419\n",
      "The Best K Neighbors Classifier Has Parameters Of: {'n_neighbors': 1000, 'weights': 'uniform'}\n",
      "The Best K Neighbors Classifier Has a Neg Log Loss Of: -0.626\n",
      "The Best K Neighbors Classifier Has Parameters Of: {'n_neighbors': 1000, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "final_KNC_regressor_plays = knc_grid_search_plays.best_estimator_\n",
    "print(\"The Best K Neighbors Classifier Has a Neg Log Loss Of: {}\".format(round(knc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best K Neighbors Classifier Has Parameters Of: {}\".format(knc_grid_search_plays.best_params_))\n",
    "\n",
    "final_KNC_regressor_onbase = knc_grid_search_onbase.best_estimator_\n",
    "print(\"The Best K Neighbors Classifier Has a Neg Log Loss Of: {}\".format(round(knc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best K Neighbors Classifier Has Parameters Of: {}\".format(knc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cecd6-7afb-43f2-a5d9-d45f6de9ed6e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c541f-e590-4ba4-bb08-623c1dc5cf98",
   "metadata": {},
   "source": [
    "### Basic Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7471a7a6-88b9-41db-a3d9-237811f2d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Random Forest Classifier (Plays) Has a Neg Log Loss of: -2.633\n",
      "The Basic Random Forest Classifier (On Base) Has a Neg Log Loss of: -0.805\n"
     ]
    }
   ],
   "source": [
    "rf_plays = RandomForestClassifier(random_state=42)\n",
    "rf_scores_plays = cross_val_score(rf_plays, x_train, y_train_plays, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Random Forest Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(rf_scores_plays.mean(),3)))\n",
    "\n",
    "rf_onbase = RandomForestClassifier(random_state=42)\n",
    "rf_scores_onbase = cross_val_score(rf_onbase, x_train, y_train_onbase, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Random Forest Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(rf_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa3708-b682-4733-9971-04f0ac3f4718",
   "metadata": {},
   "source": [
    "### Grid Search for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ad5af3cd-b71d-4bc5-8884-b09b53eb3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the Random Forest Grid Search Below\n",
    "estimators_params= [900, 1100, 1300]\n",
    "criterion_params = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "max_depth_params = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "01b318b7-d861-4c0a-9640-61c70f18cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_parameters = {'n_estimators':estimators_params, \"criterion\":criterion_params, \"max_depth\":max_depth_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "rf_grid_search_plays = GridSearchCV(RandomForestClassifier(random_state = 42), rf_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "rf_grid_search_plays.fit(x_train[:10000], y_train_plays[:10000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "rf_grid_search_onbase = GridSearchCV(RandomForestClassifier(random_state = 42), rf_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "rf_grid_search_onbase.fit(x_train[:10000], y_train_onbase[:10000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6cc0f94d-a1a2-4331-b767-bfa92836642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: -1.426\n",
      "The Best Random Forest Classifier (On Base) Has Parameters Of: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1100}\n",
      "The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: -0.631\n",
      "The Best Random Forest Classifier (On Base) Has Parameters Of: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "final_RF_regressor_plays = rf_grid_search_plays.best_estimator_\n",
    "print(\"The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(rf_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Random Forest Classifier (On Base) Has Parameters Of: {}\".format(rf_grid_search_plays.best_params_))\n",
    "\n",
    "final_RF_regressor_onbase = rf_grid_search_onbase.best_estimator_\n",
    "print(\"The Best Random Forest Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(rf_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Random Forest Classifier (On Base) Has Parameters Of: {}\".format(rf_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99ccfb-1e38-4104-8668-4be590bc0d7d",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51353baf-a3b8-44d0-8a30-a09cbaec7e1e",
   "metadata": {},
   "source": [
    "### Basic Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c1ca2b39-d918-48f3-b87c-3fa211174262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Support Vector Classifier (Plays) Has a Neg Log Loss of: -1.723\n",
      "The Basic Support Vector Classifier (On Base) Has a Neg Log Loss of: -0.61\n"
     ]
    }
   ],
   "source": [
    "svc_plays = SVC(probability=True)\n",
    "svc_scores_plays = cross_val_score(svc_plays, x_train, y_train_plays, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Support Vector Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(svc_scores_plays.mean(),3)))\n",
    "\n",
    "svc_onbase = SVC(probability=True)\n",
    "svc_scores_onbase = cross_val_score(svc_onbase, x_train, y_train_onbase, cv = 5, scoring = \"neg_log_loss\")\n",
    "print(\"The Basic Support Vector Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(svc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df1cac-f6ae-47e0-ab5c-bb9eea3495fe",
   "metadata": {},
   "source": [
    "### Grid Search for Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "60051da3-f698-4d05-b41e-a2cf9f10905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detail parameters for the Support Vector Classifier Grid Search Below\n",
    "C_params= [.33,.66, 1]\n",
    "kernel_params = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "degree_params = [3,5,7]\n",
    "gamma_params = [\"auto\", \"scale\"]\n",
    "class_weight_params = [None, \"balanced\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d46bb8-d747-48fb-b9f7-48fc2ab4d1ca",
   "metadata": {},
   "source": [
    "Because SVCs scale poorly with n instances, we can try training the model on a subset of the training data. The below cells first find a suitible SVC to test on the subsample, and then cross_val_score and increasing sizes of the sample to check where the cross-entropy levels out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "648b375f-e078-4340-a4f5-1ead8163a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search For Plays\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5] END C=0.33, class_weight=None, degree=3, gamma=auto, kernel=linear;, score=-1.448 total time=   4.1s\n",
      "[CV 2/5] END C=0.33, class_weight=None, degree=3, gamma=auto, kernel=linear;, score=-1.449 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a Grid Search for our SVC on a 5000 instance subset of the training data\n",
    "svc_parameters = {'C':C_params, \"kernel\":kernel_params, \"degree\":degree_params, \"gamma\":gamma_params, \"class_weight\":class_weight_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "svc_grid_search_plays = GridSearchCV(SVC(probability=True), svc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 5)\n",
    "svc_grid_search_plays.fit(x_train[:5000], y_train_plays[:5000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "svc_grid_search_onbase = GridSearchCV(SVC(probability=True), svc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 5)\n",
    "svc_grid_search_onbase.fit(x_train[:5000], y_train_onbase[:5000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db926a10-24a0-4328-9188-0d5b4c9c067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SVC_regressor_plays = svc_grid_search_plays.best_estimator_\n",
    "print(\"The Best Support Vector Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(svc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Support Vector Classifier (Plays) Has Parameters Of: {}\".format(svc_grid_search.best_params_))\n",
    "\n",
    "final_SVC_regressor_onbase = svc_grid_search_onbase.best_estimator_\n",
    "print(\"The Best Support Vector Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(svc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Support Vector Classifier (On Base) Has Parameters Of: {}\".format(svc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eff8d424-a63f-4d3c-96ac-4ecae7d86e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score_dict_II = {}\n",
    "for n in [15000]:\n",
    "    print(n)\n",
    "    model = SVC(C=.33, class_weight=\"balanced\", degree=7, gamma=\"auto\", kernel=\"rbf\", probability=True)\n",
    "    score = cross_val_score(model, x_train[:n], y_train[:n], cv=5, scoring=\"neg_log_loss\", verbose=3, error_score=\"raise\", n_jobs=4)\n",
    "    score_dict_II[n] = -score.mean()\n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5fc6bf0-9766-4ea2-9397-654c9f11d9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f67fca0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_dict_II.keys(), score_dict_II.values())\n",
    "plt.title(\"SVC Log Loss With Sample Size n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4719be-64c1-46bd-b3e5-c02b121afa72",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b78946-3c5d-440b-a049-79ab306a68ef",
   "metadata": {},
   "source": [
    "Similar to the SVC, we will attempt to find a suitable model on a smaller sample of the data, although we can train the final model on the full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab53369-cc76-46b0-a45a-d4f6b9c70770",
   "metadata": {},
   "source": [
    "### Basic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "42c9c509-0894-4d6b-b1ee-2d4dd241e620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   12.4s remaining:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: -1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:    2.2s remaining:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: -0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "gbc_plays = GradientBoostingClassifier()\n",
    "gbc_scores_plays = cross_val_score(gbc_plays, x_train[:5000], y_train_plays[:5000], cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Basic Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(gbc_scores_plays.mean(),3)))\n",
    "\n",
    "gbc_onbase = GradientBoostingClassifier()\n",
    "gbc_scores_onbase = cross_val_score(gbc_onbase, x_train[:5000], y_train_onbase[:5000], cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Basic Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(gbc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297fa33c-5f0f-4a79-a7c1-dd9f3cf4da6d",
   "metadata": {},
   "source": [
    "### Grid Search for Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f2b430-afe1-46bf-9acd-8c65f0db8bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_params = [100, 200, 300]\n",
    "depth_params = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae67fd5a-558f-4f2d-ac46-c2b9fa31053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_parameters = {'n_estimators':estimator_params, \"max_depth\":depth_params}\n",
    "\n",
    "print(\"Grid Search For Plays\")\n",
    "gbc_grid_search_plays = GridSearchCV(GradientBoostingClassifier(), gbc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs=4)\n",
    "gbc_grid_search_plays.fit(x_train[:5000], y_train_plays[:5000])\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Grid Search For On Base\")\n",
    "gbc_grid_search_onbase = GridSearchCV(GradientBoostingClassifier(), gbc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3, n_jobs=4)\n",
    "gbc_grid_search_onbase.fit(x_train[:5000], y_train_onbase[:5000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17669502-7a3f-4315-ad28-6bb2ae1cc976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Gradient Boosted Classifier Has a Neg Log Loss Of: -1.481\n",
      "The Best Gradient Boosted Classifier Has Parameters Of: {'max_depth': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "final_GBC_regressor_plays = gbc_grid_search.best_estimator_\n",
    "print(\"The Best Gradient Boosted Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(gbc_grid_search_plays.best_score_.mean(), 3)))\n",
    "print(\"The Best Gradient Boosted Classifier (Plays Has Parameters Of: {}\".format(gbc_grid_search_plays.best_params_))\n",
    "\n",
    "final_GBC_regressor_onbase = gbc_grid_search.best_estimator_\n",
    "print(\"The Best Gradient Boosted Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(gbc_grid_search_onbase.best_score_.mean(), 3)))\n",
    "print(\"The Best Gradient Boosted Classifier (On Base) Has Parameters Of: {}\".format(gbc_grid_search_onbase.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9b446-4c67-4f82-9801-65497bb90bf7",
   "metadata": {},
   "source": [
    "#### Histogram Based Option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebcf95-5eba-4a36-b0aa-802a711fcc8a",
   "metadata": {},
   "source": [
    "Because of the testing limitations, we will also try a Histogram-based Gradient Boosting Classification Tree, which scales significantly better than the standard gradient boosting tree. It does not appear to support grid search however, so we will do that manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "cd1219bc-fa6b-4a89-b59d-766b44b9801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic Hist Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: -1.62\n",
      "The Basic Hist Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: -0.615\n"
     ]
    }
   ],
   "source": [
    "hgbc_plays = HistGradientBoostingClassifier()\n",
    "hgbc_scores_plays = cross_val_score(hgbc_plays, x_train, y_train_plays, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic Hist Gradient Boosted Classifier (Plays) Has a Neg Log Loss of: {}\".format(round(hgbc_scores_plays.mean(),3)))\n",
    "\n",
    "hgbc_onbase = HistGradientBoostingClassifier()\n",
    "hgbc_scores_onbase = cross_val_score(hgbc_onbase, x_train, y_train_onbase, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic Hist Gradient Boosted Classifier (On Base) Has a Neg Log Loss of: {}\".format(round(hgbc_scores_onbase.mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9c793e48-cd2e-45f0-8152-23c4b292a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_params = [30, 50, 70]\n",
    "depth_params = [5, 10, None]\n",
    "max_leaf_params = [2, 3, None]\n",
    "\n",
    "all_param_lists = [iter_params, depth_params, max_leaf_params]\n",
    "\n",
    "hgbc_param_list = list(itertools.product(*all_param_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8228515f-027e-41f0-bc67-bfb53c5d42c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for the Plays Model\n",
    "print(\"Grid Search For Plays\")\n",
    "\n",
    "best_score_plays = -10000\n",
    "best_params_plays = {}\n",
    "for tup in hgbc_param_list:\n",
    "    print(tup)\n",
    "    score = cross_val_score(HistGradientBoostingClassifier(max_iter=tup[0], max_depth = tup[1], max_leaf_nodes = tup[2]), x_train, y_train_plays, cv=5,\n",
    "                                                          n_jobs = 4, scoring=\"neg_log_loss\").mean()\n",
    "    \n",
    "    if score > best_score_plays:\n",
    "        best_score_plays = score\n",
    "        best_params_plays = {\"max_iter\":tup[0], \"max_depth\":tup[1], \"max_leaf_nodes\":tup[2],}\n",
    "                            \n",
    "    clear_output(wait=False)\n",
    "    \n",
    "# And Grid Search Again for the On Base Model\n",
    "print(\"Grid Search For On Base\")\n",
    "\n",
    "best_score_onbase = -10000\n",
    "best_params_onbase = {}\n",
    "for tup in hgbc_param_list:\n",
    "    print(tup)\n",
    "    score = cross_val_score(HistGradientBoostingClassifier(max_iter=tup[0], max_depth = tup[1], max_leaf_nodes = tup[2]), x_train, y_train_onbase, cv=5,\n",
    "                                                          n_jobs = 4, scoring=\"neg_log_loss\").mean()\n",
    "    \n",
    "    if score > best_score_onbase:\n",
    "        best_score_onbase = score\n",
    "        best_params_onbase = {\"max_iter\":tup[0], \"max_depth\":tup[1], \"max_leaf_nodes\":tup[2],}\n",
    "                            \n",
    "    clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea1894-ce92-4106-856b-49cea051a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_HGBC_regressor_plays = HistGradientBoostingClassifier(max_iter=best_params_plays[\"max_iter\"], max_depth = best_params_plays[\"max_depth\"], max_leaf_nodes = best_params_plays[\"max_leaf_nodes\"])\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (Plays) Has a Neg Log Loss Of: {}\".format(round(best_score_plays, 3)))\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (Plays) Has Parameters Of: {}\".format(best_params_plays))\n",
    "\n",
    "final_HGBC_regressor_onbase = HistGradientBoostingClassifier(max_iter=best_params_onbase[\"max_iter\"], max_depth = best_params_onbase[\"max_depth\"], max_leaf_nodes = best_params_onbase[\"max_leaf_nodes\"])\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (On Base) Has a Neg Log Loss Of: {}\".format(round(best_score_onbase, 3)))\n",
    "print(\"The Best Histogram-Based Gradient Boosted Classifier (On Base) Has Parameters Of: {}\".format(best_params_onbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92f140-043d-4e64-afd5-4ae7c660377d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443619b-60a6-455c-9593-0eb7030cd580",
   "metadata": {},
   "source": [
    "### Basic ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd0e4650-b2db-4167-a101-ec4e8dd7907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic ADA Boost Classifier Has a Neg Log Loss of: -1.919\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc_scores = cross_val_score(abc, x_train, y_train, cv=5, scoring=\"neg_log_loss\", n_jobs = 4)\n",
    "print(\"The Basic ADA Boost Classifier Has a Neg Log Loss of: {}\".format(round(abc_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "706e2475-6de0-4b87-9429-a948ff459b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   24.8s remaining:   37.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic ADA Boost Classifier Has a Neg Log Loss of: -1.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   47.9s finished\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(base_estimator = SVC(), algorithm = \"SAMME\")\n",
    "abc_scores = cross_val_score(abc, x_train[:2000], y_train[:2000], cv=5, scoring=\"neg_log_loss\", n_jobs = 4, verbose=3)\n",
    "print(\"The Basic ADA Boost Classifier Has a Neg Log Loss of: {}\".format(round(abc_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab25115-2855-47b3-b8f3-e6e7a143e700",
   "metadata": {},
   "source": [
    "### Grid Search for ADA Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "283f507d-3cc6-4783-b928-70e45da1e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_params = [300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25c98934-e363-4a1c-927e-23b8fecb0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_parameters = {'n_estimators':estimators_params}\n",
    "\n",
    "abc_grid_search = GridSearchCV(AdaBoostClassifier(random_state = 42), abc_parameters, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "abc_grid_search.fit(x_train[:30000], y_train[:30000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "781e8c5f-8343-4637-9d5f-fe91a8e46be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Ada Boost Classifier Has a Neg Log Loss Of: -1.936\n",
      "The Best Ada Boost Classifier Has Parameters Of: {'n_estimators': 300}\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  24.8s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  25.4s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  25.4s\n",
      "[CV] END .................................. score: (test=nan) total time=   0.0s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  24.4s\n",
      "[CV] END ............................... score: (test=-1.935) total time=  23.4s\n"
     ]
    }
   ],
   "source": [
    "final_abc_regressor = abc_grid_search.best_estimator_\n",
    "print(\"The Best Ada Boost Classifier Has a Neg Log Loss Of: {}\".format(round(abc_grid_search.best_score_, 3)))\n",
    "print(\"The Best Ada Boost Classifier Has Parameters Of: {}\".format(abc_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b76f21-3e64-4cb0-82ad-a31486ecacc2",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "923ae406-d16e-4ff7-ab70-06812ea66071",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_plays_encoded = OrdinalEncoder().fit_transform(np.array(y_train_plays).reshape(-1,1))\n",
    "y_train_plays_encoded = [int(x[0]) for x in y_train_plays_encoded]\n",
    "\n",
    "y_train_onbase_encoded = OrdinalEncoder().fit_transform(np.array(y_train_onbase).reshape(-1,1))\n",
    "y_train_onbase_encoded = [int(x[0]) for x in y_train_onbase_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0dc9e-c03d-4647-9a64-4d807fc0fa6f",
   "metadata": {},
   "source": [
    "### Basic XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34fddf7e-e003-4f14-a483-09211a20a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   18.0s remaining:   26.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Basic XGBoost Boost Classifier Has a Neg Log Loss of: -1.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   27.2s finished\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb_scores = cross_val_score(xgb, x_train, y_train_encoded, cv=5, scoring=\"neg_log_loss\", n_jobs=4, verbose = 3)\n",
    "print(\"The Basic XGBoost Boost Classifier Has a Neg Log Loss of: {}\".format(round(xgb_scores.mean(),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99cc79-fd1a-4551-a5af-355e1407ad50",
   "metadata": {},
   "source": [
    "### Grid Search for XGBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f84c72cf-d3a5-4525-86d1-7efed61efcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_weight_params = [1, 5]\n",
    "gamma_params = [.5, 1, 1.5]\n",
    "subsample_params = [.6, .8]\n",
    "colsample_bytree_params = [.6, .8]\n",
    "max_depth_params = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86b73718-169a-4999-b0f7-bbae85ca9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'min_child_weight': child_weight_params,'gamma': gamma_params,'subsample': subsample_params,\n",
    "              'colsample_bytree': colsample_bytree_params,'max_depth': max_depth_params}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(XGBClassifier(), xgb_params, cv=5, scoring = \"neg_log_loss\", verbose = 3)\n",
    "xgb_grid_search.fit(x_train[:30000], y_train_encoded[:30000])\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c273092a-4053-4828-868e-703fcc40f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Ada Boost Classifier Has a Neg Log Loss Of: -1.423\n",
      "The Best Ada Boost Classifier Has Parameters Of: {'colsample_bytree': 0.6, 'gamma': 1.5, 'max_depth': 2, 'min_child_weight': 5, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "final_xgb_regressor = xgb_grid_search.best_estimator_\n",
    "print(\"The Best XGBoost Classifier Has a Neg Log Loss Of: {}\".format(round(xgb_grid_search.best_score_, 3)))\n",
    "print(\"The Best XABoost Classifier Has Parameters Of: {}\".format(xgb_grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fe78c094-6af1-4299-b347-f562a915071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   5 | elapsed:   12.3s remaining:   18.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best XGBoost Classifier Has a Neg Log Loss Of: -1.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:   18.3s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb_grid_search.best_estimator_, x_train, y_train_encoded, cv=5, scoring=\"neg_log_loss\", verbose=3, n_jobs=4)\n",
    "print(\"The Best XGBoost Classifier Has a Neg Log Loss Of: {}\".format(round(scores.mean(), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7e18a-8802-4f5b-925f-6ddfe3da4c55",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "89ed6357-fc46-4a60-88b4-72a726719a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "36573/36573 [==============================] - 15s 395us/step - loss: 1.6437 - sparse_categorical_crossentropy: 1.6437\n",
      "Epoch 2/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6094 - sparse_categorical_crossentropy: 1.6094\n",
      "Epoch 3/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6063 - sparse_categorical_crossentropy: 1.6063\n",
      "Epoch 4/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6050 - sparse_categorical_crossentropy: 1.6050\n",
      "Epoch 5/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6038 - sparse_categorical_crossentropy: 1.6038\n",
      "Epoch 6/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6031 - sparse_categorical_crossentropy: 1.6031\n",
      "Epoch 7/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6028 - sparse_categorical_crossentropy: 1.6028\n",
      "Epoch 8/150\n",
      "36573/36573 [==============================] - 14s 393us/step - loss: 1.6022 - sparse_categorical_crossentropy: 1.6022\n",
      "Epoch 9/150\n",
      "36573/36573 [==============================] - 15s 399us/step - loss: 1.6017 - sparse_categorical_crossentropy: 1.6017\n",
      "Epoch 10/150\n",
      "36573/36573 [==============================] - 15s 397us/step - loss: 1.6017 - sparse_categorical_crossentropy: 1.6017\n",
      "Epoch 11/150\n",
      "36573/36573 [==============================] - 15s 413us/step - loss: 1.6014 - sparse_categorical_crossentropy: 1.6014\n",
      "Epoch 12/150\n",
      "36573/36573 [==============================] - 15s 397us/step - loss: 1.6012 - sparse_categorical_crossentropy: 1.6012\n",
      "Epoch 13/150\n",
      "36573/36573 [==============================] - 14s 395us/step - loss: 1.6013 - sparse_categorical_crossentropy: 1.6013\n",
      "Epoch 14/150\n",
      "36573/36573 [==============================] - 14s 389us/step - loss: 1.6015 - sparse_categorical_crossentropy: 1.6015\n",
      "Epoch 15/150\n",
      "36573/36573 [==============================] - 15s 414us/step - loss: 1.6013 - sparse_categorical_crossentropy: 1.6013\n",
      "Epoch 16/150\n",
      "36573/36573 [==============================] - 15s 413us/step - loss: 1.6009 - sparse_categorical_crossentropy: 1.6009\n",
      "Epoch 17/150\n",
      "36573/36573 [==============================] - 15s 404us/step - loss: 1.6011 - sparse_categorical_crossentropy: 1.6011\n",
      "Epoch 18/150\n",
      "36573/36573 [==============================] - 14s 395us/step - loss: 1.6011 - sparse_categorical_crossentropy: 1.6011\n",
      "Epoch 19/150\n",
      "36573/36573 [==============================] - 14s 389us/step - loss: 1.6010 - sparse_categorical_crossentropy: 1.6010\n",
      "Epoch 20/150\n",
      "36573/36573 [==============================] - 16s 428us/step - loss: 1.6008 - sparse_categorical_crossentropy: 1.6008\n",
      "Epoch 21/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6008 - sparse_categorical_crossentropy: 1.6008\n",
      "Epoch 22/150\n",
      "36573/36573 [==============================] - 14s 394us/step - loss: 1.6005 - sparse_categorical_crossentropy: 1.6005\n",
      "Epoch 23/150\n",
      "36573/36573 [==============================] - 15s 405us/step - loss: 1.6003 - sparse_categorical_crossentropy: 1.6003\n",
      "Epoch 24/150\n",
      "36573/36573 [==============================] - 15s 398us/step - loss: 1.6005 - sparse_categorical_crossentropy: 1.6005\n",
      "Epoch 25/150\n",
      "36573/36573 [==============================] - 15s 409us/step - loss: 1.6002 - sparse_categorical_crossentropy: 1.6002\n",
      "Epoch 26/150\n",
      "36573/36573 [==============================] - 14s 392us/step - loss: 1.6001 - sparse_categorical_crossentropy: 1.6001\n",
      "Epoch 27/150\n",
      "36573/36573 [==============================] - 14s 388us/step - loss: 1.6000 - sparse_categorical_crossentropy: 1.6000\n",
      "Epoch 28/150\n",
      "36573/36573 [==============================] - 15s 397us/step - loss: 1.6003 - sparse_categorical_crossentropy: 1.6003\n",
      "Epoch 29/150\n",
      "36573/36573 [==============================] - 14s 388us/step - loss: 1.6004 - sparse_categorical_crossentropy: 1.6004\n",
      "Epoch 30/150\n",
      "36573/36573 [==============================] - 15s 403us/step - loss: 1.6002 - sparse_categorical_crossentropy: 1.6002\n",
      "Epoch 31/150\n",
      "36573/36573 [==============================] - 15s 399us/step - loss: 1.6004 - sparse_categorical_crossentropy: 1.6004\n",
      "Epoch 32/150\n",
      "36573/36573 [==============================] - 15s 398us/step - loss: 1.6000 - sparse_categorical_crossentropy: 1.6000\n",
      "Epoch 33/150\n",
      "36573/36573 [==============================] - 15s 401us/step - loss: 1.5998 - sparse_categorical_crossentropy: 1.5998\n",
      "Epoch 34/150\n",
      "36573/36573 [==============================] - 15s 400us/step - loss: 1.5998 - sparse_categorical_crossentropy: 1.5998\n",
      "Epoch 35/150\n",
      "36573/36573 [==============================] - 15s 406us/step - loss: 1.6002 - sparse_categorical_crossentropy: 1.6002\n",
      "Epoch 36/150\n",
      "36573/36573 [==============================] - 15s 399us/step - loss: 1.6000 - sparse_categorical_crossentropy: 1.6000\n",
      "Epoch 37/150\n",
      "36573/36573 [==============================] - 15s 406us/step - loss: 1.6000 - sparse_categorical_crossentropy: 1.6000\n",
      "Epoch 38/150\n",
      "36573/36573 [==============================] - 15s 401us/step - loss: 1.6006 - sparse_categorical_crossentropy: 1.6006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c472a710>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='sparse_categorical_crossentropy', patience=5, start_from_epoch=4, restore_best_weights = True)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 10 nodes and specify the input shape (54 inputs)\n",
    "model.add(Dense(10, input_shape=(126,), activation='relu'))\n",
    "\n",
    "# Add the second hidden layer with 10 nodes\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "# Add the output layer with 7 nodes (for 7 categorical outputs) and 'softmax' activation\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "# Call model on a test input\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_crossentropy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(x_train, np.array(y_train_plays_encoded), epochs=150, batch_size=10, callbacks = [callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e604d6-c61b-4808-b92f-d5b26421be7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
